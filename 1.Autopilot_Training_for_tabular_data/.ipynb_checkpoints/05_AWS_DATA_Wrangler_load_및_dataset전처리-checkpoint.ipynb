{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. AWS Data Wrangler를 이용한 Data load\n",
    "\n",
    "* https://github.com/awslabs/aws-data-wrangler\n",
    "* https://aws-data-wrangler.readthedocs.io\n",
    "\n",
    "AWS Data Wrangler는 오픈 소스 Python 패키지로 Pandas 라이브러리의 기능을 AWS를 연결하는 DataFrames 및 AWS 데이터 관련 서비스 (Amazon Redshift, AWS Glue, Amazon Athena, Amazon EMR, Amazon QuickSight 등)로 확장합니다.\n",
    "\n",
    "Pandas, Apache Arrow, Boto3, s3fs, SQLAlchemy, Psycopg2 및 PyMySQL과 같은 다른 오픈 소스 프로젝트를 기반으로 구축 된 Data Lakes, Data Warehouses 및 Databases의 데이터로드 / 언로드와 같은 일반적인 ETL 작업을 실행하는 추상 기능을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!{sys.executable} -m pip install -q awswrangler==1.2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "import awswrangler as wr\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 ) Push-Down Filters를 이용한 S3에서 Parquet 쿼리\n",
    "\n",
    "S3의 prefix 또는 S3객체 경로의 리스트에서 Apache Parquet 파일을 읽습니다. \n",
    "Dataset의 개념은 Partitioning과 카탈로그통합과 같이 복잡한 특성을 가능하게 합니다.\n",
    "\n",
    "dataset (bool) : 만약 True이면 컬럼으로 모든 관련된 partitions을 로드하여 단순 파일이 아닌 parquet dataset으로 읽습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = wr.s3.read_parquet(s3_path_parquet,\n",
    "                        filters=[(\"product_category\", \"=\", \"Digital_Software\")],\n",
    "                        dataset=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format='retina'\n",
    "\n",
    "df[['star_rating', 'review_id']].groupby('star_rating').count().plot(kind='bar', title='Breakdown by Star Rating')\n",
    "plt.xlabel('Star Rating')\n",
    "plt.ylabel('Review Count')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Balance the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "five_star_df = df.query('star_rating == 5', engine='python')\n",
    "four_star_df = df.query('star_rating == 4', engine='python')\n",
    "three_star_df = df.query('star_rating == 3', engine='python')\n",
    "two_star_df = df.query('star_rating == 2', engine='python')\n",
    "one_star_df = df.query('star_rating == 1', engine='python')\n",
    "\n",
    "# Check which sentiment has the least number of samples\n",
    "minority_count = min(five_star_df.shape[0], \n",
    "                     four_star_df.shape[0], \n",
    "                     three_star_df.shape[0], \n",
    "                     two_star_df.shape[0], \n",
    "                     one_star_df.shape[0]) \n",
    "\n",
    "five_star_df = resample(five_star_df,\n",
    "                        replace = False,\n",
    "                        n_samples = minority_count,\n",
    "                        random_state = 27)\n",
    "\n",
    "four_star_df = resample(four_star_df,\n",
    "                        replace = False,\n",
    "                        n_samples = minority_count,\n",
    "                        random_state = 27)\n",
    "\n",
    "three_star_df = resample(three_star_df,\n",
    "                        replace = False,\n",
    "                        n_samples = minority_count,\n",
    "                        random_state = 27)\n",
    "\n",
    "two_star_df = resample(two_star_df,\n",
    "                        replace = False,\n",
    "                        n_samples = minority_count,\n",
    "                        random_state = 27)\n",
    "\n",
    "one_star_df = resample(one_star_df,\n",
    "                        replace = False,\n",
    "                        n_samples = minority_count,\n",
    "                        random_state = 27)\n",
    "\n",
    "df_balanced = pd.concat([five_star_df, four_star_df, three_star_df, two_star_df, one_star_df])\n",
    "df_balanced = df_balanced.reset_index(drop=True)\n",
    "\n",
    "df_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced[['star_rating', 'review_id']].groupby('star_rating').count().plot(kind='bar', title='Breakdown by Star Rating')\n",
    "plt.xlabel('Star Rating')\n",
    "plt.ylabel('Review Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_balanced.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split the Data into Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split all data into 90% train and 10% holdout\n",
    "df_train, df_holdout = train_test_split(df_balanced, \n",
    "                                        test_size=0.10,\n",
    "                                        stratify=df_balanced['star_rating'])\n",
    "\n",
    "# Split holdout data into 50% validation and 50% test\n",
    "df_validation, df_test = train_test_split(df_holdout,\n",
    "                                          test_size=0.50, \n",
    "                                          stratify=df_holdout['star_rating'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pie chart, where the slices will be ordered and plotted counter-clockwise:\n",
    "labels = ['Train', 'Validation', 'Test']\n",
    "sizes = [len(df_train.index), len(df_validation.index), len(df_test.index)]\n",
    "explode = (0.1, 0, 0)  \n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "\n",
    "ax1.pie(sizes, explode=explode, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "\n",
    "# Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "ax1.axis('equal')  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show 90% Train Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[['star_rating', 'review_id']].groupby('star_rating').count().plot(kind='bar', title='90% Train Breakdown by Star Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show 5% Validation Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_validation[['star_rating', 'review_id']].groupby('star_rating').count().plot(kind='bar', title='5% Validation Breakdown by Star Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Show 5% Test Data Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[['star_rating', 'review_id']].groupby('star_rating').count().plot(kind='bar', title='5% Test Breakdown by Star Rating')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select `star_rating` and `review_body` for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['star_rating', 'review_body']]\n",
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train[['star_rating', 'review_body']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a Train CSV with Header for AutoPilot "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir='./data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf $data_dir\n",
    "!mkdir $data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header_train_path = os.path.join(data_dir,'amazon_reviews_us_Digital_Software_v1_00_header.csv')\n",
    "df_train.to_csv(header_train_path, index=False, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Train Data to S3 for AutoPilot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3_prefix = 'data'\n",
    "header_train_s3_uri = sess.upload_data(path=header_train_path, key_prefix=train_s3_prefix)\n",
    "header_train_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $header_train_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Write a CSV With No Header for Comprehend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noheader_train_path = os.path.join(data_dir,'amazon_reviews_us_Digital_Software_v1_00_noheader.csv')\n",
    "df_train.to_csv(noheader_train_path, index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload Train Data to S3 for Comprehend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_s3_prefix = 'data'\n",
    "noheader_train_s3_uri = sess.upload_data(path=noheader_train_path, key_prefix=train_s3_prefix)\n",
    "noheader_train_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 ls $noheader_train_s3_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store the location of our train data in our notebook server to be used next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store header_train_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store noheader_train_s3_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
