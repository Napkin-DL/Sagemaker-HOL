{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HTTPS Endpoint로 Model Serving\n",
    "\n",
    "real-time과 batch predictions Endpoint를 모두 활용할 수 있으며, 이 HOL에서는 Real-time에 대해서만 설명합니다. \n",
    "사용 중이신 애플리케이션의 대기시간이 짧은 경우 Model은 real-time API로 배포하며 HTTPS를 통해 단일 예측 요청에 대해 빠르게 예측을 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이전 Notebook에서 Endpoints를 생성하신 경우에는 Endpoints를 삭제하신 후 이 노트북을 생성하시기 바랍니다. 그렇지 않은 경우 HOL를 수행하시는 동안에 ResourceLimitExceeded error를 보실 수 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "automl-dm-epc-15-05-41-41\n",
      "endpoint-pet-classifier-1599199760\n",
      "automl-dm-model-15-05-41-41\n",
      "automl-dm-15-05-41-41-automl-dm--dpp0-model-1dfbbd0e5f8e464689f\n",
      "automl-dm-15-05-41-41-automl-dm--dpp1-model-8a74914373eb407d8a5\n",
      "automl-dm-15-05-41-41-automl-dm--dpp2-model-ccb158e1f126483d82a\n",
      "pytorch-inference-eia-2020-09-04-06-09-29-156\n"
     ]
    }
   ],
   "source": [
    "list_endpoints = sm.list_endpoints()\n",
    "\n",
    "for ep in list_endpoints['Endpoints']:\n",
    "    sm.delete_endpoint(EndpointName=ep['EndpointName'])\n",
    "    \n",
    "\n",
    "NextToken = 'None'\n",
    "while NextToken !='':\n",
    "    lec = sm.list_endpoint_configs(NextToken=NextToken) if NextToken != 'None' else sm.list_endpoint_configs()\n",
    "    for epc in lec['EndpointConfigs']:\n",
    "        print(epc['EndpointConfigName'])\n",
    "        sm.delete_endpoint_config(EndpointConfigName=epc['EndpointConfigName'])\n",
    "        time.sleep(3)\n",
    "    NextToken = lec['NextToken'] if lec.get('NextToken') else ''\n",
    "\n",
    "NextToken = 'None'\n",
    "while NextToken !='':\n",
    "    lec = sm.list_models(NextToken=NextToken) if NextToken != 'None' else sm.list_models()\n",
    "    for epc in lec['Models']:\n",
    "        print(epc['ModelName'])\n",
    "        sm.delete_model(ModelName=epc['ModelName'])\n",
    "        time.sleep(3)\n",
    "    NextToken = lec['NextToken'] if lec.get('NextToken') else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-09-15-06-48-39-100\n"
     ]
    }
   ],
   "source": [
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 내 Model 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-322537213286/tensorflow-training-2020-09-15-06-48-39-100/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz ./model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard/\n",
      "metrics/\n",
      "metrics/confusion_matrix.png\n",
      "transformers/\n",
      "transformers/fine-tuned/\n",
      "transformers/fine-tuned/tf_model.h5\n",
      "transformers/fine-tuned/config.json\n",
      "tensorflow/\n",
      "tensorflow/saved_model/\n",
      "tensorflow/saved_model/0/\n",
      "tensorflow/saved_model/0/saved_model.pb\n",
      "tensorflow/saved_model/0/variables/\n",
      "tensorflow/saved_model/0/variables/variables.data-00000-of-00002\n",
      "tensorflow/saved_model/0/variables/variables.data-00001-of-00002\n",
      "tensorflow/saved_model/0/variables/variables.index\n",
      "tensorflow/saved_model/0/assets/\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf ./model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-15 07:40:54.269855: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib:/usr/local/cuda-10.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:\n",
      "2020-09-15 07:40:54.269949: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda-10.0/lib64:/usr/local/cuda-10.0/extras/CUPTI/lib64:/usr/local/cuda-10.0/lib:/usr/local/cuda-10.0/efa/lib:/opt/amazon/efa/lib:/opt/amazon/efa/lib64:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:/usr/lib64/openmpi/lib/:/usr/local/lib:/usr/lib:/usr/local/mpi/lib:/lib/:\n",
      "2020-09-15 07:40:54.269961: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 128)\n",
      "        name: serving_default_input_ids:0\n",
      "    inputs['input_mask'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 128)\n",
      "        name: serving_default_input_mask:0\n",
      "    inputs['segment_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 128)\n",
      "        name: serving_default_segment_ids:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir ./tensorflow/saved_model/0/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model 배포\n",
    "\n",
    "단일 Model에 대해 기본적으로 `EndpointConfig`를 생성합니다. 다음 노트북에서 canary 배포와 A/B testing을 지원하는 `EndpointConfig` 전략을 수행할 계획입니다. \n",
    "\n",
    "_참고: 리전에 따라 기본적으로 제공되는 다양한 버전/Deep leanring 프레임워크 별로 deep learning 이미지를 제공하고 있으며, 필요에 따라 해당 image를 받아서 추가해서 custom 이미지를 생성할 수 있습니다._\n",
    "\n",
    "https://docs.aws.amazon.com/deep-learning-containers/latest/devguide/deep-learning-containers-images.html\n",
    "\n",
    "\n",
    "또한, SageMaker에서 학습한 모델이 아닌 경우에도 XXXXX.tar.gz로 압축하여 예측에 활용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "model = Model(model_data='s3://{}/{}/output/model.tar.gz'.format(bucket, training_job_name),\n",
    "              role=role,\n",
    "              framework_version='2.0.0') # Elastic Inference does not yet support TF 2.1.0 as of sagemaker==1.56.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Endpoint name:  tensorflow-inference-2020-09-15-07-41-00-789\n"
     ]
    }
   ],
   "source": [
    "deployed_model = model.deploy(initial_instance_count=1, # Should use >=2 for high(er) availability \n",
    "                              instance_type='ml.m5.large',\n",
    "#                              accelerator_type='ml.eia2.medium',\n",
    "                              wait=False)\n",
    "\n",
    "endpoint_name = deployed_model.endpoint\n",
    "\n",
    "print('Endpoint name:  {}'.format(endpoint_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 내 배포 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amazon-Customer-Reviews-BERT-Experiment-1600152510\n"
     ]
    }
   ],
   "source": [
    "print(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trial-1600152510\n"
     ]
    }
   ],
   "source": [
    "print(trial_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7fa8bd486c50>,trial_name='trial-1600152510',trial_arn='arn:aws:sagemaker:us-east-1:322537213286:experiment-trial/trial-1600152510',display_name='trial-1600152510',experiment_name='Amazon-Customer-Reviews-BERT-Experiment-1600152510',creation_time=datetime.datetime(2020, 9, 15, 6, 48, 30, 767000, tzinfo=tzlocal()),created_by={},last_modified_time=datetime.datetime(2020, 9, 15, 7, 40, 3, 47000, tzinfo=tzlocal()),last_modified_by={},response_metadata={'RequestId': '157e57c4-d0e2-48a7-9963-5ded140ddc46', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '157e57c4-d0e2-48a7-9963-5ded140ddc46', 'content-type': 'application/x-amz-json-1.1', 'content-length': '326', 'date': 'Tue, 15 Sep 2020 07:41:02 GMT'}, 'RetryAttempts': 0})\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from smexperiments.trial import Trial\n",
    "\n",
    "timestamp = '{}'.format(int(time.time()))\n",
    "\n",
    "trial = Trial.load(trial_name=trial_name)\n",
    "print(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deploy trial component name TrialComponent-2020-09-15-074102-uzmt\n"
     ]
    }
   ],
   "source": [
    "from smexperiments.tracker import Tracker\n",
    "\n",
    "tracker_deploy = Tracker.create(display_name='deploy', \n",
    "                                sagemaker_boto_client=sm)\n",
    "\n",
    "deploy_trial_component_name = tracker_deploy.trial_component.trial_component_name\n",
    "print('Deploy trial component name {}'.format(deploy_trial_component_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trial에 Component로 `deploy` Trial Component 와 Tracker를 추가합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.add_trial_component(tracker_deploy.trial_component)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Endpoint Name 추적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrialComponent(sagemaker_boto_client=<botocore.client.SageMaker object at 0x7fa8bcae2400>,trial_component_name='TrialComponent-2020-09-15-074102-uzmt',display_name='deploy',trial_component_arn='arn:aws:sagemaker:us-east-1:322537213286:experiment-trial-component/trialcomponent-2020-09-15-074102-uzmt',response_metadata={'RequestId': '9fa8c1cc-848f-4b08-8266-58d39d8f5124', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': '9fa8c1cc-848f-4b08-8266-58d39d8f5124', 'content-type': 'application/x-amz-json-1.1', 'content-length': '129', 'date': 'Tue, 15 Sep 2020 07:41:03 GMT'}, 'RetryAttempts': 0},parameters={'endpoint_name': 'tensorflow-inference-2020-09-15-07-41-00-789'},input_artifacts={},output_artifacts={})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracker_deploy.log_parameters({\n",
    "    'endpoint_name': endpoint_name,\n",
    "})\n",
    "\n",
    "# must save after logging\n",
    "tracker_deploy.trial_component.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-1#/endpoints/tensorflow-inference-2020-09-15-07-41-00-789\">REST Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">REST Endpoint</a></b>'.format(region, endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "waiter = client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">위 Endpoint가 Deploy되기 전까지 기다려 주시기 바랍니다.</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 57)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sagemaker.analytics import ExperimentAnalytics\n",
    "\n",
    "lineage_table = ExperimentAnalytics(\n",
    "    sagemaker_session=sess,\n",
    "    experiment_name=experiment_name,\n",
    "    metric_names=['validation:accuracy'],\n",
    "    sort_by=\"CreationTime\",\n",
    "    sort_order=\"Ascending\",\n",
    ")\n",
    "\n",
    "lineage_df = lineage_table.dataframe()\n",
    "lineage_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TrialComponentName</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>max_seq_length</th>\n",
       "      <th>test_split_percentage</th>\n",
       "      <th>train_split_percentage</th>\n",
       "      <th>validation_split_percentage</th>\n",
       "      <th>raw_data_s3_uri - MediaType</th>\n",
       "      <th>raw_data_s3_uri - Value</th>\n",
       "      <th>SourceArn</th>\n",
       "      <th>SageMaker.ImageUri</th>\n",
       "      <th>...</th>\n",
       "      <th>train - Value</th>\n",
       "      <th>validation - MediaType</th>\n",
       "      <th>validation - Value</th>\n",
       "      <th>SageMaker.Checkpoints - MediaType</th>\n",
       "      <th>SageMaker.Checkpoints - Value</th>\n",
       "      <th>SageMaker.DebugHookOutput - MediaType</th>\n",
       "      <th>SageMaker.DebugHookOutput - Value</th>\n",
       "      <th>SageMaker.ModelArtifact - MediaType</th>\n",
       "      <th>SageMaker.ModelArtifact - Value</th>\n",
       "      <th>endpoint_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TrialComponent-2020-09-15-064830-dysr</td>\n",
       "      <td>prepare</td>\n",
       "      <td>128.0</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.05</td>\n",
       "      <td>s3/uri</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/amazon-r...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensorflow-training-2020-09-15-06-48-39-100-aw...</td>\n",
       "      <td>train</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:322537213286:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/t...</td>\n",
       "      <td>...</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/checkpoi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/tensorfl...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensorflow-training-2020-09-15-07-39-58-824-aw...</td>\n",
       "      <td>train</td>\n",
       "      <td>128.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>arn:aws:sagemaker:us-east-1:322537213286:train...</td>\n",
       "      <td>763104351884.dkr.ecr.us-east-1.amazonaws.com/t...</td>\n",
       "      <td>...</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/sagemake...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/checkpoi...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>s3://sagemaker-us-east-1-322537213286/</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TrialComponent-2020-09-15-074102-uzmt</td>\n",
       "      <td>deploy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tensorflow-inference-2020-09-15-07-41-00-789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  TrialComponentName DisplayName  \\\n",
       "0              TrialComponent-2020-09-15-064830-dysr     prepare   \n",
       "1  tensorflow-training-2020-09-15-06-48-39-100-aw...       train   \n",
       "2  tensorflow-training-2020-09-15-07-39-58-824-aw...       train   \n",
       "3              TrialComponent-2020-09-15-074102-uzmt      deploy   \n",
       "\n",
       "   max_seq_length  test_split_percentage  train_split_percentage  \\\n",
       "0           128.0                   0.05                     0.9   \n",
       "1           128.0                    NaN                     NaN   \n",
       "2           128.0                    NaN                     NaN   \n",
       "3             NaN                    NaN                     NaN   \n",
       "\n",
       "   validation_split_percentage raw_data_s3_uri - MediaType  \\\n",
       "0                         0.05                      s3/uri   \n",
       "1                          NaN                         NaN   \n",
       "2                          NaN                         NaN   \n",
       "3                          NaN                         NaN   \n",
       "\n",
       "                             raw_data_s3_uri - Value  \\\n",
       "0  s3://sagemaker-us-east-1-322537213286/amazon-r...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "\n",
       "                                           SourceArn  \\\n",
       "0                                                NaN   \n",
       "1  arn:aws:sagemaker:us-east-1:322537213286:train...   \n",
       "2  arn:aws:sagemaker:us-east-1:322537213286:train...   \n",
       "3                                                NaN   \n",
       "\n",
       "                                  SageMaker.ImageUri  ...  \\\n",
       "0                                                NaN  ...   \n",
       "1  763104351884.dkr.ecr.us-east-1.amazonaws.com/t...  ...   \n",
       "2  763104351884.dkr.ecr.us-east-1.amazonaws.com/t...  ...   \n",
       "3                                                NaN  ...   \n",
       "\n",
       "                                       train - Value validation - MediaType  \\\n",
       "0                                                NaN                    NaN   \n",
       "1  s3://sagemaker-us-east-1-322537213286/sagemake...                    NaN   \n",
       "2  s3://sagemaker-us-east-1-322537213286/sagemake...                    NaN   \n",
       "3                                                NaN                    NaN   \n",
       "\n",
       "                                  validation - Value  \\\n",
       "0                                                NaN   \n",
       "1  s3://sagemaker-us-east-1-322537213286/sagemake...   \n",
       "2  s3://sagemaker-us-east-1-322537213286/sagemake...   \n",
       "3                                                NaN   \n",
       "\n",
       "  SageMaker.Checkpoints - MediaType  \\\n",
       "0                               NaN   \n",
       "1                               NaN   \n",
       "2                               NaN   \n",
       "3                               NaN   \n",
       "\n",
       "                       SageMaker.Checkpoints - Value  \\\n",
       "0                                                NaN   \n",
       "1  s3://sagemaker-us-east-1-322537213286/checkpoi...   \n",
       "2  s3://sagemaker-us-east-1-322537213286/checkpoi...   \n",
       "3                                                NaN   \n",
       "\n",
       "  SageMaker.DebugHookOutput - MediaType  \\\n",
       "0                                   NaN   \n",
       "1                                   NaN   \n",
       "2                                   NaN   \n",
       "3                                   NaN   \n",
       "\n",
       "        SageMaker.DebugHookOutput - Value  \\\n",
       "0                                     NaN   \n",
       "1  s3://sagemaker-us-east-1-322537213286/   \n",
       "2  s3://sagemaker-us-east-1-322537213286/   \n",
       "3                                     NaN   \n",
       "\n",
       "   SageMaker.ModelArtifact - MediaType  \\\n",
       "0                                  NaN   \n",
       "1                                  NaN   \n",
       "2                                  NaN   \n",
       "3                                  NaN   \n",
       "\n",
       "                     SageMaker.ModelArtifact - Value  \\\n",
       "0                                                NaN   \n",
       "1  s3://sagemaker-us-east-1-322537213286/tensorfl...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "\n",
       "                                  endpoint_name  \n",
       "0                                           NaN  \n",
       "1                                           NaN  \n",
       "2                                           NaN  \n",
       "3  tensorflow-inference-2020-09-15-07-41-00-789  \n",
       "\n",
       "[4 rows x 57 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lineage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Raw Text를 BERT Tokens로 변환하기 위한 Request Handler 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestHandler(object):\n",
    "    import json\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __call__(self, instances):\n",
    "        transformed_instances = []\n",
    "\n",
    "        for instance in instances:\n",
    "            encode_plus_tokens = tokenizer.encode_plus(instance,\n",
    "                                                       pad_to_max_length=True,\n",
    "                                                       max_length=self.max_seq_length)\n",
    "\n",
    "            input_ids = encode_plus_tokens['input_ids']\n",
    "            input_mask = encode_plus_tokens['attention_mask']\n",
    "            segment_ids = [0] * self.max_seq_length\n",
    "\n",
    "            transformed_instance = {\"input_ids\": input_ids, \n",
    "                                    \"input_mask\": input_mask, \n",
    "                                    \"segment_ids\": segment_ids}\n",
    "\n",
    "            transformed_instances.append(transformed_instance)\n",
    "\n",
    "        transformed_data = {\"instances\": transformed_instances}\n",
    "\n",
    "        return json.dumps(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  BERT Response를 Predicted Classes로 변환하기 위한 Response Handler 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseHandler(object):\n",
    "    import json\n",
    "    import tensorflow as tf\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "    \n",
    "    def __call__(self, response, accept_header):\n",
    "        import tensorflow as tf\n",
    "\n",
    "        response_body = response.read().decode('utf-8')\n",
    "\n",
    "        response_json = json.loads(response_body)\n",
    "\n",
    "        log_probabilities = response_json[\"predictions\"]\n",
    "\n",
    "        predicted_classes = []\n",
    "\n",
    "        # Convert log_probabilities => softmax (all probabilities add up to 1) => argmax (final prediction)\n",
    "        for log_probability in log_probabilities:\n",
    "            softmax = tf.nn.softmax(log_probability)    \n",
    "            predicted_class_idx = tf.argmax(softmax, axis=-1, output_type=tf.int32)\n",
    "            predicted_class = self.classes[predicted_class_idx]\n",
    "            predicted_classes.append(predicted_class)\n",
    "\n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:transformers.file_utils:TensorFlow version 2.1.0 available.\n",
      "INFO:transformers.tokenization_utils:loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /home/ec2-user/.cache/torch/transformers/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from sagemaker.tensorflow.serving import Predictor\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "request_handler = RequestHandler(tokenizer=tokenizer,\n",
    "                                 max_seq_length=128)\n",
    "\n",
    "response_handler = ResponseHandler(classes=[1, 2, 3, 4, 5])\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name,\n",
    "                      sagemaker_session=sess,\n",
    "                      serializer=request_handler,\n",
    "                      deserializer=response_handler,\n",
    "                      content_type='application/json',\n",
    "                      model_name='saved_model',\n",
    "                      model_version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Predicted Star Rating: 5] This is great!\n",
      "[Predicted Star Rating: 5] This is not good.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "    \n",
    "reviews = [\"This is great!\", \n",
    "           \"This is not good.\"]\n",
    "\n",
    "predicted_classes = predictor.predict(reviews)\n",
    "\n",
    "for predicted_class, review in zip(predicted_classes, reviews):\n",
    "    print('[Predicted Star Rating: {}]'.format(predicted_class), review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'endpoint_name' (str)\n"
     ]
    }
   ],
   "source": [
    "%store endpoint_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using API Gateway with SageMaker Endpoints\n",
    "\n",
    "https://aws.amazon.com/blogs/machine-learning/creating-a-machine-learning-powered-rest-api-with-amazon-api-gateway-mapping-templates-and-amazon-sagemaker/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Delete Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ResponseMetadata': {'RequestId': 'fff98548-7eaa-4e0c-9b44-4ca9c5a66e4e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': 'fff98548-7eaa-4e0c-9b44-4ca9c5a66e4e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '0',\n",
       "   'date': 'Tue, 15 Sep 2020 07:48:42 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# client = boto3.client('sagemaker')\n",
    "\n",
    "# client.delete_endpoint(\n",
    "#     EndpointName=endpoint_name\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
