{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Processing Job \n",
    "\n",
    "\n",
    "기계 학습 (ML) 프로세스는 몇 단계로 구성됩니다. 먼저, 다양한 ETL 작업으로 데이터를 수집 한 다음 data의 pre-processing, 전통적인 기법 또는 사전 knowledge를 이용하여 데이터의 feature화, 마지막으로 알고리즘을 이용한 ML 모델을 학습합니다.\n",
    "\n",
    "Apache Spark와 같은 분산 데이터 처리 프레임 워크는 학습을 위해 dataset의 pre-processing하는데 사용합니다. 이 노트북에서는 Amazon SageMaker Processing에서 기본 설치된 Apache Spark의 기능을 활용하여 처리 워크로드를 실행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/prepare_dataset_bert.png)\n",
    "\n",
    "![](img/processing.jpg)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Environment\n",
    "\n",
    "\n",
    "* 모델 학습에 사용되는 S3 bucket과 prefix 가 필요합니다.\n",
    "* 학습과 processing을 위해 IAM role은 dataset에 액세스가 가능해야 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "from time import gmtime, strftime\n",
    "import boto3\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = boto3.Session().region_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-322537213286/amazon-reviews-pds/tsv/\n"
     ]
    }
   ],
   "source": [
    "# Inputs\n",
    "s3_input_data = 's3://{}/amazon-reviews-pds/tsv/'.format(bucket)\n",
    "print(s3_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-15 04:56:04   18997559 amazon_reviews_us_Digital_Software_v1_00.tsv.gz\r\n",
      "2020-09-15 04:56:06   27442648 amazon_reviews_us_Digital_Video_Games_v1_00.tsv.gz\r\n",
      "2020-09-15 04:56:09  193389086 amazon_reviews_us_Musical_Instruments_v1_00.tsv.gz\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls $s3_input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Job을 수행할 Spark Docker Image\n",
    "\n",
    "이 HOL에서는 `./container` 폴더 내에 Spark container 이미지를 포함합니다. container는 모든 Spark 구성의 부트스트랩을 처리하고 `spark-submit` CLI를 wrapper해서 제공합니다. 상위 레벨에서는,\n",
    "\n",
    "* A set of default Spark/YARN/Hadoop configurations\n",
    "* A bootstrapping script for configuring and starting up Spark master/worker nodes\n",
    "* A wrapper around the `spark-submit` CLI to submit a Spark application\n",
    "\n",
    "container 빌드와 push 절차가 완료된 후 dataset의 처리를 수행하는 관리형 분산 Spark 어플리케이션을 수행사는 것은 Amazon SageMaker Python SDK 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "docker_repo = 'amazon-reviews-spark-processor'\n",
    "docker_tag = 'latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending build context to Docker daemon  4.385MB\n",
      "Step 1/37 : FROM openjdk:8-jre-slim\n",
      "8-jre-slim: Pulling from library/openjdk\n",
      "\n",
      "\u001b[1Bf8d1c412: Pulling fs layer \n",
      "\u001b[1Bccc0fc24: Pulling fs layer \n",
      "\u001b[1B7ee20b42: Pulling fs layer \n",
      "\u001b[1BDigest: sha256:b933e809a1597f27617cf50bdd07f4daa351742c36dd34777506cd73111caca8[4A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[4A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[3A\u001b[2K\u001b[2A\u001b[2K\u001b[2A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\u001b[1A\u001b[2K\n",
      "Status: Downloaded newer image for openjdk:8-jre-slim\n",
      " ---> f75cca7b8ea8\n",
      "Step 2/37 : RUN apt-get update\n",
      " ---> Running in 136754ebbad1\n",
      "Get:1 http://security.debian.org/debian-security buster/updates InRelease [65.4 kB]\n",
      "Get:2 http://deb.debian.org/debian buster InRelease [122 kB]\n",
      "Get:3 http://deb.debian.org/debian buster-updates InRelease [51.9 kB]\n",
      "Get:4 http://security.debian.org/debian-security buster/updates/main amd64 Packages [226 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 Packages [7906 kB]\n",
      "Get:6 http://deb.debian.org/debian buster-updates/main amd64 Packages [7868 B]\n",
      "Fetched 8380 kB in 1s (5777 kB/s)\n",
      "Reading package lists...\n",
      "Removing intermediate container 136754ebbad1\n",
      " ---> 89cc4faaf7d8\n",
      "Step 3/37 : RUN apt-get install -y curl unzip python3 python3-setuptools python3-pip python-dev python3-dev python-psutil\n",
      " ---> Running in 2de473830a40\n",
      "Reading package lists...\n",
      "Building dependency tree...\n",
      "Reading state information...\n",
      "The following additional packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential bzip2 cpp\n",
      "  cpp-8 dbus dh-python dirmngr dpkg-dev fakeroot file g++ g++-8 gcc gcc-8\n",
      "  gir1.2-glib-2.0 gnupg gnupg-l10n gnupg-utils gpg gpg-agent gpg-wks-client\n",
      "  gpg-wks-server gpgconf gpgsm krb5-locales libalgorithm-diff-perl\n",
      "  libalgorithm-diff-xs-perl libalgorithm-merge-perl libapparmor1 libasan5\n",
      "  libassuan0 libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0 libcurl4\n",
      "  libdbus-1-3 libdpkg-perl libexpat1 libexpat1-dev libfakeroot\n",
      "  libfile-fcntllock-perl libgcc-8-dev libgdbm-compat4 libgdbm6\n",
      "  libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libgomp1 libgssapi-krb5-2\n",
      "  libicu63 libisl19 libitm1 libk5crypto3 libkeyutils1 libkrb5-3\n",
      "  libkrb5support0 libksba8 libldap-2.4-2 libldap-common liblocale-gettext-perl\n",
      "  liblsan0 libmagic-mgc libmagic1 libmpc3 libmpdec2 libmpfr6 libmpx2\n",
      "  libnghttp2-14 libnpth0 libperl5.28 libpsl5 libpython-dev libpython-stdlib\n",
      "  libpython2-dev libpython2-stdlib libpython2.7 libpython2.7-dev\n",
      "  libpython2.7-minimal libpython2.7-stdlib libpython3-dev libpython3-stdlib\n",
      "  libpython3.7 libpython3.7-dev libpython3.7-minimal libpython3.7-stdlib\n",
      "  libquadmath0 libreadline7 librtmp1 libsasl2-2 libsasl2-modules\n",
      "  libsasl2-modules-db libsqlite3-0 libssh2-1 libstdc++-8-dev libtsan0\n",
      "  libubsan1 libxml2 linux-libc-dev make manpages manpages-dev mime-support\n",
      "  netbase patch perl perl-modules-5.28 pinentry-curses publicsuffix python\n",
      "  python-minimal python-pip-whl python2 python2-dev python2-minimal python2.7\n",
      "  python2.7-dev python2.7-minimal python3-asn1crypto python3-cffi-backend\n",
      "  python3-crypto python3-cryptography python3-dbus python3-distutils\n",
      "  python3-entrypoints python3-gi python3-keyring python3-keyrings.alt\n",
      "  python3-lib2to3 python3-minimal python3-pkg-resources python3-secretstorage\n",
      "  python3-six python3-wheel python3-xdg python3.7 python3.7-dev\n",
      "  python3.7-minimal readline-common shared-mime-info xdg-user-dirs xz-utils\n",
      "Suggested packages:\n",
      "  binutils-doc bzip2-doc cpp-doc gcc-8-locales default-dbus-session-bus\n",
      "  | dbus-session-bus dbus-user-session libpam-systemd pinentry-gnome3 tor\n",
      "  debian-keyring g++-multilib g++-8-multilib gcc-8-doc libstdc++6-8-dbg\n",
      "  gcc-multilib autoconf automake libtool flex bison gdb gcc-doc gcc-8-multilib\n",
      "  libgcc1-dbg libgomp1-dbg libitm1-dbg libatomic1-dbg libasan5-dbg\n",
      "  liblsan0-dbg libtsan0-dbg libubsan1-dbg libmpx2-dbg libquadmath0-dbg\n",
      "  parcimonie xloadimage scdaemon glibc-doc sensible-utils git bzr gdbm-l10n\n",
      "  krb5-doc krb5-user libsasl2-modules-gssapi-mit\n",
      "  | libsasl2-modules-gssapi-heimdal libsasl2-modules-ldap libsasl2-modules-otp\n",
      "  libsasl2-modules-sql libstdc++-8-doc make-doc man-browser ed diffutils-doc\n",
      "  perl-doc libterm-readline-gnu-perl | libterm-readline-perl-perl\n",
      "  libb-debug-perl liblocale-codes-perl pinentry-doc python-doc python-tk\n",
      "  python-psutil-doc python2-doc python2.7-doc binfmt-support python3-doc\n",
      "  python3-tk python3-venv python-crypto-doc python-cryptography-doc\n",
      "  python3-cryptography-vectors python-dbus-doc python3-dbus-dbg gnome-keyring\n",
      "  libkf5wallet-bin gir1.2-gnomekeyring-1.0 python-secretstorage-doc\n",
      "  python-setuptools-doc python3.7-venv python3.7-doc readline-doc zip\n",
      "The following NEW packages will be installed:\n",
      "  binutils binutils-common binutils-x86-64-linux-gnu build-essential bzip2 cpp\n",
      "  cpp-8 curl dbus dh-python dirmngr dpkg-dev fakeroot file g++ g++-8 gcc gcc-8\n",
      "  gir1.2-glib-2.0 gnupg gnupg-l10n gnupg-utils gpg gpg-agent gpg-wks-client\n",
      "  gpg-wks-server gpgconf gpgsm krb5-locales libalgorithm-diff-perl\n",
      "  libalgorithm-diff-xs-perl libalgorithm-merge-perl libapparmor1 libasan5\n",
      "  libassuan0 libatomic1 libbinutils libc-dev-bin libc6-dev libcc1-0 libcurl4\n",
      "  libdbus-1-3 libdpkg-perl libexpat1 libexpat1-dev libfakeroot\n",
      "  libfile-fcntllock-perl libgcc-8-dev libgdbm-compat4 libgdbm6\n",
      "  libgirepository-1.0-1 libglib2.0-0 libglib2.0-data libgomp1 libgssapi-krb5-2\n",
      "  libicu63 libisl19 libitm1 libk5crypto3 libkeyutils1 libkrb5-3\n",
      "  libkrb5support0 libksba8 libldap-2.4-2 libldap-common liblocale-gettext-perl\n",
      "  liblsan0 libmagic-mgc libmagic1 libmpc3 libmpdec2 libmpfr6 libmpx2\n",
      "  libnghttp2-14 libnpth0 libperl5.28 libpsl5 libpython-dev libpython-stdlib\n",
      "  libpython2-dev libpython2-stdlib libpython2.7 libpython2.7-dev\n",
      "  libpython2.7-minimal libpython2.7-stdlib libpython3-dev libpython3-stdlib\n",
      "  libpython3.7 libpython3.7-dev libpython3.7-minimal libpython3.7-stdlib\n",
      "  libquadmath0 libreadline7 librtmp1 libsasl2-2 libsasl2-modules\n",
      "  libsasl2-modules-db libsqlite3-0 libssh2-1 libstdc++-8-dev libtsan0\n",
      "  libubsan1 libxml2 linux-libc-dev make manpages manpages-dev mime-support\n",
      "  netbase patch perl perl-modules-5.28 pinentry-curses publicsuffix python\n",
      "  python-dev python-minimal python-pip-whl python-psutil python2 python2-dev\n",
      "  python2-minimal python2.7 python2.7-dev python2.7-minimal python3\n",
      "  python3-asn1crypto python3-cffi-backend python3-crypto python3-cryptography\n",
      "  python3-dbus python3-dev python3-distutils python3-entrypoints python3-gi\n",
      "  python3-keyring python3-keyrings.alt python3-lib2to3 python3-minimal\n",
      "  python3-pip python3-pkg-resources python3-secretstorage python3-setuptools\n",
      "  python3-six python3-wheel python3-xdg python3.7 python3.7-dev\n",
      "  python3.7-minimal readline-common shared-mime-info unzip xdg-user-dirs\n",
      "  xz-utils\n",
      "0 upgraded, 154 newly installed, 0 to remove and 0 not upgraded.\n",
      "Need to get 178 MB of archives.\n",
      "After this operation, 521 MB of additional disk space will be used.\n",
      "Get:1 http://deb.debian.org/debian buster/main amd64 perl-modules-5.28 all 5.28.1-6+deb10u1 [2873 kB]\n",
      "Get:2 http://deb.debian.org/debian buster/main amd64 libgdbm6 amd64 1.18.1-4 [64.7 kB]\n",
      "Get:3 http://deb.debian.org/debian buster/main amd64 libgdbm-compat4 amd64 1.18.1-4 [44.1 kB]\n",
      "Get:4 http://deb.debian.org/debian buster/main amd64 libperl5.28 amd64 5.28.1-6+deb10u1 [3894 kB]\n",
      "Get:5 http://deb.debian.org/debian buster/main amd64 perl amd64 5.28.1-6+deb10u1 [204 kB]\n",
      "Get:6 http://deb.debian.org/debian buster/main amd64 libpython2.7-minimal amd64 2.7.16-2+deb10u1 [395 kB]\n",
      "Get:7 http://deb.debian.org/debian buster/main amd64 python2.7-minimal amd64 2.7.16-2+deb10u1 [1369 kB]\n",
      "Get:8 http://deb.debian.org/debian buster/main amd64 python2-minimal amd64 2.7.16-1 [41.4 kB]\n",
      "Get:9 http://deb.debian.org/debian buster/main amd64 python-minimal amd64 2.7.16-1 [21.0 kB]\n",
      "Get:10 http://deb.debian.org/debian buster/main amd64 mime-support all 3.62 [37.2 kB]\n",
      "Get:11 http://deb.debian.org/debian buster/main amd64 libexpat1 amd64 2.2.6-2+deb10u1 [106 kB]\n",
      "Get:12 http://deb.debian.org/debian buster/main amd64 readline-common all 7.0-5 [70.6 kB]\n",
      "Get:13 http://deb.debian.org/debian buster/main amd64 libreadline7 amd64 7.0-5 [151 kB]\n",
      "Get:14 http://deb.debian.org/debian buster/main amd64 libsqlite3-0 amd64 3.27.2-3 [641 kB]\n",
      "Get:15 http://deb.debian.org/debian buster/main amd64 libpython2.7-stdlib amd64 2.7.16-2+deb10u1 [1912 kB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:16 http://deb.debian.org/debian buster/main amd64 python2.7 amd64 2.7.16-2+deb10u1 [305 kB]\n",
      "Get:17 http://deb.debian.org/debian buster/main amd64 libpython2-stdlib amd64 2.7.16-1 [20.8 kB]\n",
      "Get:18 http://deb.debian.org/debian buster/main amd64 libpython-stdlib amd64 2.7.16-1 [20.8 kB]\n",
      "Get:19 http://deb.debian.org/debian buster/main amd64 python2 amd64 2.7.16-1 [41.6 kB]\n",
      "Get:20 http://deb.debian.org/debian buster/main amd64 python amd64 2.7.16-1 [22.8 kB]\n",
      "Get:21 http://deb.debian.org/debian buster/main amd64 liblocale-gettext-perl amd64 1.07-3+b4 [18.9 kB]\n",
      "Get:22 http://deb.debian.org/debian buster/main amd64 libpython3.7-minimal amd64 3.7.3-2+deb10u2 [589 kB]\n",
      "Get:23 http://deb.debian.org/debian buster/main amd64 python3.7-minimal amd64 3.7.3-2+deb10u2 [1731 kB]\n",
      "Get:24 http://deb.debian.org/debian buster/main amd64 python3-minimal amd64 3.7.3-1 [36.6 kB]\n",
      "Get:25 http://deb.debian.org/debian buster/main amd64 libmpdec2 amd64 2.4.2-2 [87.2 kB]\n",
      "Get:26 http://deb.debian.org/debian buster/main amd64 libpython3.7-stdlib amd64 3.7.3-2+deb10u2 [1732 kB]\n",
      "Get:27 http://deb.debian.org/debian buster/main amd64 python3.7 amd64 3.7.3-2+deb10u2 [330 kB]\n",
      "Get:28 http://deb.debian.org/debian buster/main amd64 libpython3-stdlib amd64 3.7.3-1 [20.0 kB]\n",
      "Get:29 http://deb.debian.org/debian buster/main amd64 python3 amd64 3.7.3-1 [61.5 kB]\n",
      "Get:30 http://deb.debian.org/debian buster/main amd64 netbase all 5.6 [19.4 kB]\n",
      "Get:31 http://deb.debian.org/debian buster/main amd64 bzip2 amd64 1.0.6-9.2~deb10u1 [48.4 kB]\n",
      "Get:32 http://deb.debian.org/debian buster/main amd64 libapparmor1 amd64 2.13.2-10 [94.7 kB]\n",
      "Get:33 http://deb.debian.org/debian buster/main amd64 libdbus-1-3 amd64 1.12.20-0+deb10u1 [215 kB]\n",
      "Get:34 http://deb.debian.org/debian buster/main amd64 dbus amd64 1.12.20-0+deb10u1 [236 kB]\n",
      "Get:35 http://deb.debian.org/debian buster/main amd64 libmagic-mgc amd64 1:5.35-4+deb10u1 [242 kB]\n",
      "Get:36 http://deb.debian.org/debian buster/main amd64 libmagic1 amd64 1:5.35-4+deb10u1 [117 kB]\n",
      "Get:37 http://deb.debian.org/debian buster/main amd64 file amd64 1:5.35-4+deb10u1 [66.4 kB]\n",
      "Get:38 http://deb.debian.org/debian buster/main amd64 krb5-locales all 1.17-3 [95.4 kB]\n",
      "Get:39 http://deb.debian.org/debian buster/main amd64 manpages all 4.16-2 [1295 kB]\n",
      "Get:40 http://deb.debian.org/debian buster/main amd64 xz-utils amd64 5.2.4-1 [183 kB]\n",
      "Get:41 http://deb.debian.org/debian buster/main amd64 binutils-common amd64 2.31.1-16 [2073 kB]\n",
      "Get:42 http://deb.debian.org/debian buster/main amd64 libbinutils amd64 2.31.1-16 [478 kB]\n",
      "Get:43 http://deb.debian.org/debian buster/main amd64 binutils-x86-64-linux-gnu amd64 2.31.1-16 [1823 kB]\n",
      "Get:44 http://deb.debian.org/debian buster/main amd64 binutils amd64 2.31.1-16 [56.8 kB]\n",
      "Get:45 http://deb.debian.org/debian buster/main amd64 libc-dev-bin amd64 2.28-10 [275 kB]\n",
      "Get:46 http://deb.debian.org/debian buster/main amd64 linux-libc-dev amd64 4.19.132-1 [1376 kB]\n",
      "Get:47 http://deb.debian.org/debian buster/main amd64 libc6-dev amd64 2.28-10 [2691 kB]\n",
      "Get:48 http://deb.debian.org/debian buster/main amd64 libisl19 amd64 0.20-2 [587 kB]\n",
      "Get:49 http://deb.debian.org/debian buster/main amd64 libmpfr6 amd64 4.0.2-1 [775 kB]\n",
      "Get:50 http://deb.debian.org/debian buster/main amd64 libmpc3 amd64 1.1.0-1 [41.3 kB]\n",
      "Get:51 http://deb.debian.org/debian buster/main amd64 cpp-8 amd64 8.3.0-6 [8914 kB]\n",
      "Get:52 http://deb.debian.org/debian buster/main amd64 cpp amd64 4:8.3.0-1 [19.4 kB]\n",
      "Get:53 http://deb.debian.org/debian buster/main amd64 libcc1-0 amd64 8.3.0-6 [46.6 kB]\n",
      "Get:54 http://deb.debian.org/debian buster/main amd64 libgomp1 amd64 8.3.0-6 [75.8 kB]\n",
      "Get:55 http://deb.debian.org/debian buster/main amd64 libitm1 amd64 8.3.0-6 [27.7 kB]\n",
      "Get:56 http://deb.debian.org/debian buster/main amd64 libatomic1 amd64 8.3.0-6 [9032 B]\n",
      "Get:57 http://deb.debian.org/debian buster/main amd64 libasan5 amd64 8.3.0-6 [362 kB]\n",
      "Get:58 http://deb.debian.org/debian buster/main amd64 liblsan0 amd64 8.3.0-6 [131 kB]\n",
      "Get:59 http://deb.debian.org/debian buster/main amd64 libtsan0 amd64 8.3.0-6 [283 kB]\n",
      "Get:60 http://deb.debian.org/debian buster/main amd64 libubsan1 amd64 8.3.0-6 [120 kB]\n",
      "Get:61 http://deb.debian.org/debian buster/main amd64 libmpx2 amd64 8.3.0-6 [11.4 kB]\n",
      "Get:62 http://deb.debian.org/debian buster/main amd64 libquadmath0 amd64 8.3.0-6 [133 kB]\n",
      "Get:63 http://deb.debian.org/debian buster/main amd64 libgcc-8-dev amd64 8.3.0-6 [2298 kB]\n",
      "Get:64 http://deb.debian.org/debian buster/main amd64 gcc-8 amd64 8.3.0-6 [9452 kB]\n",
      "Get:65 http://deb.debian.org/debian buster/main amd64 gcc amd64 4:8.3.0-1 [5196 B]\n",
      "Get:66 http://deb.debian.org/debian buster/main amd64 libstdc++-8-dev amd64 8.3.0-6 [1532 kB]\n",
      "Get:67 http://deb.debian.org/debian buster/main amd64 g++-8 amd64 8.3.0-6 [9752 kB]\n",
      "Get:68 http://deb.debian.org/debian buster/main amd64 g++ amd64 4:8.3.0-1 [1644 B]\n",
      "Get:69 http://deb.debian.org/debian buster/main amd64 make amd64 4.2.1-1.2 [341 kB]\n",
      "Get:70 http://deb.debian.org/debian buster/main amd64 libdpkg-perl all 1.19.7 [1414 kB]\n",
      "Get:71 http://deb.debian.org/debian buster/main amd64 patch amd64 2.7.6-3+deb10u1 [126 kB]\n",
      "Get:72 http://deb.debian.org/debian buster/main amd64 dpkg-dev all 1.19.7 [1773 kB]\n",
      "Get:73 http://deb.debian.org/debian buster/main amd64 build-essential amd64 12.6 [7576 B]\n",
      "Get:74 http://deb.debian.org/debian buster/main amd64 libkeyutils1 amd64 1.6-6 [15.0 kB]\n",
      "Get:75 http://deb.debian.org/debian buster/main amd64 libkrb5support0 amd64 1.17-3 [65.6 kB]\n",
      "Get:76 http://deb.debian.org/debian buster/main amd64 libk5crypto3 amd64 1.17-3 [121 kB]\n",
      "Get:77 http://deb.debian.org/debian buster/main amd64 libkrb5-3 amd64 1.17-3 [370 kB]\n",
      "Get:78 http://deb.debian.org/debian buster/main amd64 libgssapi-krb5-2 amd64 1.17-3 [158 kB]\n",
      "Get:79 http://deb.debian.org/debian buster/main amd64 libsasl2-modules-db amd64 2.1.27+dfsg-1+deb10u1 [69.1 kB]\n",
      "Get:80 http://deb.debian.org/debian buster/main amd64 libsasl2-2 amd64 2.1.27+dfsg-1+deb10u1 [106 kB]\n",
      "Get:81 http://deb.debian.org/debian buster/main amd64 libldap-common all 2.4.47+dfsg-3+deb10u2 [89.7 kB]\n",
      "Get:82 http://deb.debian.org/debian buster/main amd64 libldap-2.4-2 amd64 2.4.47+dfsg-3+deb10u2 [224 kB]\n",
      "Get:83 http://deb.debian.org/debian buster/main amd64 libnghttp2-14 amd64 1.36.0-2+deb10u1 [85.0 kB]\n",
      "Get:84 http://deb.debian.org/debian buster/main amd64 libpsl5 amd64 0.20.2-2 [53.7 kB]\n",
      "Get:85 http://deb.debian.org/debian buster/main amd64 librtmp1 amd64 2.4+20151223.gitfa8646d.1-2 [60.5 kB]\n",
      "Get:86 http://deb.debian.org/debian buster/main amd64 libssh2-1 amd64 1.8.0-2.1 [140 kB]\n",
      "Get:87 http://deb.debian.org/debian buster/main amd64 libcurl4 amd64 7.64.0-4+deb10u1 [331 kB]\n",
      "Get:88 http://deb.debian.org/debian buster/main amd64 curl amd64 7.64.0-4+deb10u1 [264 kB]\n",
      "Get:89 http://deb.debian.org/debian buster/main amd64 python3-lib2to3 all 3.7.3-1 [76.7 kB]\n",
      "Get:90 http://deb.debian.org/debian buster/main amd64 python3-distutils all 3.7.3-1 [142 kB]\n",
      "Get:91 http://deb.debian.org/debian buster/main amd64 dh-python all 3.20190308 [99.3 kB]\n",
      "Get:92 http://deb.debian.org/debian buster/main amd64 libassuan0 amd64 2.5.2-1 [49.4 kB]\n",
      "Get:93 http://deb.debian.org/debian buster/main amd64 gpgconf amd64 2.2.12-1+deb10u1 [510 kB]\n",
      "Get:94 http://deb.debian.org/debian buster/main amd64 libksba8 amd64 1.3.5-2 [99.7 kB]\n",
      "Get:95 http://deb.debian.org/debian buster/main amd64 libnpth0 amd64 1.6-1 [18.4 kB]\n",
      "Get:96 http://deb.debian.org/debian buster/main amd64 dirmngr amd64 2.2.12-1+deb10u1 [712 kB]\n",
      "Get:97 http://deb.debian.org/debian buster/main amd64 libfakeroot amd64 1.23-1 [45.9 kB]\n",
      "Get:98 http://deb.debian.org/debian buster/main amd64 fakeroot amd64 1.23-1 [85.8 kB]\n",
      "Get:99 http://deb.debian.org/debian buster/main amd64 libglib2.0-0 amd64 2.58.3-2+deb10u2 [1258 kB]\n",
      "Get:100 http://deb.debian.org/debian buster/main amd64 libgirepository-1.0-1 amd64 1.58.3-2 [92.8 kB]\n",
      "Get:101 http://deb.debian.org/debian buster/main amd64 gir1.2-glib-2.0 amd64 1.58.3-2 [143 kB]\n",
      "Get:102 http://deb.debian.org/debian buster/main amd64 gnupg-l10n all 2.2.12-1+deb10u1 [1010 kB]\n",
      "Get:103 http://deb.debian.org/debian buster/main amd64 gnupg-utils amd64 2.2.12-1+deb10u1 [861 kB]\n",
      "Get:104 http://deb.debian.org/debian buster/main amd64 gpg amd64 2.2.12-1+deb10u1 [865 kB]\n",
      "Get:105 http://deb.debian.org/debian buster/main amd64 pinentry-curses amd64 1.1.0-2 [64.5 kB]\n",
      "Get:106 http://deb.debian.org/debian buster/main amd64 gpg-agent amd64 2.2.12-1+deb10u1 [617 kB]\n",
      "Get:107 http://deb.debian.org/debian buster/main amd64 gpg-wks-client amd64 2.2.12-1+deb10u1 [485 kB]\n",
      "Get:108 http://deb.debian.org/debian buster/main amd64 gpg-wks-server amd64 2.2.12-1+deb10u1 [478 kB]\n",
      "Get:109 http://deb.debian.org/debian buster/main amd64 gpgsm amd64 2.2.12-1+deb10u1 [604 kB]\n",
      "Get:110 http://deb.debian.org/debian buster/main amd64 gnupg all 2.2.12-1+deb10u1 [715 kB]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Get:111 http://deb.debian.org/debian buster/main amd64 libalgorithm-diff-perl all 1.19.03-2 [47.9 kB]\n",
      "Get:112 http://deb.debian.org/debian buster/main amd64 libalgorithm-diff-xs-perl amd64 0.04-5+b1 [11.8 kB]\n",
      "Get:113 http://deb.debian.org/debian buster/main amd64 libalgorithm-merge-perl all 0.08-3 [12.7 kB]\n",
      "Get:114 http://deb.debian.org/debian buster/main amd64 libexpat1-dev amd64 2.2.6-2+deb10u1 [153 kB]\n",
      "Get:115 http://deb.debian.org/debian buster/main amd64 libfile-fcntllock-perl amd64 0.22-3+b5 [35.4 kB]\n",
      "Get:116 http://deb.debian.org/debian buster/main amd64 libglib2.0-data all 2.58.3-2+deb10u2 [1110 kB]\n",
      "Get:117 http://deb.debian.org/debian buster/main amd64 libicu63 amd64 63.1-6+deb10u1 [8300 kB]\n",
      "Get:118 http://deb.debian.org/debian buster/main amd64 libpython2.7 amd64 2.7.16-2+deb10u1 [1036 kB]\n",
      "Get:119 http://deb.debian.org/debian buster/main amd64 libpython2.7-dev amd64 2.7.16-2+deb10u1 [31.6 MB]\n",
      "Get:120 http://deb.debian.org/debian buster/main amd64 libpython2-dev amd64 2.7.16-1 [20.9 kB]\n",
      "Get:121 http://deb.debian.org/debian buster/main amd64 libpython-dev amd64 2.7.16-1 [20.9 kB]\n",
      "Get:122 http://deb.debian.org/debian buster/main amd64 libpython3.7 amd64 3.7.3-2+deb10u2 [1498 kB]\n",
      "Get:123 http://deb.debian.org/debian buster/main amd64 libpython3.7-dev amd64 3.7.3-2+deb10u2 [48.4 MB]\n",
      "Get:124 http://deb.debian.org/debian buster/main amd64 libpython3-dev amd64 3.7.3-1 [20.1 kB]\n",
      "Get:125 http://deb.debian.org/debian buster/main amd64 libsasl2-modules amd64 2.1.27+dfsg-1+deb10u1 [104 kB]\n",
      "Get:126 http://deb.debian.org/debian buster/main amd64 libxml2 amd64 2.9.4+dfsg1-7+b3 [687 kB]\n",
      "Get:127 http://deb.debian.org/debian buster/main amd64 manpages-dev all 4.16-2 [2232 kB]\n",
      "Get:128 http://deb.debian.org/debian buster/main amd64 publicsuffix all 20190415.1030-1 [116 kB]\n",
      "Get:129 http://deb.debian.org/debian buster/main amd64 python2.7-dev amd64 2.7.16-2+deb10u1 [294 kB]\n",
      "Get:130 http://deb.debian.org/debian buster/main amd64 python2-dev amd64 2.7.16-1 [1212 B]\n",
      "Get:131 http://deb.debian.org/debian buster/main amd64 python-dev amd64 2.7.16-1 [1192 B]\n",
      "Get:132 http://deb.debian.org/debian buster/main amd64 python-pip-whl all 18.1-5 [1591 kB]\n",
      "Get:133 http://deb.debian.org/debian buster/main amd64 python-psutil amd64 5.5.1-1 [166 kB]\n",
      "Get:134 http://deb.debian.org/debian buster/main amd64 python3-asn1crypto all 0.24.0-1 [78.2 kB]\n",
      "Get:135 http://deb.debian.org/debian buster/main amd64 python3-cffi-backend amd64 1.12.2-1 [79.7 kB]\n",
      "Get:136 http://deb.debian.org/debian buster/main amd64 python3-crypto amd64 2.6.1-9+b1 [263 kB]\n",
      "Get:137 http://deb.debian.org/debian buster/main amd64 python3-six all 1.12.0-1 [15.7 kB]\n",
      "Get:138 http://deb.debian.org/debian buster/main amd64 python3-cryptography amd64 2.6.1-3+deb10u2 [219 kB]\n",
      "Get:139 http://deb.debian.org/debian buster/main amd64 python3-dbus amd64 1.2.8-3 [103 kB]\n",
      "Get:140 http://deb.debian.org/debian buster/main amd64 python3.7-dev amd64 3.7.3-2+deb10u2 [510 kB]\n",
      "Get:141 http://deb.debian.org/debian buster/main amd64 python3-dev amd64 3.7.3-1 [1264 B]\n",
      "Get:142 http://deb.debian.org/debian buster/main amd64 python3-entrypoints all 0.3-1 [5508 B]\n",
      "Get:143 http://deb.debian.org/debian buster/main amd64 python3-gi amd64 3.30.4-1 [180 kB]\n",
      "Get:144 http://deb.debian.org/debian buster/main amd64 python3-secretstorage all 2.3.1-2 [14.2 kB]\n",
      "Get:145 http://deb.debian.org/debian buster/main amd64 python3-keyring all 17.1.1-1 [43.1 kB]\n",
      "Get:146 http://deb.debian.org/debian buster/main amd64 python3-keyrings.alt all 3.1.1-1 [18.2 kB]\n",
      "Get:147 http://deb.debian.org/debian buster/main amd64 python3-pip all 18.1-5 [171 kB]\n",
      "Get:148 http://deb.debian.org/debian buster/main amd64 python3-pkg-resources all 40.8.0-1 [153 kB]\n",
      "Get:149 http://deb.debian.org/debian buster/main amd64 python3-setuptools all 40.8.0-1 [306 kB]\n",
      "Get:150 http://deb.debian.org/debian buster/main amd64 python3-wheel all 0.32.3-2 [19.4 kB]\n",
      "Get:151 http://deb.debian.org/debian buster/main amd64 python3-xdg all 0.25-5 [35.9 kB]\n",
      "Get:152 http://deb.debian.org/debian buster/main amd64 shared-mime-info amd64 1.10-1 [766 kB]\n",
      "Get:153 http://deb.debian.org/debian buster/main amd64 unzip amd64 6.0-23+deb10u1 [172 kB]\n",
      "Get:154 http://deb.debian.org/debian buster/main amd64 xdg-user-dirs amd64 0.17-2 [53.8 kB]\n",
      "\u001b[91mdebconf: delaying package configuration, since apt-utils is not installed\n",
      "\u001b[0mFetched 178 MB in 2s (90.9 MB/s)\n",
      "Selecting previously unselected package perl-modules-5.28.\n",
      "(Reading database ... 6889 files and directories currently installed.)\n",
      "Preparing to unpack .../00-perl-modules-5.28_5.28.1-6+deb10u1_all.deb ...\n",
      "Unpacking perl-modules-5.28 (5.28.1-6+deb10u1) ...\n",
      "Selecting previously unselected package libgdbm6:amd64.\n",
      "Preparing to unpack .../01-libgdbm6_1.18.1-4_amd64.deb ...\n",
      "Unpacking libgdbm6:amd64 (1.18.1-4) ...\n",
      "Selecting previously unselected package libgdbm-compat4:amd64.\n",
      "Preparing to unpack .../02-libgdbm-compat4_1.18.1-4_amd64.deb ...\n",
      "Unpacking libgdbm-compat4:amd64 (1.18.1-4) ...\n",
      "Selecting previously unselected package libperl5.28:amd64.\n",
      "Preparing to unpack .../03-libperl5.28_5.28.1-6+deb10u1_amd64.deb ...\n",
      "Unpacking libperl5.28:amd64 (5.28.1-6+deb10u1) ...\n",
      "Selecting previously unselected package perl.\n",
      "Preparing to unpack .../04-perl_5.28.1-6+deb10u1_amd64.deb ...\n",
      "Unpacking perl (5.28.1-6+deb10u1) ...\n",
      "Selecting previously unselected package libpython2.7-minimal:amd64.\n",
      "Preparing to unpack .../05-libpython2.7-minimal_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking libpython2.7-minimal:amd64 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package python2.7-minimal.\n",
      "Preparing to unpack .../06-python2.7-minimal_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking python2.7-minimal (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package python2-minimal.\n",
      "Preparing to unpack .../07-python2-minimal_2.7.16-1_amd64.deb ...\n",
      "Unpacking python2-minimal (2.7.16-1) ...\n",
      "Selecting previously unselected package python-minimal.\n",
      "Preparing to unpack .../08-python-minimal_2.7.16-1_amd64.deb ...\n",
      "Unpacking python-minimal (2.7.16-1) ...\n",
      "Selecting previously unselected package mime-support.\n",
      "Preparing to unpack .../09-mime-support_3.62_all.deb ...\n",
      "Unpacking mime-support (3.62) ...\n",
      "Selecting previously unselected package libexpat1:amd64.\n",
      "Preparing to unpack .../10-libexpat1_2.2.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libexpat1:amd64 (2.2.6-2+deb10u1) ...\n",
      "Selecting previously unselected package readline-common.\n",
      "Preparing to unpack .../11-readline-common_7.0-5_all.deb ...\n",
      "Unpacking readline-common (7.0-5) ...\n",
      "Selecting previously unselected package libreadline7:amd64.\n",
      "Preparing to unpack .../12-libreadline7_7.0-5_amd64.deb ...\n",
      "Unpacking libreadline7:amd64 (7.0-5) ...\n",
      "Selecting previously unselected package libsqlite3-0:amd64.\n",
      "Preparing to unpack .../13-libsqlite3-0_3.27.2-3_amd64.deb ...\n",
      "Unpacking libsqlite3-0:amd64 (3.27.2-3) ...\n",
      "Selecting previously unselected package libpython2.7-stdlib:amd64.\n",
      "Preparing to unpack .../14-libpython2.7-stdlib_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking libpython2.7-stdlib:amd64 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package python2.7.\n",
      "Preparing to unpack .../15-python2.7_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking python2.7 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package libpython2-stdlib:amd64.\n",
      "Preparing to unpack .../16-libpython2-stdlib_2.7.16-1_amd64.deb ...\n",
      "Unpacking libpython2-stdlib:amd64 (2.7.16-1) ...\n",
      "Selecting previously unselected package libpython-stdlib:amd64.\n",
      "Preparing to unpack .../17-libpython-stdlib_2.7.16-1_amd64.deb ...\n",
      "Unpacking libpython-stdlib:amd64 (2.7.16-1) ...\n",
      "Setting up libpython2.7-minimal:amd64 (2.7.16-2+deb10u1) ...\n",
      "Setting up python2.7-minimal (2.7.16-2+deb10u1) ...\n",
      "Linking and byte-compiling packages for runtime python2.7...\n",
      "Setting up python2-minimal (2.7.16-1) ...\n",
      "Selecting previously unselected package python2.\n",
      "(Reading database ... 9661 files and directories currently installed.)\n",
      "Preparing to unpack .../python2_2.7.16-1_amd64.deb ...\n",
      "Unpacking python2 (2.7.16-1) ...\n",
      "Setting up python-minimal (2.7.16-1) ...\n",
      "Selecting previously unselected package python.\n",
      "(Reading database ... 9694 files and directories currently installed.)\n",
      "Preparing to unpack .../python_2.7.16-1_amd64.deb ...\n",
      "Unpacking python (2.7.16-1) ...\n",
      "Selecting previously unselected package liblocale-gettext-perl.\n",
      "Preparing to unpack .../liblocale-gettext-perl_1.07-3+b4_amd64.deb ...\n",
      "Unpacking liblocale-gettext-perl (1.07-3+b4) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libpython3.7-minimal:amd64.\n",
      "Preparing to unpack .../libpython3.7-minimal_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libpython3.7-minimal:amd64 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package python3.7-minimal.\n",
      "Preparing to unpack .../python3.7-minimal_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking python3.7-minimal (3.7.3-2+deb10u2) ...\n",
      "Setting up libpython3.7-minimal:amd64 (3.7.3-2+deb10u2) ...\n",
      "Setting up libexpat1:amd64 (2.2.6-2+deb10u1) ...\n",
      "Setting up python3.7-minimal (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package python3-minimal.\n",
      "(Reading database ... 9963 files and directories currently installed.)\n",
      "Preparing to unpack .../python3-minimal_3.7.3-1_amd64.deb ...\n",
      "Unpacking python3-minimal (3.7.3-1) ...\n",
      "Selecting previously unselected package libmpdec2:amd64.\n",
      "Preparing to unpack .../libmpdec2_2.4.2-2_amd64.deb ...\n",
      "Unpacking libmpdec2:amd64 (2.4.2-2) ...\n",
      "Selecting previously unselected package libpython3.7-stdlib:amd64.\n",
      "Preparing to unpack .../libpython3.7-stdlib_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libpython3.7-stdlib:amd64 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package python3.7.\n",
      "Preparing to unpack .../python3.7_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking python3.7 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libpython3-stdlib:amd64.\n",
      "Preparing to unpack .../libpython3-stdlib_3.7.3-1_amd64.deb ...\n",
      "Unpacking libpython3-stdlib:amd64 (3.7.3-1) ...\n",
      "Setting up python3-minimal (3.7.3-1) ...\n",
      "Selecting previously unselected package python3.\n",
      "(Reading database ... 10375 files and directories currently installed.)\n",
      "Preparing to unpack .../000-python3_3.7.3-1_amd64.deb ...\n",
      "Unpacking python3 (3.7.3-1) ...\n",
      "Selecting previously unselected package netbase.\n",
      "Preparing to unpack .../001-netbase_5.6_all.deb ...\n",
      "Unpacking netbase (5.6) ...\n",
      "Selecting previously unselected package bzip2.\n",
      "Preparing to unpack .../002-bzip2_1.0.6-9.2~deb10u1_amd64.deb ...\n",
      "Unpacking bzip2 (1.0.6-9.2~deb10u1) ...\n",
      "Selecting previously unselected package libapparmor1:amd64.\n",
      "Preparing to unpack .../003-libapparmor1_2.13.2-10_amd64.deb ...\n",
      "Unpacking libapparmor1:amd64 (2.13.2-10) ...\n",
      "Selecting previously unselected package libdbus-1-3:amd64.\n",
      "Preparing to unpack .../004-libdbus-1-3_1.12.20-0+deb10u1_amd64.deb ...\n",
      "Unpacking libdbus-1-3:amd64 (1.12.20-0+deb10u1) ...\n",
      "Selecting previously unselected package dbus.\n",
      "Preparing to unpack .../005-dbus_1.12.20-0+deb10u1_amd64.deb ...\n",
      "Unpacking dbus (1.12.20-0+deb10u1) ...\n",
      "Selecting previously unselected package libmagic-mgc.\n",
      "Preparing to unpack .../006-libmagic-mgc_1%3a5.35-4+deb10u1_amd64.deb ...\n",
      "Unpacking libmagic-mgc (1:5.35-4+deb10u1) ...\n",
      "Selecting previously unselected package libmagic1:amd64.\n",
      "Preparing to unpack .../007-libmagic1_1%3a5.35-4+deb10u1_amd64.deb ...\n",
      "Unpacking libmagic1:amd64 (1:5.35-4+deb10u1) ...\n",
      "Selecting previously unselected package file.\n",
      "Preparing to unpack .../008-file_1%3a5.35-4+deb10u1_amd64.deb ...\n",
      "Unpacking file (1:5.35-4+deb10u1) ...\n",
      "Selecting previously unselected package krb5-locales.\n",
      "Preparing to unpack .../009-krb5-locales_1.17-3_all.deb ...\n",
      "Unpacking krb5-locales (1.17-3) ...\n",
      "Selecting previously unselected package manpages.\n",
      "Preparing to unpack .../010-manpages_4.16-2_all.deb ...\n",
      "Unpacking manpages (4.16-2) ...\n",
      "Selecting previously unselected package xz-utils.\n",
      "Preparing to unpack .../011-xz-utils_5.2.4-1_amd64.deb ...\n",
      "Unpacking xz-utils (5.2.4-1) ...\n",
      "Selecting previously unselected package binutils-common:amd64.\n",
      "Preparing to unpack .../012-binutils-common_2.31.1-16_amd64.deb ...\n",
      "Unpacking binutils-common:amd64 (2.31.1-16) ...\n",
      "Selecting previously unselected package libbinutils:amd64.\n",
      "Preparing to unpack .../013-libbinutils_2.31.1-16_amd64.deb ...\n",
      "Unpacking libbinutils:amd64 (2.31.1-16) ...\n",
      "Selecting previously unselected package binutils-x86-64-linux-gnu.\n",
      "Preparing to unpack .../014-binutils-x86-64-linux-gnu_2.31.1-16_amd64.deb ...\n",
      "Unpacking binutils-x86-64-linux-gnu (2.31.1-16) ...\n",
      "Selecting previously unselected package binutils.\n",
      "Preparing to unpack .../015-binutils_2.31.1-16_amd64.deb ...\n",
      "Unpacking binutils (2.31.1-16) ...\n",
      "Selecting previously unselected package libc-dev-bin.\n",
      "Preparing to unpack .../016-libc-dev-bin_2.28-10_amd64.deb ...\n",
      "Unpacking libc-dev-bin (2.28-10) ...\n",
      "Selecting previously unselected package linux-libc-dev:amd64.\n",
      "Preparing to unpack .../017-linux-libc-dev_4.19.132-1_amd64.deb ...\n",
      "Unpacking linux-libc-dev:amd64 (4.19.132-1) ...\n",
      "Selecting previously unselected package libc6-dev:amd64.\n",
      "Preparing to unpack .../018-libc6-dev_2.28-10_amd64.deb ...\n",
      "Unpacking libc6-dev:amd64 (2.28-10) ...\n",
      "Selecting previously unselected package libisl19:amd64.\n",
      "Preparing to unpack .../019-libisl19_0.20-2_amd64.deb ...\n",
      "Unpacking libisl19:amd64 (0.20-2) ...\n",
      "Selecting previously unselected package libmpfr6:amd64.\n",
      "Preparing to unpack .../020-libmpfr6_4.0.2-1_amd64.deb ...\n",
      "Unpacking libmpfr6:amd64 (4.0.2-1) ...\n",
      "Selecting previously unselected package libmpc3:amd64.\n",
      "Preparing to unpack .../021-libmpc3_1.1.0-1_amd64.deb ...\n",
      "Unpacking libmpc3:amd64 (1.1.0-1) ...\n",
      "Selecting previously unselected package cpp-8.\n",
      "Preparing to unpack .../022-cpp-8_8.3.0-6_amd64.deb ...\n",
      "Unpacking cpp-8 (8.3.0-6) ...\n",
      "Selecting previously unselected package cpp.\n",
      "Preparing to unpack .../023-cpp_4%3a8.3.0-1_amd64.deb ...\n",
      "Unpacking cpp (4:8.3.0-1) ...\n",
      "Selecting previously unselected package libcc1-0:amd64.\n",
      "Preparing to unpack .../024-libcc1-0_8.3.0-6_amd64.deb ...\n",
      "Unpacking libcc1-0:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libgomp1:amd64.\n",
      "Preparing to unpack .../025-libgomp1_8.3.0-6_amd64.deb ...\n",
      "Unpacking libgomp1:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libitm1:amd64.\n",
      "Preparing to unpack .../026-libitm1_8.3.0-6_amd64.deb ...\n",
      "Unpacking libitm1:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libatomic1:amd64.\n",
      "Preparing to unpack .../027-libatomic1_8.3.0-6_amd64.deb ...\n",
      "Unpacking libatomic1:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libasan5:amd64.\n",
      "Preparing to unpack .../028-libasan5_8.3.0-6_amd64.deb ...\n",
      "Unpacking libasan5:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package liblsan0:amd64.\n",
      "Preparing to unpack .../029-liblsan0_8.3.0-6_amd64.deb ...\n",
      "Unpacking liblsan0:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libtsan0:amd64.\n",
      "Preparing to unpack .../030-libtsan0_8.3.0-6_amd64.deb ...\n",
      "Unpacking libtsan0:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libubsan1:amd64.\n",
      "Preparing to unpack .../031-libubsan1_8.3.0-6_amd64.deb ...\n",
      "Unpacking libubsan1:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libmpx2:amd64.\n",
      "Preparing to unpack .../032-libmpx2_8.3.0-6_amd64.deb ...\n",
      "Unpacking libmpx2:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libquadmath0:amd64.\n",
      "Preparing to unpack .../033-libquadmath0_8.3.0-6_amd64.deb ...\n",
      "Unpacking libquadmath0:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package libgcc-8-dev:amd64.\n",
      "Preparing to unpack .../034-libgcc-8-dev_8.3.0-6_amd64.deb ...\n",
      "Unpacking libgcc-8-dev:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package gcc-8.\n",
      "Preparing to unpack .../035-gcc-8_8.3.0-6_amd64.deb ...\n",
      "Unpacking gcc-8 (8.3.0-6) ...\n",
      "Selecting previously unselected package gcc.\n",
      "Preparing to unpack .../036-gcc_4%3a8.3.0-1_amd64.deb ...\n",
      "Unpacking gcc (4:8.3.0-1) ...\n",
      "Selecting previously unselected package libstdc++-8-dev:amd64.\n",
      "Preparing to unpack .../037-libstdc++-8-dev_8.3.0-6_amd64.deb ...\n",
      "Unpacking libstdc++-8-dev:amd64 (8.3.0-6) ...\n",
      "Selecting previously unselected package g++-8.\n",
      "Preparing to unpack .../038-g++-8_8.3.0-6_amd64.deb ...\n",
      "Unpacking g++-8 (8.3.0-6) ...\n",
      "Selecting previously unselected package g++.\n",
      "Preparing to unpack .../039-g++_4%3a8.3.0-1_amd64.deb ...\n",
      "Unpacking g++ (4:8.3.0-1) ...\n",
      "Selecting previously unselected package make.\n",
      "Preparing to unpack .../040-make_4.2.1-1.2_amd64.deb ...\n",
      "Unpacking make (4.2.1-1.2) ...\n",
      "Selecting previously unselected package libdpkg-perl.\n",
      "Preparing to unpack .../041-libdpkg-perl_1.19.7_all.deb ...\n",
      "Unpacking libdpkg-perl (1.19.7) ...\n",
      "Selecting previously unselected package patch.\n",
      "Preparing to unpack .../042-patch_2.7.6-3+deb10u1_amd64.deb ...\n",
      "Unpacking patch (2.7.6-3+deb10u1) ...\n",
      "Selecting previously unselected package dpkg-dev.\n",
      "Preparing to unpack .../043-dpkg-dev_1.19.7_all.deb ...\n",
      "Unpacking dpkg-dev (1.19.7) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package build-essential.\n",
      "Preparing to unpack .../044-build-essential_12.6_amd64.deb ...\n",
      "Unpacking build-essential (12.6) ...\n",
      "Selecting previously unselected package libkeyutils1:amd64.\n",
      "Preparing to unpack .../045-libkeyutils1_1.6-6_amd64.deb ...\n",
      "Unpacking libkeyutils1:amd64 (1.6-6) ...\n",
      "Selecting previously unselected package libkrb5support0:amd64.\n",
      "Preparing to unpack .../046-libkrb5support0_1.17-3_amd64.deb ...\n",
      "Unpacking libkrb5support0:amd64 (1.17-3) ...\n",
      "Selecting previously unselected package libk5crypto3:amd64.\n",
      "Preparing to unpack .../047-libk5crypto3_1.17-3_amd64.deb ...\n",
      "Unpacking libk5crypto3:amd64 (1.17-3) ...\n",
      "Selecting previously unselected package libkrb5-3:amd64.\n",
      "Preparing to unpack .../048-libkrb5-3_1.17-3_amd64.deb ...\n",
      "Unpacking libkrb5-3:amd64 (1.17-3) ...\n",
      "Selecting previously unselected package libgssapi-krb5-2:amd64.\n",
      "Preparing to unpack .../049-libgssapi-krb5-2_1.17-3_amd64.deb ...\n",
      "Unpacking libgssapi-krb5-2:amd64 (1.17-3) ...\n",
      "Selecting previously unselected package libsasl2-modules-db:amd64.\n",
      "Preparing to unpack .../050-libsasl2-modules-db_2.1.27+dfsg-1+deb10u1_amd64.deb ...\n",
      "Unpacking libsasl2-modules-db:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Selecting previously unselected package libsasl2-2:amd64.\n",
      "Preparing to unpack .../051-libsasl2-2_2.1.27+dfsg-1+deb10u1_amd64.deb ...\n",
      "Unpacking libsasl2-2:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Selecting previously unselected package libldap-common.\n",
      "Preparing to unpack .../052-libldap-common_2.4.47+dfsg-3+deb10u2_all.deb ...\n",
      "Unpacking libldap-common (2.4.47+dfsg-3+deb10u2) ...\n",
      "Selecting previously unselected package libldap-2.4-2:amd64.\n",
      "Preparing to unpack .../053-libldap-2.4-2_2.4.47+dfsg-3+deb10u2_amd64.deb ...\n",
      "Unpacking libldap-2.4-2:amd64 (2.4.47+dfsg-3+deb10u2) ...\n",
      "Selecting previously unselected package libnghttp2-14:amd64.\n",
      "Preparing to unpack .../054-libnghttp2-14_1.36.0-2+deb10u1_amd64.deb ...\n",
      "Unpacking libnghttp2-14:amd64 (1.36.0-2+deb10u1) ...\n",
      "Selecting previously unselected package libpsl5:amd64.\n",
      "Preparing to unpack .../055-libpsl5_0.20.2-2_amd64.deb ...\n",
      "Unpacking libpsl5:amd64 (0.20.2-2) ...\n",
      "Selecting previously unselected package librtmp1:amd64.\n",
      "Preparing to unpack .../056-librtmp1_2.4+20151223.gitfa8646d.1-2_amd64.deb ...\n",
      "Unpacking librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2) ...\n",
      "Selecting previously unselected package libssh2-1:amd64.\n",
      "Preparing to unpack .../057-libssh2-1_1.8.0-2.1_amd64.deb ...\n",
      "Unpacking libssh2-1:amd64 (1.8.0-2.1) ...\n",
      "Selecting previously unselected package libcurl4:amd64.\n",
      "Preparing to unpack .../058-libcurl4_7.64.0-4+deb10u1_amd64.deb ...\n",
      "Unpacking libcurl4:amd64 (7.64.0-4+deb10u1) ...\n",
      "Selecting previously unselected package curl.\n",
      "Preparing to unpack .../059-curl_7.64.0-4+deb10u1_amd64.deb ...\n",
      "Unpacking curl (7.64.0-4+deb10u1) ...\n",
      "Selecting previously unselected package python3-lib2to3.\n",
      "Preparing to unpack .../060-python3-lib2to3_3.7.3-1_all.deb ...\n",
      "Unpacking python3-lib2to3 (3.7.3-1) ...\n",
      "Selecting previously unselected package python3-distutils.\n",
      "Preparing to unpack .../061-python3-distutils_3.7.3-1_all.deb ...\n",
      "Unpacking python3-distutils (3.7.3-1) ...\n",
      "Selecting previously unselected package dh-python.\n",
      "Preparing to unpack .../062-dh-python_3.20190308_all.deb ...\n",
      "Unpacking dh-python (3.20190308) ...\n",
      "Selecting previously unselected package libassuan0:amd64.\n",
      "Preparing to unpack .../063-libassuan0_2.5.2-1_amd64.deb ...\n",
      "Unpacking libassuan0:amd64 (2.5.2-1) ...\n",
      "Selecting previously unselected package gpgconf.\n",
      "Preparing to unpack .../064-gpgconf_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpgconf (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package libksba8:amd64.\n",
      "Preparing to unpack .../065-libksba8_1.3.5-2_amd64.deb ...\n",
      "Unpacking libksba8:amd64 (1.3.5-2) ...\n",
      "Selecting previously unselected package libnpth0:amd64.\n",
      "Preparing to unpack .../066-libnpth0_1.6-1_amd64.deb ...\n",
      "Unpacking libnpth0:amd64 (1.6-1) ...\n",
      "Selecting previously unselected package dirmngr.\n",
      "Preparing to unpack .../067-dirmngr_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking dirmngr (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package libfakeroot:amd64.\n",
      "Preparing to unpack .../068-libfakeroot_1.23-1_amd64.deb ...\n",
      "Unpacking libfakeroot:amd64 (1.23-1) ...\n",
      "Selecting previously unselected package fakeroot.\n",
      "Preparing to unpack .../069-fakeroot_1.23-1_amd64.deb ...\n",
      "Unpacking fakeroot (1.23-1) ...\n",
      "Selecting previously unselected package libglib2.0-0:amd64.\n",
      "Preparing to unpack .../070-libglib2.0-0_2.58.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libglib2.0-0:amd64 (2.58.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libgirepository-1.0-1:amd64.\n",
      "Preparing to unpack .../071-libgirepository-1.0-1_1.58.3-2_amd64.deb ...\n",
      "Unpacking libgirepository-1.0-1:amd64 (1.58.3-2) ...\n",
      "Selecting previously unselected package gir1.2-glib-2.0:amd64.\n",
      "Preparing to unpack .../072-gir1.2-glib-2.0_1.58.3-2_amd64.deb ...\n",
      "Unpacking gir1.2-glib-2.0:amd64 (1.58.3-2) ...\n",
      "Selecting previously unselected package gnupg-l10n.\n",
      "Preparing to unpack .../073-gnupg-l10n_2.2.12-1+deb10u1_all.deb ...\n",
      "Unpacking gnupg-l10n (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gnupg-utils.\n",
      "Preparing to unpack .../074-gnupg-utils_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gnupg-utils (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gpg.\n",
      "Preparing to unpack .../075-gpg_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpg (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package pinentry-curses.\n",
      "Preparing to unpack .../076-pinentry-curses_1.1.0-2_amd64.deb ...\n",
      "Unpacking pinentry-curses (1.1.0-2) ...\n",
      "Selecting previously unselected package gpg-agent.\n",
      "Preparing to unpack .../077-gpg-agent_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpg-agent (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gpg-wks-client.\n",
      "Preparing to unpack .../078-gpg-wks-client_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpg-wks-client (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gpg-wks-server.\n",
      "Preparing to unpack .../079-gpg-wks-server_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpg-wks-server (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gpgsm.\n",
      "Preparing to unpack .../080-gpgsm_2.2.12-1+deb10u1_amd64.deb ...\n",
      "Unpacking gpgsm (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package gnupg.\n",
      "Preparing to unpack .../081-gnupg_2.2.12-1+deb10u1_all.deb ...\n",
      "Unpacking gnupg (2.2.12-1+deb10u1) ...\n",
      "Selecting previously unselected package libalgorithm-diff-perl.\n",
      "Preparing to unpack .../082-libalgorithm-diff-perl_1.19.03-2_all.deb ...\n",
      "Unpacking libalgorithm-diff-perl (1.19.03-2) ...\n",
      "Selecting previously unselected package libalgorithm-diff-xs-perl.\n",
      "Preparing to unpack .../083-libalgorithm-diff-xs-perl_0.04-5+b1_amd64.deb ...\n",
      "Unpacking libalgorithm-diff-xs-perl (0.04-5+b1) ...\n",
      "Selecting previously unselected package libalgorithm-merge-perl.\n",
      "Preparing to unpack .../084-libalgorithm-merge-perl_0.08-3_all.deb ...\n",
      "Unpacking libalgorithm-merge-perl (0.08-3) ...\n",
      "Selecting previously unselected package libexpat1-dev:amd64.\n",
      "Preparing to unpack .../085-libexpat1-dev_2.2.6-2+deb10u1_amd64.deb ...\n",
      "Unpacking libexpat1-dev:amd64 (2.2.6-2+deb10u1) ...\n",
      "Selecting previously unselected package libfile-fcntllock-perl.\n",
      "Preparing to unpack .../086-libfile-fcntllock-perl_0.22-3+b5_amd64.deb ...\n",
      "Unpacking libfile-fcntllock-perl (0.22-3+b5) ...\n",
      "Selecting previously unselected package libglib2.0-data.\n",
      "Preparing to unpack .../087-libglib2.0-data_2.58.3-2+deb10u2_all.deb ...\n",
      "Unpacking libglib2.0-data (2.58.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libicu63:amd64.\n",
      "Preparing to unpack .../088-libicu63_63.1-6+deb10u1_amd64.deb ...\n",
      "Unpacking libicu63:amd64 (63.1-6+deb10u1) ...\n",
      "Selecting previously unselected package libpython2.7:amd64.\n",
      "Preparing to unpack .../089-libpython2.7_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking libpython2.7:amd64 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package libpython2.7-dev:amd64.\n",
      "Preparing to unpack .../090-libpython2.7-dev_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking libpython2.7-dev:amd64 (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package libpython2-dev:amd64.\n",
      "Preparing to unpack .../091-libpython2-dev_2.7.16-1_amd64.deb ...\n",
      "Unpacking libpython2-dev:amd64 (2.7.16-1) ...\n",
      "Selecting previously unselected package libpython-dev:amd64.\n",
      "Preparing to unpack .../092-libpython-dev_2.7.16-1_amd64.deb ...\n",
      "Unpacking libpython-dev:amd64 (2.7.16-1) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting previously unselected package libpython3.7:amd64.\n",
      "Preparing to unpack .../093-libpython3.7_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libpython3.7:amd64 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libpython3.7-dev:amd64.\n",
      "Preparing to unpack .../094-libpython3.7-dev_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking libpython3.7-dev:amd64 (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package libpython3-dev:amd64.\n",
      "Preparing to unpack .../095-libpython3-dev_3.7.3-1_amd64.deb ...\n",
      "Unpacking libpython3-dev:amd64 (3.7.3-1) ...\n",
      "Selecting previously unselected package libsasl2-modules:amd64.\n",
      "Preparing to unpack .../096-libsasl2-modules_2.1.27+dfsg-1+deb10u1_amd64.deb ...\n",
      "Unpacking libsasl2-modules:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Selecting previously unselected package libxml2:amd64.\n",
      "Preparing to unpack .../097-libxml2_2.9.4+dfsg1-7+b3_amd64.deb ...\n",
      "Unpacking libxml2:amd64 (2.9.4+dfsg1-7+b3) ...\n",
      "Selecting previously unselected package manpages-dev.\n",
      "Preparing to unpack .../098-manpages-dev_4.16-2_all.deb ...\n",
      "Unpacking manpages-dev (4.16-2) ...\n",
      "Selecting previously unselected package publicsuffix.\n",
      "Preparing to unpack .../099-publicsuffix_20190415.1030-1_all.deb ...\n",
      "Unpacking publicsuffix (20190415.1030-1) ...\n",
      "Selecting previously unselected package python2.7-dev.\n",
      "Preparing to unpack .../100-python2.7-dev_2.7.16-2+deb10u1_amd64.deb ...\n",
      "Unpacking python2.7-dev (2.7.16-2+deb10u1) ...\n",
      "Selecting previously unselected package python2-dev.\n",
      "Preparing to unpack .../101-python2-dev_2.7.16-1_amd64.deb ...\n",
      "Unpacking python2-dev (2.7.16-1) ...\n",
      "Selecting previously unselected package python-dev.\n",
      "Preparing to unpack .../102-python-dev_2.7.16-1_amd64.deb ...\n",
      "Unpacking python-dev (2.7.16-1) ...\n",
      "Selecting previously unselected package python-pip-whl.\n",
      "Preparing to unpack .../103-python-pip-whl_18.1-5_all.deb ...\n",
      "Unpacking python-pip-whl (18.1-5) ...\n",
      "Selecting previously unselected package python-psutil.\n",
      "Preparing to unpack .../104-python-psutil_5.5.1-1_amd64.deb ...\n",
      "Unpacking python-psutil (5.5.1-1) ...\n",
      "Selecting previously unselected package python3-asn1crypto.\n",
      "Preparing to unpack .../105-python3-asn1crypto_0.24.0-1_all.deb ...\n",
      "Unpacking python3-asn1crypto (0.24.0-1) ...\n",
      "Selecting previously unselected package python3-cffi-backend.\n",
      "Preparing to unpack .../106-python3-cffi-backend_1.12.2-1_amd64.deb ...\n",
      "Unpacking python3-cffi-backend (1.12.2-1) ...\n",
      "Selecting previously unselected package python3-crypto.\n",
      "Preparing to unpack .../107-python3-crypto_2.6.1-9+b1_amd64.deb ...\n",
      "Unpacking python3-crypto (2.6.1-9+b1) ...\n",
      "Selecting previously unselected package python3-six.\n",
      "Preparing to unpack .../108-python3-six_1.12.0-1_all.deb ...\n",
      "Unpacking python3-six (1.12.0-1) ...\n",
      "Selecting previously unselected package python3-cryptography.\n",
      "Preparing to unpack .../109-python3-cryptography_2.6.1-3+deb10u2_amd64.deb ...\n",
      "Unpacking python3-cryptography (2.6.1-3+deb10u2) ...\n",
      "Selecting previously unselected package python3-dbus.\n",
      "Preparing to unpack .../110-python3-dbus_1.2.8-3_amd64.deb ...\n",
      "Unpacking python3-dbus (1.2.8-3) ...\n",
      "Selecting previously unselected package python3.7-dev.\n",
      "Preparing to unpack .../111-python3.7-dev_3.7.3-2+deb10u2_amd64.deb ...\n",
      "Unpacking python3.7-dev (3.7.3-2+deb10u2) ...\n",
      "Selecting previously unselected package python3-dev.\n",
      "Preparing to unpack .../112-python3-dev_3.7.3-1_amd64.deb ...\n",
      "Unpacking python3-dev (3.7.3-1) ...\n",
      "Selecting previously unselected package python3-entrypoints.\n",
      "Preparing to unpack .../113-python3-entrypoints_0.3-1_all.deb ...\n",
      "Unpacking python3-entrypoints (0.3-1) ...\n",
      "Selecting previously unselected package python3-gi.\n",
      "Preparing to unpack .../114-python3-gi_3.30.4-1_amd64.deb ...\n",
      "Unpacking python3-gi (3.30.4-1) ...\n",
      "Selecting previously unselected package python3-secretstorage.\n",
      "Preparing to unpack .../115-python3-secretstorage_2.3.1-2_all.deb ...\n",
      "Unpacking python3-secretstorage (2.3.1-2) ...\n",
      "Selecting previously unselected package python3-keyring.\n",
      "Preparing to unpack .../116-python3-keyring_17.1.1-1_all.deb ...\n",
      "Unpacking python3-keyring (17.1.1-1) ...\n",
      "Selecting previously unselected package python3-keyrings.alt.\n",
      "Preparing to unpack .../117-python3-keyrings.alt_3.1.1-1_all.deb ...\n",
      "Unpacking python3-keyrings.alt (3.1.1-1) ...\n",
      "Selecting previously unselected package python3-pip.\n",
      "Preparing to unpack .../118-python3-pip_18.1-5_all.deb ...\n",
      "Unpacking python3-pip (18.1-5) ...\n",
      "Selecting previously unselected package python3-pkg-resources.\n",
      "Preparing to unpack .../119-python3-pkg-resources_40.8.0-1_all.deb ...\n",
      "Unpacking python3-pkg-resources (40.8.0-1) ...\n",
      "Selecting previously unselected package python3-setuptools.\n",
      "Preparing to unpack .../120-python3-setuptools_40.8.0-1_all.deb ...\n",
      "Unpacking python3-setuptools (40.8.0-1) ...\n",
      "Selecting previously unselected package python3-wheel.\n",
      "Preparing to unpack .../121-python3-wheel_0.32.3-2_all.deb ...\n",
      "Unpacking python3-wheel (0.32.3-2) ...\n",
      "Selecting previously unselected package python3-xdg.\n",
      "Preparing to unpack .../122-python3-xdg_0.25-5_all.deb ...\n",
      "Unpacking python3-xdg (0.25-5) ...\n",
      "Selecting previously unselected package shared-mime-info.\n",
      "Preparing to unpack .../123-shared-mime-info_1.10-1_amd64.deb ...\n",
      "Unpacking shared-mime-info (1.10-1) ...\n",
      "Selecting previously unselected package unzip.\n",
      "Preparing to unpack .../124-unzip_6.0-23+deb10u1_amd64.deb ...\n",
      "Unpacking unzip (6.0-23+deb10u1) ...\n",
      "Selecting previously unselected package xdg-user-dirs.\n",
      "Preparing to unpack .../125-xdg-user-dirs_0.17-2_amd64.deb ...\n",
      "Unpacking xdg-user-dirs (0.17-2) ...\n",
      "Setting up perl-modules-5.28 (5.28.1-6+deb10u1) ...\n",
      "Setting up libksba8:amd64 (1.3.5-2) ...\n",
      "Setting up libkeyutils1:amd64 (1.6-6) ...\n",
      "Setting up libapparmor1:amd64 (2.13.2-10) ...\n",
      "Setting up libpsl5:amd64 (0.20.2-2) ...\n",
      "Setting up mime-support (3.62) ...\n",
      "Setting up xdg-user-dirs (0.17-2) ...\n",
      "Setting up libmagic-mgc (1:5.35-4+deb10u1) ...\n",
      "Setting up libglib2.0-0:amd64 (2.58.3-2+deb10u2) ...\n",
      "No schema files found: doing nothing.\n",
      "Setting up manpages (4.16-2) ...\n",
      "Setting up unzip (6.0-23+deb10u1) ...\n",
      "Setting up libsqlite3-0:amd64 (3.27.2-3) ...\n",
      "Setting up libsasl2-modules:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Setting up binutils-common:amd64 (2.31.1-16) ...\n",
      "Setting up libnghttp2-14:amd64 (1.36.0-2+deb10u1) ...\n",
      "Setting up libmagic1:amd64 (1:5.35-4+deb10u1) ...\n",
      "Setting up linux-libc-dev:amd64 (4.19.132-1) ...\n",
      "Setting up libnpth0:amd64 (1.6-1) ...\n",
      "Setting up krb5-locales (1.17-3) ...\n",
      "Setting up file (1:5.35-4+deb10u1) ...\n",
      "Setting up libassuan0:amd64 (2.5.2-1) ...\n",
      "Setting up libgomp1:amd64 (8.3.0-6) ...\n",
      "Setting up bzip2 (1.0.6-9.2~deb10u1) ...\n",
      "Setting up libldap-common (2.4.47+dfsg-3+deb10u2) ...\n",
      "Setting up libicu63:amd64 (63.1-6+deb10u1) ...\n",
      "Setting up libfakeroot:amd64 (1.23-1) ...\n",
      "Setting up libkrb5support0:amd64 (1.17-3) ...\n",
      "Setting up libsasl2-modules-db:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Setting up fakeroot (1.23-1) ...\n",
      "update-alternatives: using /usr/bin/fakeroot-sysv to provide /usr/bin/fakeroot (fakeroot) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/fakeroot.1.gz because associated file /usr/share/man/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/faked.1.gz because associated file /usr/share/man/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/fakeroot.1.gz because associated file /usr/share/man/es/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/es/man1/faked.1.gz because associated file /usr/share/man/es/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/fakeroot.1.gz because associated file /usr/share/man/fr/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/fr/man1/faked.1.gz because associated file /usr/share/man/fr/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/fakeroot.1.gz because associated file /usr/share/man/sv/man1/fakeroot-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/sv/man1/faked.1.gz because associated file /usr/share/man/sv/man1/faked-sysv.1.gz (of link group fakeroot) doesn't exist\n",
      "Setting up libasan5:amd64 (8.3.0-6) ...\n",
      "Setting up libglib2.0-data (2.58.3-2+deb10u2) ...\n",
      "Setting up make (4.2.1-1.2) ...\n",
      "Setting up libmpfr6:amd64 (4.0.2-1) ...\n",
      "Setting up gnupg-l10n (2.2.12-1+deb10u1) ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up librtmp1:amd64 (2.4+20151223.gitfa8646d.1-2) ...\n",
      "Setting up libdbus-1-3:amd64 (1.12.20-0+deb10u1) ...\n",
      "Setting up dbus (1.12.20-0+deb10u1) ...\n",
      "invoke-rc.d: could not determine current runlevel\n",
      "invoke-rc.d: policy-rc.d denied execution of start.\n",
      "Setting up xz-utils (5.2.4-1) ...\n",
      "update-alternatives: using /usr/bin/xz to provide /usr/bin/lzma (lzma) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzma.1.gz because associated file /usr/share/man/man1/xz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unlzma.1.gz because associated file /usr/share/man/man1/unxz.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcat.1.gz because associated file /usr/share/man/man1/xzcat.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzmore.1.gz because associated file /usr/share/man/man1/xzmore.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzless.1.gz because associated file /usr/share/man/man1/xzless.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzdiff.1.gz because associated file /usr/share/man/man1/xzdiff.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzcmp.1.gz because associated file /usr/share/man/man1/xzcmp.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzgrep.1.gz because associated file /usr/share/man/man1/xzgrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzegrep.1.gz because associated file /usr/share/man/man1/xzegrep.1.gz (of link group lzma) doesn't exist\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/lzfgrep.1.gz because associated file /usr/share/man/man1/xzfgrep.1.gz (of link group lzma) doesn't exist\n",
      "Setting up libquadmath0:amd64 (8.3.0-6) ...\n",
      "Setting up libmpc3:amd64 (1.1.0-1) ...\n",
      "Setting up libatomic1:amd64 (8.3.0-6) ...\n",
      "Setting up patch (2.7.6-3+deb10u1) ...\n",
      "Setting up libk5crypto3:amd64 (1.17-3) ...\n",
      "Setting up libsasl2-2:amd64 (2.1.27+dfsg-1+deb10u1) ...\n",
      "Setting up libmpx2:amd64 (8.3.0-6) ...\n",
      "Setting up libubsan1:amd64 (8.3.0-6) ...\n",
      "Setting up libisl19:amd64 (0.20-2) ...\n",
      "Setting up libgirepository-1.0-1:amd64 (1.58.3-2) ...\n",
      "Setting up libssh2-1:amd64 (1.8.0-2.1) ...\n",
      "Setting up netbase (5.6) ...\n",
      "Setting up python-pip-whl (18.1-5) ...\n",
      "Setting up libkrb5-3:amd64 (1.17-3) ...\n",
      "Setting up libmpdec2:amd64 (2.4.2-2) ...\n",
      "Setting up libbinutils:amd64 (2.31.1-16) ...\n",
      "Setting up cpp-8 (8.3.0-6) ...\n",
      "Setting up libc-dev-bin (2.28-10) ...\n",
      "Setting up readline-common (7.0-5) ...\n",
      "Setting up publicsuffix (20190415.1030-1) ...\n",
      "Setting up libxml2:amd64 (2.9.4+dfsg1-7+b3) ...\n",
      "Setting up libcc1-0:amd64 (8.3.0-6) ...\n",
      "Setting up liblocale-gettext-perl (1.07-3+b4) ...\n",
      "Setting up liblsan0:amd64 (8.3.0-6) ...\n",
      "Setting up libitm1:amd64 (8.3.0-6) ...\n",
      "Setting up libreadline7:amd64 (7.0-5) ...\n",
      "Setting up libgdbm6:amd64 (1.18.1-4) ...\n",
      "Setting up gnupg-utils (2.2.12-1+deb10u1) ...\n",
      "Setting up binutils-x86-64-linux-gnu (2.31.1-16) ...\n",
      "Setting up libtsan0:amd64 (8.3.0-6) ...\n",
      "Setting up pinentry-curses (1.1.0-2) ...\n",
      "Setting up manpages-dev (4.16-2) ...\n",
      "Setting up libpython3.7-stdlib:amd64 (3.7.3-2+deb10u2) ...\n",
      "Setting up libpython3.7:amd64 (3.7.3-2+deb10u2) ...\n",
      "Setting up libldap-2.4-2:amd64 (2.4.47+dfsg-3+deb10u2) ...\n",
      "Setting up binutils (2.31.1-16) ...\n",
      "Setting up libpython2.7-stdlib:amd64 (2.7.16-2+deb10u1) ...\n",
      "Setting up shared-mime-info (1.10-1) ...\n",
      "Setting up libgssapi-krb5-2:amd64 (1.17-3) ...\n",
      "Setting up libgdbm-compat4:amd64 (1.18.1-4) ...\n",
      "Setting up gir1.2-glib-2.0:amd64 (1.58.3-2) ...\n",
      "Setting up libgcc-8-dev:amd64 (8.3.0-6) ...\n",
      "Setting up libperl5.28:amd64 (5.28.1-6+deb10u1) ...\n",
      "Setting up cpp (4:8.3.0-1) ...\n",
      "Setting up gpgconf (2.2.12-1+deb10u1) ...\n",
      "Setting up libcurl4:amd64 (7.64.0-4+deb10u1) ...\n",
      "Setting up libc6-dev:amd64 (2.28-10) ...\n",
      "Setting up curl (7.64.0-4+deb10u1) ...\n",
      "Setting up gpg (2.2.12-1+deb10u1) ...\n",
      "Setting up libpython3-stdlib:amd64 (3.7.3-1) ...\n",
      "Setting up libstdc++-8-dev:amd64 (8.3.0-6) ...\n",
      "Setting up python3.7 (3.7.3-2+deb10u2) ...\n",
      "Setting up libpython2.7:amd64 (2.7.16-2+deb10u1) ...\n",
      "Setting up gcc-8 (8.3.0-6) ...\n",
      "Setting up gpg-agent (2.2.12-1+deb10u1) ...\n",
      "Setting up python2.7 (2.7.16-2+deb10u1) ...\n",
      "Setting up libpython2-stdlib:amd64 (2.7.16-1) ...\n",
      "Setting up gpgsm (2.2.12-1+deb10u1) ...\n",
      "Setting up python3 (3.7.3-1) ...\n",
      "running python rtupdate hooks for python3.7...\n",
      "running python post-rtupdate hooks for python3.7...\n",
      "Setting up python3-xdg (0.25-5) ...\n",
      "Setting up python3-wheel (0.32.3-2) ...\n",
      "Setting up python2 (2.7.16-1) ...\n",
      "Setting up gcc (4:8.3.0-1) ...\n",
      "Setting up python3-six (1.12.0-1) ...\n",
      "Setting up dirmngr (2.2.12-1+deb10u1) ...\n",
      "Setting up libpython-stdlib:amd64 (2.7.16-1) ...\n",
      "Setting up perl (5.28.1-6+deb10u1) ...\n",
      "Setting up libexpat1-dev:amd64 (2.2.6-2+deb10u1) ...\n",
      "Setting up python3-gi (3.30.4-1) ...\n",
      "Setting up libdpkg-perl (1.19.7) ...\n",
      "Setting up gpg-wks-server (2.2.12-1+deb10u1) ...\n",
      "Setting up g++-8 (8.3.0-6) ...\n",
      "Setting up python3-crypto (2.6.1-9+b1) ...\n",
      "Setting up python3-lib2to3 (3.7.3-1) ...\n",
      "Setting up python (2.7.16-1) ...\n",
      "Setting up python3-asn1crypto (0.24.0-1) ...\n",
      "Setting up python3-cffi-backend (1.12.2-1) ...\n",
      "Setting up python3-pkg-resources (40.8.0-1) ...\n",
      "Setting up python3-entrypoints (0.3-1) ...\n",
      "Setting up python3-distutils (3.7.3-1) ...\n",
      "Setting up dh-python (3.20190308) ...\n",
      "Setting up python3-dbus (1.2.8-3) ...\n",
      "Setting up libpython2.7-dev:amd64 (2.7.16-2+deb10u1) ...\n",
      "Setting up python3-setuptools (40.8.0-1) ...\n",
      "Setting up gpg-wks-client (2.2.12-1+deb10u1) ...\n",
      "Setting up libfile-fcntllock-perl (0.22-3+b5) ...\n",
      "Setting up libalgorithm-diff-perl (1.19.03-2) ...\n",
      "Setting up libpython3.7-dev:amd64 (3.7.3-2+deb10u2) ...\n",
      "Setting up python3.7-dev (3.7.3-2+deb10u2) ...\n",
      "Setting up dpkg-dev (1.19.7) ...\n",
      "Setting up python3-cryptography (2.6.1-3+deb10u2) ...\n",
      "Setting up python3-pip (18.1-5) ...\n",
      "Setting up python-psutil (5.5.1-1) ...\n",
      "Setting up g++ (4:8.3.0-1) ...\n",
      "update-alternatives: using /usr/bin/g++ to provide /usr/bin/c++ (c++) in auto mode\n",
      "Setting up python3-keyrings.alt (3.1.1-1) ...\n",
      "Setting up gnupg (2.2.12-1+deb10u1) ...\n",
      "Setting up build-essential (12.6) ...\n",
      "Setting up libpython2-dev:amd64 (2.7.16-1) ...\n",
      "Setting up libalgorithm-diff-xs-perl (0.04-5+b1) ...\n",
      "Setting up libalgorithm-merge-perl (0.08-3) ...\n",
      "Setting up python2.7-dev (2.7.16-2+deb10u1) ...\n",
      "Setting up libpython3-dev:amd64 (3.7.3-1) ...\n",
      "Setting up python2-dev (2.7.16-1) ...\n",
      "Setting up libpython-dev:amd64 (2.7.16-1) ...\n",
      "Setting up python3-secretstorage (2.3.1-2) ...\n",
      "Setting up python3-dev (3.7.3-1) ...\n",
      "Setting up python3-keyring (17.1.1-1) ...\n",
      "Setting up python-dev (2.7.16-1) ...\n",
      "Processing triggers for libc-bin (2.28-10) ...\n",
      "Removing intermediate container 2de473830a40\n",
      " ---> 70d4f5e0c8fb\n",
      "Step 4/37 : RUN pip3 install py4j psutil==5.6.5 numpy==1.17.4\n",
      " ---> Running in 18063dae8fd3\n",
      "Collecting py4j\n",
      "  Downloading https://files.pythonhosted.org/packages/30/42/25ad191f311fcdb38b750d49de167abd535e37a144e730a80d7c439d1751/py4j-0.10.9.1-py2.py3-none-any.whl (198kB)\n",
      "Collecting psutil==5.6.5\n",
      "  Downloading https://files.pythonhosted.org/packages/03/9a/95c4b3d0424426e5fd94b5302ff74cea44d5d4f53466e1228ac8e73e14b4/psutil-5.6.5.tar.gz (447kB)\n",
      "Collecting numpy==1.17.4\n",
      "  Downloading https://files.pythonhosted.org/packages/9b/af/4fc72f9d38e43b092e91e5b8cb9956d25b2e3ff8c75aed95df5569e4734e/numpy-1.17.4-cp37-cp37m-manylinux1_x86_64.whl (20.0MB)\n",
      "Building wheels for collected packages: psutil\n",
      "  Running setup.py bdist_wheel for psutil: started\n",
      "  Running setup.py bdist_wheel for psutil: finished with status 'done'\n",
      "  Stored in directory: /root/.cache/pip/wheels/33/48/b6/72b7243c5caf65b7d5b460e9fad82b1256992284e870b7db59\n",
      "Successfully built psutil\n",
      "Installing collected packages: py4j, psutil, numpy\n",
      "Successfully installed numpy-1.17.4 psutil-5.6.5 py4j-0.10.9.1\n",
      "Removing intermediate container 18063dae8fd3\n",
      " ---> a4d85696b6a9\n",
      "Step 5/37 : RUN apt-get clean\n",
      " ---> Running in e48eef1dc6ed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removing intermediate container e48eef1dc6ed\n",
      " ---> 4e5241cdb33b\n",
      "Step 6/37 : RUN rm -rf /var/lib/apt/lists/*\n",
      " ---> Running in fd11516f476d\n",
      "Removing intermediate container fd11516f476d\n",
      " ---> b8af7199d006\n",
      "Step 7/37 : ENV PYTHONHASHSEED 0\n",
      " ---> Running in 67e69a40b043\n",
      "Removing intermediate container 67e69a40b043\n",
      " ---> 2798320363dd\n",
      "Step 8/37 : ENV PYTHONIOENCODING UTF-8\n",
      " ---> Running in 83309272600c\n",
      "Removing intermediate container 83309272600c\n",
      " ---> 8c11598de3db\n",
      "Step 9/37 : ENV PIP_DISABLE_PIP_VERSION_CHECK 1\n",
      " ---> Running in 883dc4cc32a9\n",
      "Removing intermediate container 883dc4cc32a9\n",
      " ---> b703cf4ed145\n",
      "Step 10/37 : ENV HADOOP_VERSION 3.2.1\n",
      " ---> Running in 235dc647039b\n",
      "Removing intermediate container 235dc647039b\n",
      " ---> 4a524cf58328\n",
      "Step 11/37 : ENV HADOOP_HOME /usr/hadoop-$HADOOP_VERSION\n",
      " ---> Running in c333dc9a7020\n",
      "Removing intermediate container c333dc9a7020\n",
      " ---> 1d06dddc2444\n",
      "Step 12/37 : ENV HADOOP_CONF_DIR=$HADOOP_HOME/etc/hadoop\n",
      " ---> Running in b00dab8657d1\n",
      "Removing intermediate container b00dab8657d1\n",
      " ---> c50e444fc213\n",
      "Step 13/37 : ENV PATH $PATH:$HADOOP_HOME/bin\n",
      " ---> Running in 4ef01332fddd\n",
      "Removing intermediate container 4ef01332fddd\n",
      " ---> 2b2d8cb867e6\n",
      "Step 14/37 : RUN curl -sL --retry 3   \"http://archive.apache.org/dist/hadoop/common/hadoop-$HADOOP_VERSION/hadoop-$HADOOP_VERSION.tar.gz\"   | gunzip   | tar -x -C /usr/  && rm -rf $HADOOP_HOME/share/doc  && chown -R root:root $HADOOP_HOME\n",
      " ---> Running in c22d66281e4e\n",
      "Removing intermediate container c22d66281e4e\n",
      " ---> 78e7087d0bd7\n",
      "Step 15/37 : ENV SPARK_VERSION 2.4.6\n",
      " ---> Running in 70a30c854ce0\n",
      "Removing intermediate container 70a30c854ce0\n",
      " ---> 1806b3bbf4b7\n",
      "Step 16/37 : ENV SPARK_PACKAGE spark-${SPARK_VERSION}-bin-without-hadoop\n",
      " ---> Running in 95f0fb698168\n",
      "Removing intermediate container 95f0fb698168\n",
      " ---> 01891865bd40\n",
      "Step 17/37 : ENV SPARK_HOME /usr/spark-${SPARK_VERSION}\n",
      " ---> Running in 3404b3d72fef\n",
      "Removing intermediate container 3404b3d72fef\n",
      " ---> 7405e7846531\n",
      "Step 18/37 : ENV SPARK_DIST_CLASSPATH=\"$HADOOP_HOME/etc/hadoop/*:$HADOOP_HOME/share/hadoop/common/lib/*:$HADOOP_HOME/share/hadoop/common/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/hdfs/lib/*:$HADOOP_HOME/share/hadoop/hdfs/*:$HADOOP_HOME/share/hadoop/yarn/lib/*:$HADOOP_HOME/share/hadoop/yarn/*:$HADOOP_HOME/share/hadoop/mapreduce/lib/*:$HADOOP_HOME/share/hadoop/mapreduce/*:$HADOOP_HOME/share/hadoop/tools/lib/*\"\n",
      " ---> Running in 3b2476ead847\n",
      "Removing intermediate container 3b2476ead847\n",
      " ---> bf52e72729f6\n",
      "Step 19/37 : ENV PATH $PATH:${SPARK_HOME}/bin\n",
      " ---> Running in ff7deea43dfb\n",
      "Removing intermediate container ff7deea43dfb\n",
      " ---> 177189155633\n",
      "Step 20/37 : RUN curl -sL --retry 3   \"https://archive.apache.org/dist/spark/spark-${SPARK_VERSION}/${SPARK_PACKAGE}.tgz\"   | gunzip   | tar x -C /usr/  && mv /usr/$SPARK_PACKAGE $SPARK_HOME  && chown -R root:root $SPARK_HOME\n",
      " ---> Running in b34694632375\n",
      "Removing intermediate container b34694632375\n",
      " ---> 6959192d92cf\n",
      "Step 21/37 : ENV PYSPARK_PYTHON=/usr/bin/python3\n",
      " ---> Running in b79d107416cd\n",
      "Removing intermediate container b79d107416cd\n",
      " ---> e9e04915b176\n",
      "Step 22/37 : ENV PATH=\"/usr/bin:/opt/program:${PATH}\"\n",
      " ---> Running in 5be88414060a\n",
      "Removing intermediate container 5be88414060a\n",
      " ---> b62184bab6c4\n",
      "Step 23/37 : ENV YARN_RESOURCEMANAGER_USER=\"root\"\n",
      " ---> Running in 989db71710f9\n",
      "Removing intermediate container 989db71710f9\n",
      " ---> 82fe5de62686\n",
      "Step 24/37 : ENV YARN_NODEMANAGER_USER=\"root\"\n",
      " ---> Running in e6298c56d51b\n",
      "Removing intermediate container e6298c56d51b\n",
      " ---> fccd4230e88d\n",
      "Step 25/37 : ENV HDFS_NAMENODE_USER=\"root\"\n",
      " ---> Running in dc1ef0f94f18\n",
      "Removing intermediate container dc1ef0f94f18\n",
      " ---> 7eb3593e5784\n",
      "Step 26/37 : ENV HDFS_DATANODE_USER=\"root\"\n",
      " ---> Running in e54ba232dce1\n",
      "Removing intermediate container e54ba232dce1\n",
      " ---> b15935a30d76\n",
      "Step 27/37 : ENV HDFS_SECONDARYNAMENODE_USER=\"root\"\n",
      " ---> Running in 355de13f0b89\n",
      "Removing intermediate container 355de13f0b89\n",
      " ---> 66237fe32360\n",
      "Step 28/37 : COPY program /opt/program\n",
      " ---> f1e2b8147754\n",
      "Step 29/37 : RUN chmod +x /opt/program/submit\n",
      " ---> Running in 8ec4a8ae1b34\n",
      "Removing intermediate container 8ec4a8ae1b34\n",
      " ---> 38f96a15d1f4\n",
      "Step 30/37 : COPY hadoop-config /opt/hadoop-config\n",
      " ---> 5394169ee594\n",
      "Step 31/37 : COPY jars /usr/jars\n",
      " ---> bb7ac8490a34\n",
      "Step 32/37 : WORKDIR $SPARK_HOME\n",
      " ---> Running in de5e4c06a571\n",
      "Removing intermediate container de5e4c06a571\n",
      " ---> a228862f57cd\n",
      "Step 33/37 : RUN pip3 install -q pip --upgrade\n",
      " ---> Running in d2e70d0eecac\n",
      "Removing intermediate container d2e70d0eecac\n",
      " ---> 1084cabb2c70\n",
      "Step 34/37 : RUN pip3 install -q wrapt --upgrade --ignore-installed\n",
      " ---> Running in 49bb0046ec85\n",
      "\u001b[91mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[0mRemoving intermediate container 49bb0046ec85\n",
      " ---> 53b64d5adfa3\n",
      "Step 35/37 : RUN pip3 install -q transformers==2.8.0\n",
      " ---> Running in b5cd7eb92b16\n",
      "\u001b[91mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[0mRemoving intermediate container b5cd7eb92b16\n",
      " ---> 7d7d92da2c4c\n",
      "Step 36/37 : RUN pip3 install -q tensorflow==2.1.0 --upgrade --ignore-installed\n",
      " ---> Running in c11ecb3362d1\n",
      "\u001b[91mWARNING: pip is being invoked by an old script wrapper. This will fail in a future version of pip.\n",
      "Please see https://github.com/pypa/pip/issues/5599 for advice on fixing the underlying issue.\n",
      "To avoid this problem you can invoke Python with '-m pip' instead of running pip directly.\n",
      "\u001b[0mRemoving intermediate container c11ecb3362d1\n",
      " ---> 65e9fcdac07f\n",
      "Step 37/37 : ENTRYPOINT [\"/opt/program/submit\"]\n",
      " ---> Running in 95de31e5d30f\n",
      "Removing intermediate container 95de31e5d30f\n",
      " ---> 746a577b4695\n",
      "Successfully built 746a577b4695\n",
      "Successfully tagged amazon-reviews-spark-processor:latest\n"
     ]
    }
   ],
   "source": [
    "!docker build -t $docker_repo:$docker_tag -f container/Dockerfile ./container"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Spark container의 Amazon Elastic Container Registry(Amazon ECR) 리포지토리를 생성하고 image를 push합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "322537213286.dkr.ecr.us-east-1.amazonaws.com/amazon-reviews-spark-processor:latest\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "region = boto3.session.Session().region_name\n",
    "\n",
    "image_uri = '{}.dkr.ecr.{}.amazonaws.com/{}:{}'.format(account_id, region, docker_repo, docker_tag)\n",
    "print(image_uri)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECR repository 생성과 docker image를 push하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING! Using --password via the CLI is insecure. Use --password-stdin.\n",
      "WARNING! Your password will be stored unencrypted in /home/ec2-user/.docker/config.json.\n",
      "Configure a credential helper to remove this warning. See\n",
      "https://docs.docker.com/engine/reference/commandline/login/#credentials-store\n",
      "\n",
      "Login Succeeded\n"
     ]
    }
   ],
   "source": [
    "!$(aws ecr get-login --region $region --registry-ids $account_id --no-include-email)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `RepositoryNotFoundException` 오류는 무시하셔도 됩니다. 즉시 repository를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"repositories\": [\r\n",
      "        {\r\n",
      "            \"repositoryArn\": \"arn:aws:ecr:us-east-1:322537213286:repository/amazon-reviews-spark-processor\",\r\n",
      "            \"registryId\": \"322537213286\",\r\n",
      "            \"repositoryName\": \"amazon-reviews-spark-processor\",\r\n",
      "            \"repositoryUri\": \"322537213286.dkr.ecr.us-east-1.amazonaws.com/amazon-reviews-spark-processor\",\r\n",
      "            \"createdAt\": 1596262176.0,\r\n",
      "            \"imageTagMutability\": \"MUTABLE\",\r\n",
      "            \"imageScanningConfiguration\": {\r\n",
      "                \"scanOnPush\": false\r\n",
      "            },\r\n",
      "            \"encryptionConfiguration\": {\r\n",
      "                \"encryptionType\": \"AES256\"\r\n",
      "            }\r\n",
      "        }\r\n",
      "    ]\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!aws ecr describe-repositories --repository-names $docker_repo || aws ecr create-repository --repository-name $docker_repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker tag $docker_repo:$docker_tag $image_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The push refers to repository [322537213286.dkr.ecr.us-east-1.amazonaws.com/amazon-reviews-spark-processor]\n",
      "\n",
      "\u001b[1Baca904c6: Preparing \n",
      "\u001b[1B74080c56: Preparing \n",
      "\u001b[1B3c74b171: Preparing \n",
      "\u001b[1B67a7277d: Preparing \n",
      "\u001b[1Ba83bff53: Preparing \n",
      "\u001b[1Bfadc25c7: Preparing \n",
      "\u001b[1B7e01acfe: Preparing \n",
      "\u001b[1Bb0ef4a87: Preparing \n",
      "\u001b[1B5a61114d: Preparing \n",
      "\u001b[1Bee9c1c2d: Preparing \n",
      "\u001b[1B213985ea: Preparing \n",
      "\u001b[1B12a14adb: Preparing \n",
      "\u001b[1Bfde717d1: Preparing \n",
      "\u001b[1B7654db06: Preparing \n",
      "\u001b[1B721e75f9: Preparing \n",
      "\u001b[1Ba1389900: Preparing \n",
      "\u001b[1B7b6ca8b9: Preparing \n",
      "\u001b[1Bfd2b2495: Preparing \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[19Bca904c6: Pushing  1.334GB/2.013GB\u001b[15A\u001b[2K\u001b[18A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[14A\u001b[2K\u001b[16A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[15A\u001b[2K\u001b[18A\u001b[2K\u001b[13A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[16A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[18A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[18A\u001b[2K\u001b[11A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[18A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[18A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[18A\u001b[2K\u001b[11A\u001b[2K\u001b[11A\u001b[2K\u001b[18A\u001b[2K\u001b[10A\u001b[2K\u001b[18A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[18A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[18A\u001b[2K\u001b[11A\u001b[2K\u001b[18A\u001b[2K\u001b[11A\u001b[2K\u001b[18A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[18A\u001b[2K\u001b[10A\u001b[2K\u001b[18A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[18A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[18A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[18A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[11A\u001b[2K\u001b[19A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[18A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[7A\u001b[2K\u001b[7A\u001b[2K\u001b[11A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[11A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[19A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[5A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[5A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[3A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[10A\u001b[2K\u001b[2A\u001b[2K\u001b[10A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[2A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[2A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[2A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[2A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[19A\u001b[2K\u001b[4A\u001b[2K\u001b[6A\u001b[2K\u001b[4A\u001b[2K\u001b[10A\u001b[2K\u001b[2A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[6A\u001b[2K\u001b[10A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[1A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[6A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[19Bca904c6: Pushed   2.023GB/2.013GB\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2KPushing  1.831GB/2.013GB\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2K\u001b[19A\u001b[2Klatest: digest: sha256:cd1a6bd948c583694f96daac7c3681ff66aa93cc4286600eabb61e3cc063738e size: 4318\n"
     ]
    }
   ],
   "source": [
    "!docker push $image_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker Processing Jobs 으로 Job 수행\n",
    "\n",
    "Amazon SageMaker Python SDK를 사용하여 Processing job을 실행합니다. Spark container와 job configuration에서 processing에 대한 Spark ML script를 사용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m print_function\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36m__future__\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m unicode_literals\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtime\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshutil\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcsv\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mcollections\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msubprocess\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36msys\u001b[39;49;00m\r\n",
      "\u001b[37m#subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'pip', '--upgrade'])\u001b[39;49;00m\r\n",
      "\u001b[37m#subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'wrapt', '--upgrade', '--ignore-installed'])\u001b[39;49;00m\r\n",
      "\u001b[37m#subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'tensorflow==2.1.0', '--ignore-installed'])\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtensorflow\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mtf\u001b[39;49;00m\r\n",
      "\u001b[36mprint\u001b[39;49;00m(tf.__version__)\r\n",
      "\u001b[37m#subprocess.check_call([sys.executable, '-m', 'pip', 'install', 'transformers==2.8.0'])\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mtransformers\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DistilBertTokenizer\r\n",
      "\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m SparkSession\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mml\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m Pipeline\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mml\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mlinalg\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m DenseVector\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m split\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mfunctions\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m udf, col\r\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mpyspark\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36msql\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mtypes\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m *\r\n",
      "\r\n",
      "tokenizer = DistilBertTokenizer.from_pretrained(\u001b[33m'\u001b[39;49;00m\u001b[33mdistilbert-base-uncased\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\u001b[37m# We set sequences to be at most 128 tokens long.\u001b[39;49;00m\r\n",
      "MAX_SEQ_LENGTH = \u001b[34m128\u001b[39;49;00m\r\n",
      "DATA_COLUMN = \u001b[33m'\u001b[39;49;00m\u001b[33mreview_body\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "LABEL_COLUMN = \u001b[33m'\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "LABEL_VALUES = [\u001b[34m1\u001b[39;49;00m, \u001b[34m2\u001b[39;49;00m, \u001b[34m3\u001b[39;49;00m, \u001b[34m4\u001b[39;49;00m, \u001b[34m5\u001b[39;49;00m]\r\n",
      "\r\n",
      "label_map = {}\r\n",
      "\u001b[34mfor\u001b[39;49;00m (i, label) \u001b[35min\u001b[39;49;00m \u001b[36menumerate\u001b[39;49;00m(LABEL_VALUES):\r\n",
      "    label_map[label] = i\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mInputFeatures\u001b[39;49;00m(\u001b[36mobject\u001b[39;49;00m):\r\n",
      "  \u001b[33m\"\"\"BERT feature vectors.\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "  \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m,\r\n",
      "               input_ids,\r\n",
      "               input_mask,\r\n",
      "               segment_ids,\r\n",
      "               label_id):\r\n",
      "    \u001b[36mself\u001b[39;49;00m.input_ids = input_ids\r\n",
      "    \u001b[36mself\u001b[39;49;00m.input_mask = input_mask\r\n",
      "    \u001b[36mself\u001b[39;49;00m.segment_ids = segment_ids\r\n",
      "    \u001b[36mself\u001b[39;49;00m.label_id = label_id\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mclass\u001b[39;49;00m \u001b[04m\u001b[32mInput\u001b[39;49;00m(\u001b[36mobject\u001b[39;49;00m):\r\n",
      "  \u001b[33m\"\"\"A single training/test input for sequence classification.\"\"\"\u001b[39;49;00m\r\n",
      "\r\n",
      "  \u001b[34mdef\u001b[39;49;00m \u001b[32m__init__\u001b[39;49;00m(\u001b[36mself\u001b[39;49;00m, text, label=\u001b[34mNone\u001b[39;49;00m):\r\n",
      "    \u001b[33m\"\"\"Constructs an Input.\u001b[39;49;00m\r\n",
      "\u001b[33m    Args:\u001b[39;49;00m\r\n",
      "\u001b[33m      text: string. The untokenized text of the first sequence. For single\u001b[39;49;00m\r\n",
      "\u001b[33m        sequence tasks, only this sequence must be specified.\u001b[39;49;00m\r\n",
      "\u001b[33m      label: (Optional) string. The label of the example. This should be\u001b[39;49;00m\r\n",
      "\u001b[33m        specified for train and dev examples, but not for test examples.\u001b[39;49;00m\r\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[36mself\u001b[39;49;00m.text = text\r\n",
      "    \u001b[36mself\u001b[39;49;00m.label = label\r\n",
      "    \r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mconvert_input\u001b[39;49;00m(label, text):\r\n",
      "    \u001b[37m# First, we need to preprocess our data so that it matches the data BERT was trained on:\u001b[39;49;00m\r\n",
      "    \u001b[37m#\u001b[39;49;00m\r\n",
      "    \u001b[37m# 1. Lowercase our text (if we're using a BERT lowercase model)\u001b[39;49;00m\r\n",
      "    \u001b[37m# 2. Tokenize it (i.e. \"sally says hi\" -> [\"sally\", \"says\", \"hi\"])\u001b[39;49;00m\r\n",
      "    \u001b[37m# 3. Break words into WordPieces (i.e. \"calling\" -> [\"call\", \"##ing\"])\u001b[39;49;00m\r\n",
      "    \u001b[37m#\u001b[39;49;00m\r\n",
      "    \u001b[37m# Fortunately, the Transformers tokenizer does this for us!\u001b[39;49;00m\r\n",
      "    \u001b[37m#\u001b[39;49;00m\r\n",
      "\u001b[37m#    tokens = tokenizer.tokenize(text_input.text)\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[37m# Next, we need to do the following:\u001b[39;49;00m\r\n",
      "    \u001b[37m#\u001b[39;49;00m\r\n",
      "    \u001b[37m# 4. Map our words to indexes using a vocab file that BERT provides\u001b[39;49;00m\r\n",
      "    \u001b[37m# 5. Add special \"CLS\" and \"SEP\" tokens (see the [readme](https://github.com/google-research/bert))\u001b[39;49;00m\r\n",
      "    \u001b[37m# 6. Append \"index\" and \"segment\" tokens to each input (see the [BERT paper](https://arxiv.org/pdf/1810.04805.pdf))\u001b[39;49;00m\r\n",
      "    \u001b[37m#\u001b[39;49;00m\r\n",
      "    \u001b[37m# Again, the Transformers tokenizer does this for us!\u001b[39;49;00m\r\n",
      "    \u001b[37m#\u001b[39;49;00m\r\n",
      "    encode_plus_tokens = tokenizer.encode_plus(text,\r\n",
      "                                               pad_to_max_length=\u001b[34mTrue\u001b[39;49;00m,\r\n",
      "                                               max_length=MAX_SEQ_LENGTH)\r\n",
      "\r\n",
      "    \u001b[37m# Convert the text-based tokens to ids from the pre-trained BERT vocabulary\u001b[39;49;00m\r\n",
      "    input_ids = encode_plus_tokens[\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    \u001b[37m# Specifies which tokens BERT should pay attention to (0 or 1)\u001b[39;49;00m\r\n",
      "    input_mask = encode_plus_tokens[\u001b[33m'\u001b[39;49;00m\u001b[33mattention_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]\r\n",
      "    \u001b[37m# Segment Ids are always 0 for single-sequence tasks (or 1 if two-sequence tasks)\u001b[39;49;00m\r\n",
      "    segment_ids = [\u001b[34m0\u001b[39;49;00m] * MAX_SEQ_LENGTH\r\n",
      "\r\n",
      "    \u001b[37m# Label for our training data (star_rating 1 through 5)\u001b[39;49;00m\r\n",
      "    label_id = label_map[label]\r\n",
      "\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m {\u001b[33m'\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: input_ids, \u001b[33m'\u001b[39;49;00m\u001b[33minput_mask\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: input_mask, \u001b[33m'\u001b[39;49;00m\u001b[33msegment_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: segment_ids, \u001b[33m'\u001b[39;49;00m\u001b[33mlabel_ids\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: [label_id]}\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mlist_arg\u001b[39;49;00m(raw_value):\r\n",
      "    \u001b[33m\"\"\"argparse type for a list of strings\"\"\"\u001b[39;49;00m\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m \u001b[36mstr\u001b[39;49;00m(raw_value).split(\u001b[33m'\u001b[39;49;00m\u001b[33m,\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mparse_args\u001b[39;49;00m():\r\n",
      "    \u001b[37m# Unlike SageMaker training jobs (which have `SM_HOSTS` and `SM_CURRENT_HOST` env vars), processing jobs to need to parse the resource config file directly\u001b[39;49;00m\r\n",
      "    resconfig = {}\r\n",
      "    \u001b[34mtry\u001b[39;49;00m:\r\n",
      "        \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/config/resourceconfig.json\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mr\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m cfgfile:\r\n",
      "            resconfig = json.load(cfgfile)\r\n",
      "    \u001b[34mexcept\u001b[39;49;00m \u001b[36mFileNotFoundError\u001b[39;49;00m:\r\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/config/resourceconfig.json not found.  current_host is unknown.\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "        \u001b[34mpass\u001b[39;49;00m \u001b[37m# Ignore\u001b[39;49;00m\r\n",
      "\r\n",
      "    \u001b[37m# Local testing with CLI args\u001b[39;49;00m\r\n",
      "    parser = argparse.ArgumentParser(description=\u001b[33m'\u001b[39;49;00m\u001b[33mProcess\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=list_arg,\r\n",
      "        default=resconfig.get(\u001b[33m'\u001b[39;49;00m\u001b[33mhosts\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, [\u001b[33m'\u001b[39;49;00m\u001b[33munknown\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m]),\r\n",
      "        help=\u001b[33m'\u001b[39;49;00m\u001b[33mComma-separated list of host names running the job\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--current-host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\r\n",
      "        default=resconfig.get(\u001b[33m'\u001b[39;49;00m\u001b[33mcurrent_host\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33munknown\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m),\r\n",
      "        help=\u001b[33m'\u001b[39;49;00m\u001b[33mName of this host running the job\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m\r\n",
      "    )\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--input-data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\r\n",
      "        default=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/input/data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m,\r\n",
      "        default=\u001b[33m'\u001b[39;49;00m\u001b[33m/opt/ml/processing/output\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "    )\r\n",
      "    \u001b[34mreturn\u001b[39;49;00m parser.parse_args()\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtransform\u001b[39;49;00m(spark, s3_input_data, s3_output_train_data, s3_output_validation_data, s3_output_test_data): \r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mProcessing \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m => \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(s3_input_data, s3_output_train_data, s3_output_validation_data, s3_output_test_data))\r\n",
      " \r\n",
      "    schema = StructType([\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mmarketplace\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mcustomer_id\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mreview_id\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mproduct_id\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mproduct_parent\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mproduct_title\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mproduct_category\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, IntegerType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mhelpful_votes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, IntegerType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mtotal_votes\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, IntegerType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mvine\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mverified_purchase\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mreview_headline\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mreview_body\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m),\r\n",
      "        StructField(\u001b[33m'\u001b[39;49;00m\u001b[33mreview_date\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, StringType(), \u001b[34mTrue\u001b[39;49;00m)\r\n",
      "    ])\r\n",
      "    \r\n",
      "    df_csv = spark.read.csv(path=s3_input_data,\r\n",
      "                            sep=\u001b[33m'\u001b[39;49;00m\u001b[33m\\t\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\r\n",
      "                            schema=schema,\r\n",
      "                            header=\u001b[34mTrue\u001b[39;49;00m,\r\n",
      "                            quote=\u001b[34mNone\u001b[39;49;00m)\r\n",
      "    df_csv.show()\r\n",
      "\r\n",
      "    \u001b[37m# This dataset should already be clean, but always good to double-check\u001b[39;49;00m\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mShowing null review_body rows...\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    df_csv.where(col(\u001b[33m'\u001b[39;49;00m\u001b[33mreview_body\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).isNull()).show()\r\n",
      "\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mShowing cleaned csv\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    df_csv_dropped = df_csv.na.drop(subset=[\u001b[33m'\u001b[39;49;00m\u001b[33mreview_body\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    df_csv_dropped.show()\r\n",
      "\r\n",
      "    \u001b[37m# TODO:  Balance\u001b[39;49;00m\r\n",
      "    \r\n",
      "    features_df = df_csv_dropped.select([\u001b[33m'\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mreview_body\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\r\n",
      "    features_df.show()\r\n",
      "\r\n",
      "    tfrecord_schema = StructType([\r\n",
      "      StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_ids\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ArrayType(IntegerType(), \u001b[34mFalse\u001b[39;49;00m)),\r\n",
      "      StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33minput_mask\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ArrayType(IntegerType(), \u001b[34mFalse\u001b[39;49;00m)),\r\n",
      "      StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33msegment_ids\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ArrayType(IntegerType(), \u001b[34mFalse\u001b[39;49;00m)),\r\n",
      "      StructField(\u001b[33m\"\u001b[39;49;00m\u001b[33mlabel_ids\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m, ArrayType(IntegerType(), \u001b[34mFalse\u001b[39;49;00m))\r\n",
      "    ])\r\n",
      "\r\n",
      "    bert_transformer = udf(\u001b[34mlambda\u001b[39;49;00m text, label: convert_input(text, label), tfrecord_schema)\r\n",
      "\r\n",
      "    spark.udf.register(\u001b[33m'\u001b[39;49;00m\u001b[33mbert_transformer\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, bert_transformer)\r\n",
      "\r\n",
      "    transformed_df = features_df.select(bert_transformer(\u001b[33m'\u001b[39;49;00m\u001b[33mstar_rating\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mreview_body\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).alias(\u001b[33m'\u001b[39;49;00m\u001b[33mtfrecords\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m))\r\n",
      "    transformed_df.show(truncate=\u001b[34mFalse\u001b[39;49;00m)\r\n",
      "\r\n",
      "    flattened_df = transformed_df.select(\u001b[33m'\u001b[39;49;00m\u001b[33mtfrecords.*\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    flattened_df.show()\r\n",
      "\r\n",
      "    \u001b[37m# Split 90-5-5%\u001b[39;49;00m\r\n",
      "    train_df, validation_df, test_df = flattened_df.randomSplit([\u001b[34m0.9\u001b[39;49;00m, \u001b[34m0.05\u001b[39;49;00m, \u001b[34m0.05\u001b[39;49;00m])\r\n",
      "\r\n",
      "    train_df.write.format(\u001b[33m'\u001b[39;49;00m\u001b[33mtfrecord\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).option(\u001b[33m'\u001b[39;49;00m\u001b[33mrecordType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExample\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).save(path=s3_output_train_data)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mWrote to output file:  \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(s3_output_train_data))\r\n",
      "    \r\n",
      "    validation_df.write.format(\u001b[33m'\u001b[39;49;00m\u001b[33mtfrecord\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).option(\u001b[33m'\u001b[39;49;00m\u001b[33mrecordType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExample\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).save(path=s3_output_validation_data)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mWrote to output file:  \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(s3_output_validation_data))\r\n",
      "\r\n",
      "    test_df.write.format(\u001b[33m'\u001b[39;49;00m\u001b[33mtfrecord\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).option(\u001b[33m'\u001b[39;49;00m\u001b[33mrecordType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExample\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).save(path=s3_output_test_data)    \r\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m'\u001b[39;49;00m\u001b[33mWrote to output file:  \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m.format(s3_output_test_data))\r\n",
      "\r\n",
      "    restored_test_df = spark.read.format(\u001b[33m'\u001b[39;49;00m\u001b[33mtfrecord\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).option(\u001b[33m'\u001b[39;49;00m\u001b[33mrecordType\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33mExample\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).load(path=s3_output_test_data)\r\n",
      "    restored_test_df.show()\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmain\u001b[39;49;00m():\r\n",
      "    spark = SparkSession.builder.appName(\u001b[33m'\u001b[39;49;00m\u001b[33mAmazonReviewsSparkProcessor\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m).getOrCreate()\r\n",
      "\r\n",
      "    \u001b[37m# Convert command line args into a map of args\u001b[39;49;00m\r\n",
      "    args_iter = \u001b[36miter\u001b[39;49;00m(sys.argv[\u001b[34m1\u001b[39;49;00m:])\r\n",
      "    args = \u001b[36mdict\u001b[39;49;00m(\u001b[36mzip\u001b[39;49;00m(args_iter, args_iter))\r\n",
      "\r\n",
      "    \u001b[37m# Retrieve the args and replace 's3://' with 's3a://' (used by Spark)\u001b[39;49;00m\r\n",
      "    s3_input_data = args[\u001b[33m'\u001b[39;49;00m\u001b[33ms3_input_data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].replace(\u001b[33m'\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33ms3a://\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(s3_input_data)\r\n",
      "\r\n",
      "    s3_output_train_data = args[\u001b[33m'\u001b[39;49;00m\u001b[33ms3_output_train_data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].replace(\u001b[33m'\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33ms3a://\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(s3_output_train_data)\r\n",
      "\r\n",
      "    s3_output_validation_data = args[\u001b[33m'\u001b[39;49;00m\u001b[33ms3_output_validation_data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].replace(\u001b[33m'\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33ms3a://\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(s3_output_validation_data)\r\n",
      "\r\n",
      "    s3_output_test_data = args[\u001b[33m'\u001b[39;49;00m\u001b[33ms3_output_test_data\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m].replace(\u001b[33m'\u001b[39;49;00m\u001b[33ms3://\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[33m'\u001b[39;49;00m\u001b[33ms3a://\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\r\n",
      "    \u001b[36mprint\u001b[39;49;00m(s3_output_test_data)\r\n",
      "\r\n",
      "    transform(spark, s3_input_data, s3_output_train_data, s3_output_validation_data, s3_output_test_data)\r\n",
      "\r\n",
      "\r\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m\"\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m:\r\n",
      "    main()\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize src_dir/preprocess-spark-text-to-bert.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ScriptProcessor\n",
    "\n",
    "processor = ScriptProcessor(base_job_name='spark-amazon-reviews-processor',\n",
    "                            image_uri=image_uri,\n",
    "                            command=['/opt/program/submit'],\n",
    "                            role=role,\n",
    "                            instance_count=2, # instance_count needs to be > 1 or you will see the following error:  \"INFO yarn.Client: Application report for application_ (state: ACCEPTED)\"\n",
    "                            instance_type='ml.r5.xlarge',\n",
    "                            env={'mode': 'python'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Output Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import gmtime, strftime\n",
    "timestamp_prefix = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "output_prefix = 'amazon-reviews-spark-processor-{}'.format(timestamp_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train\n",
      "s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation\n",
      "s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test\n"
     ]
    }
   ],
   "source": [
    "train_data_bert_output = 's3://{}/{}/output/bert-train'.format(bucket, output_prefix)\n",
    "validation_data_bert_output = 's3://{}/{}/output/bert-validation'.format(bucket, output_prefix)\n",
    "test_data_bert_output = 's3://{}/{}/output/bert-test'.format(bucket, output_prefix)\n",
    "\n",
    "print(train_data_bert_output)\n",
    "print(validation_data_bert_output)\n",
    "print(test_data_bert_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'session' will be renamed to 'sagemaker_session' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Job Name:  spark-amazon-reviews-processor-2020-09-15-05-53-32-188\n",
      "Inputs:  [{'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-322537213286/spark-amazon-reviews-processor-2020-09-15-05-53-32-188/input/code/preprocess-spark-text-to-bert.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
      "Outputs:  [{'OutputName': 'dummy-output', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-322537213286/spark-amazon-reviews-processor-2020-09-15-05-53-32-188/output/dummy-output', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.processing import ProcessingOutput\n",
    "\n",
    "processor.run(code='./src_dir/preprocess-spark-text-to-bert.py',\n",
    "              arguments=['s3_input_data', s3_input_data,\n",
    "                         's3_output_train_data', train_data_bert_output,\n",
    "                         's3_output_validation_data', validation_data_bert_output,\n",
    "                         's3_output_test_data', test_data_bert_output,                         \n",
    "              ],\n",
    "              # We need this dummy output to allow us to call \n",
    "              #    ProcessingJob.from_processing_name() later \n",
    "              #    to describe the job and poll for Completed status\n",
    "              outputs=[\n",
    "                       ProcessingOutput(s3_upload_mode='EndOfJob',\n",
    "                                        output_name='dummy-output',\n",
    "                                        source='/opt/ml/processing/output')\n",
    "              ],          \n",
    "              logs=True,\n",
    "              wait=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://console.aws.amazon.com/cloudwatch/home?region=us-east-1#logStream:group=/aws/sagemaker/ProcessingJobs;prefix=spark-amazon-reviews-processor-2020-09-15-05-53-32-188;streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "spark_processing_job_name = processor.jobs[-1].describe()['ProcessingJobName']\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/cloudwatch/home?region={}#logStream:group=/aws/sagemaker/ProcessingJobs;prefix={};streamFilter=typeLogStreamPrefix\">CloudWatch Logs</a> After About 5 Minutes</b>'.format(region, spark_processing_job_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://s3.console.aws.amazon.com/s3/buckets/sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/?region=us-east-1&tab=overview\">S3 Output Data</a> After The Spark Job Has Completed</b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "# This is different than the job name because we are not using ProcessingOutput's in this Spark ML case.\n",
    "spark_processing_job_s3_output_prefix = output_prefix\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://s3.console.aws.amazon.com/s3/buckets/{}/{}/?region={}&tab=overview\">S3 Output Data</a> After The Spark Job Has Completed</b>'.format(bucket, spark_processing_job_s3_output_prefix, region)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# List Processing Jobs through boto3 Python SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ProcessingJobSummaries': [{'ProcessingJobName': 'spark-amazon-reviews-processor-2020-09-15-05-53-32-188',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/spark-amazon-reviews-processor-2020-09-15-05-53-32-188',\n",
       "   'CreationTime': datetime.datetime(2020, 9, 15, 5, 53, 32, 776000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 9, 15, 5, 53, 32, 776000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'InProgress'},\n",
       "  {'ProcessingJobName': 'sagemaker-scikit-learn-2020-09-15-05-48-17-452',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/sagemaker-scikit-learn-2020-09-15-05-48-17-452',\n",
       "   'CreationTime': datetime.datetime(2020, 9, 15, 5, 48, 17, 936000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 9, 15, 5, 53, 23, 152000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 9, 15, 5, 53, 23, 156000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'},\n",
       "  {'ProcessingJobName': 'pr-1-5bfd335f662a4945bc40956e50bbeeca13b23f2d823541ce83dd868af6',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/pr-1-5bfd335f662a4945bc40956e50bbeeca13b23f2d823541ce83dd868af6',\n",
       "   'CreationTime': datetime.datetime(2020, 9, 15, 5, 45, 35, 86000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 9, 15, 5, 50, 55, 281000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 9, 15, 5, 50, 55, 285000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'},\n",
       "  {'ProcessingJobName': 'db-1-5fbfb46d39a94024b6fa41d0df79e6de0bf48ed2f29d4a51b9b88cbb93',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/db-1-5fbfb46d39a94024b6fa41d0df79e6de0bf48ed2f29d4a51b9b88cbb93',\n",
       "   'CreationTime': datetime.datetime(2020, 9, 15, 5, 41, 45, 421000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 9, 15, 5, 45, 16, 688000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 9, 15, 5, 45, 16, 691000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'},\n",
       "  {'ProcessingJobName': 'tensorflow-training-2020-0-Overtraining-72eb97f8',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/tensorflow-training-2020-0-overtraining-72eb97f8',\n",
       "   'CreationTime': datetime.datetime(2020, 8, 7, 4, 32, 55, 238000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 8, 7, 4, 39, 42, 824000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 8, 7, 4, 39, 42, 828000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'},\n",
       "  {'ProcessingJobName': 'tensorflow-training-2020-0-LossNotDecreasing-447fb897',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/tensorflow-training-2020-0-lossnotdecreasing-447fb897',\n",
       "   'CreationTime': datetime.datetime(2020, 8, 7, 4, 32, 53, 693000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 8, 7, 4, 40, 15, 652000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 8, 7, 4, 40, 15, 656000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'},\n",
       "  {'ProcessingJobName': 'sagemaker-scikit-learn-2020-08-06-06-47-26-318',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/sagemaker-scikit-learn-2020-08-06-06-47-26-318',\n",
       "   'CreationTime': datetime.datetime(2020, 8, 6, 6, 47, 26, 772000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 8, 6, 6, 52, 21, 745000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 8, 6, 6, 52, 21, 749000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'},\n",
       "  {'ProcessingJobName': 'spark-amazon-reviews-processor-2020-08-05-21-08-03-022',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/spark-amazon-reviews-processor-2020-08-05-21-08-03-022',\n",
       "   'CreationTime': datetime.datetime(2020, 8, 5, 21, 8, 3, 491000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 8, 6, 0, 58, 23, 277000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 8, 6, 0, 58, 23, 280000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'},\n",
       "  {'ProcessingJobName': 'sagemaker-scikit-learn-2020-08-05-21-03-13-532',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/sagemaker-scikit-learn-2020-08-05-21-03-13-532',\n",
       "   'CreationTime': datetime.datetime(2020, 8, 5, 21, 3, 14, 29000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 8, 5, 21, 8, 7, 787000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 8, 5, 21, 8, 7, 790000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'},\n",
       "  {'ProcessingJobName': 'sagemaker-scikit-learn-2020-08-05-14-41-53-847',\n",
       "   'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/sagemaker-scikit-learn-2020-08-05-14-41-53-847',\n",
       "   'CreationTime': datetime.datetime(2020, 8, 5, 14, 41, 54, 904000, tzinfo=tzlocal()),\n",
       "   'ProcessingEndTime': datetime.datetime(2020, 8, 5, 14, 47, 30, 283000, tzinfo=tzlocal()),\n",
       "   'LastModifiedTime': datetime.datetime(2020, 8, 5, 14, 47, 30, 285000, tzinfo=tzlocal()),\n",
       "   'ProcessingJobStatus': 'Completed'}],\n",
       " 'NextToken': 'cIws2QhTXUIa8bi8XqFFSFgJoq5/N5VqPat8zDAW89U64DprP+2aAFY9YJ2MwWi+v9YqilwnnS5qn3OWYIyBSb2IJDojp6MR/F8aUqwL6QQT7sEeahlM6ej/txHO1yammI0xhb4wImO4+duhSKpnubrKas1BOnHOmJtejcda0ayE0Fq8HDgtBVxXTQRe/s5Axsl9guVfver0vwpsv1/t2XWF0iHwzXX4/bBRmvhfebBqc1bEKEfMDMfJly+Uid3Fn+3OqNEOfD9ghOPpmDiSbueTL3dzdAsHjIycSHou+11gG0Qhq+nGTqZjs9YEzdX4i+kG/r/w7wNFiCc/6FTWGF5qLRd9HBRYWDP7wPIVlVdI31BKIXlDEirxenMMzaC7O05+Gm3TjQdR98L0SmQkSbLyOo/PIYCJ640q1QObyanattcMdbhfJD1su17tZd6fhJpU1aDVTgahk0U3/zbiDM8ibblL1IZjRyeaenVhLFMBoG+AwyqrVfdoSrsnr566fc3OCBKxcqcHIlPwV09+rvFPQkJYw5/2xdtvr6qMbxjcxA==',\n",
       " 'ResponseMetadata': {'RequestId': '312e4545-73f7-4181-8e01-6d1e4d5209bb',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '312e4545-73f7-4181-8e01-6d1e4d5209bb',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '4023',\n",
       "   'date': 'Tue, 15 Sep 2020 05:53:32 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import boto3\n",
    "\n",
    "client = boto3.client('sagemaker')\n",
    "client.list_processing_jobs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Please Wait Until the Processing Job Completes\n",
    "Re-run this next cell until the job status shows `Completed`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "InProgress\n",
      "\n",
      "\n",
      "{'ProcessingInputs': [{'InputName': 'code', 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-322537213286/spark-amazon-reviews-processor-2020-09-15-05-53-32-188/input/code/preprocess-spark-text-to-bert.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}], 'ProcessingOutputConfig': {'Outputs': [{'OutputName': 'dummy-output', 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-322537213286/spark-amazon-reviews-processor-2020-09-15-05-53-32-188/output/dummy-output', 'LocalPath': '/opt/ml/processing/output', 'S3UploadMode': 'EndOfJob'}}]}, 'ProcessingJobName': 'spark-amazon-reviews-processor-2020-09-15-05-53-32-188', 'ProcessingResources': {'ClusterConfig': {'InstanceCount': 2, 'InstanceType': 'ml.r5.xlarge', 'VolumeSizeInGB': 30}}, 'StoppingCondition': {'MaxRuntimeInSeconds': 86400}, 'AppSpecification': {'ImageUri': '322537213286.dkr.ecr.us-east-1.amazonaws.com/amazon-reviews-spark-processor:latest', 'ContainerEntrypoint': ['/opt/program/submit', '/opt/ml/processing/input/code/preprocess-spark-text-to-bert.py'], 'ContainerArguments': ['s3_input_data', 's3://sagemaker-us-east-1-322537213286/amazon-reviews-pds/tsv/', 's3_output_train_data', 's3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train', 's3_output_validation_data', 's3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation', 's3_output_test_data', 's3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test']}, 'Environment': {'mode': 'python'}, 'RoleArn': 'arn:aws:iam::322537213286:role/service-role/AIMLWorkshop-SageMakerIamRole-W344QRC65HN0', 'ProcessingJobArn': 'arn:aws:sagemaker:us-east-1:322537213286:processing-job/spark-amazon-reviews-processor-2020-09-15-05-53-32-188', 'ProcessingJobStatus': 'InProgress', 'LastModifiedTime': datetime.datetime(2020, 9, 15, 5, 53, 32, 776000, tzinfo=tzlocal()), 'CreationTime': datetime.datetime(2020, 9, 15, 5, 53, 32, 776000, tzinfo=tzlocal()), 'ResponseMetadata': {'RequestId': 'b971da39-c4f3-45b3-a19e-8952da1097a4', 'HTTPStatusCode': 200, 'HTTPHeaders': {'x-amzn-requestid': 'b971da39-c4f3-45b3-a19e-8952da1097a4', 'content-type': 'application/x-amz-json-1.1', 'content-length': '1970', 'date': 'Tue, 15 Sep 2020 05:53:32 GMT'}, 'RetryAttempts': 0}}\n"
     ]
    }
   ],
   "source": [
    "running_processor = sagemaker.processing.ProcessingJob.from_processing_name(processing_job_name=spark_processing_job_name,\n",
    "                                                                            sagemaker_session=sagemaker_session)\n",
    "\n",
    "processing_job_description = running_processor.describe()\n",
    "\n",
    "processing_job_status = processing_job_description['ProcessingJobStatus']\n",
    "print('\\n')\n",
    "print(processing_job_status)\n",
    "print('\\n')\n",
    "\n",
    "print(processing_job_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".......................\u001b[34mWARNING: Use of this script to start HDFS daemons is deprecated.\u001b[0m\n",
      "\u001b[34mWARNING: Attempting to execute replacement \"hdfs --daemon start\" instead.\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.2.1/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: Use of this script to start YARN daemons is deprecated.\u001b[0m\n",
      "\u001b[34mWARNING: Attempting to execute replacement \"yarn --daemon start\" instead.\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34mWARNING: /usr/hadoop-3.2.1/logs does not exist. Creating.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:15,541 INFO namenode.NameNode: STARTUP_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG: Starting NameNode\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   host = algo-1/10.0.220.139\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   args = [-format, -force]\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   version = 3.2.1\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   classpath = /usr/hadoop-3.2.1/etc/hadoop:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jsr305-3.0.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/asm-5.0.4.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jersey-json-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-codec-1.11.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/avro-1.7.7.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jetty-security-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/animal-sniffer-annotations-1.17.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jackson-annotations-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jetty-io-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/failureaccess-1.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/hadoop-auth-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/gson-2.2.4.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/curator-recipes-2.13.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jackson-databind-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/error_prone_annotations-2.2.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jetty-util-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jsp-api-2.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/accessors-smart-1.2.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jetty-http-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/dnsjava-2.1.7.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jul-to-slf4j-1.7.25.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/log4j-1.2.17.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jetty-xml-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-io-2.5.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jetty-server-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/curator-client-2.13.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/token-provider-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/re2j-1.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/curator-framework-2.13.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/checker-qual-2.5.2.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jersey-core-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-text-1.4.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-lang3-3.7.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/paranamer-2.3.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/httpcore-4.4.10.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jsch-0.1.54.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-compress-1.18.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/guava-27.0-jre.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jersey-server-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/metrics-core-3.2.4.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/json-smart-2.3.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/httpclient-4.5.6.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/audience-annotations-0.5.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/slf4j-api-1.7.25.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/zookeeper-3.4.13.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-cli-1.2.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jettison-1.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/j2objc-annotations-1.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/commons-net-3.6.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/hadoop-annotations-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/aws-java-sdk-bundle-1.11.375.jar:/usr/hadoop-3.2.1/share/hadoop/common/lib/hadoop-aws-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/hadoop-kms-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1-tests.jar:/usr/hadoop-3.2.1/share/hadoop/common/hadoop-nfs-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/common/hadoop-common-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-core-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-mapper-asl-1.9.13.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr305-3.0.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-configuration2-2.1.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-server-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/asm-5.0.4.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-json-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-codec-1.11.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-asn1-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/avro-1.7.7.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-client-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-security-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/animal-sniffer-annotations-1.17.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-annotations-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/stax2-api-3.1.4.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/javax.servlet-api-3.1.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-io-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/failureaccess-1.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-auth-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/htrace-core4-4.1.0-incubating.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/gson-2.2.4.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-recipes-2.13.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-databind-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-webapp-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-beanutils-1.9.3.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/error_prone_annotations-2.2.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/snappy-java-1.0.5.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/accessors-smart-1.2.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-http-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/dnsjava-2.1.7.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-math3-3.1.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-impl-2.2.3-1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/log4j-1.2.17.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-pkix-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-xml-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/json-simple-1.1.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-all-4.0.52.Final.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-crypto-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-collections-3.2.2.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-servlet-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-io-2.5.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-jaxrs-1.9.13.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-server-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-daemon-1.0.13.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-client-2.13.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-config-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-xc-1.9.13.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/netty-3.10.5.Final.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/token-provider-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-util-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/re2j-1.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jcip-annotations-1.0-1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/woodstox-core-5.0.3.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/curator-framework-2.13.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/checker-qual-2.5.2.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-core-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-logging-1.1.3.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-text-1.4.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-lang3-3.7.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/paranamer-2.3.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/httpcore-4.4.10.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jsch-0.1.54.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-util-ajax-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-compress-1.18.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jackson-core-asl-1.9.13.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jaxb-api-2.2.11.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/guava-27.0-jre.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jersey-server-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/listenablefuture-9999.0-empty-to-avoid-conflict-with-guava.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-xdr-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-simplekdc-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerby-util-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/json-smart-2.3.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/httpclient-4.5.6.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/audience-annotations-0.5.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/okio-1.6.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/nimbus-jose-jwt-4.41.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-common-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-admin-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/zookeeper-3.4.13.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/protobuf-java-2.5.0.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/leveldbjni-all-1.8.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-cli-1.2.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jettison-1.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/j2objc-annotations-1.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/commons-net-3.6.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/okhttp-2.7.5.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jsr311-api-1.1.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/kerb-identity-1.0.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/hadoop-annotations-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/lib/jetty-servlet-9.3.24.v20180605.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-client-3.2.1-tests.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-nfs-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1-tests.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-rbf-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-native-client-3.2.1-tests.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1-tests.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/hdfs/hadoop-hdfs-httpfs-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/lib/junit-4.11.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/lib/hamcrest-core-1.3.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1-tests.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-common-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-nativetask-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-app-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-jobclient-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-shuffle-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-plugins-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-hs-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-uploader-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/mapreduce/hadoop-mapreduce-client-core-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/java-util-1.9.0.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/ehcache-3.3.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/mssql-jdbc-6.2.1.jre7.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/swagger-annotations-1.5.4.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-json-provider-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/objenesis-1.0.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-client-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/HikariCP-java7-2.4.12.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-jaxrs-base-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/geronimo-jcache_1.0_spec-1.0-alpha-1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/jackson-module-jaxb-annotations-2.9.8.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/bcprov-jdk15on-1.60.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/guice-servlet-4.0.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/javax.inject-1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/json-io-2.5.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/fst-2.50.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/metrics-core-3.2.4.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/jersey-guice-1.19.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/snakeyaml-1.16.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/guice-4.0.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/aopalliance-1.0.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/lib/bcpkix-jdk15on-1.60.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-client-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-submarine-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-tests-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-web-proxy-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-router-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-sharedcachemanager-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-resourcemanager-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-api-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-common-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-timeline-pluginstorage-3.2.\u001b[0m\n",
      "\u001b[34m1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-registry-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-core-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-distributedshell-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-nodemanager-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-applications-unmanaged-am-launcher-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-services-api-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-server-applicationhistoryservice-3.2.1.jar:/usr/hadoop-3.2.1/share/hadoop/yarn/hadoop-yarn-common-3.2.1.jar\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   build = https://gitbox.apache.org/repos/asf/hadoop.git -r b3cbbb467e22ea829b3808f4b7b01d07e0bf3842; compiled by 'rohithsharmaks' on 2019-09-10T15:56Z\u001b[0m\n",
      "\u001b[34mSTARTUP_MSG:   java = 1.8.0_265\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:15,549 INFO namenode.NameNode: registered UNIX signal handlers for [TERM, HUP, INT]\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:15,634 INFO namenode.NameNode: createNameNode [-format, -force]\u001b[0m\n",
      "\u001b[34mFormatting using clusterid: CID-b8165d26-2723-4e0a-b384-53ab94c5e12e\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,006 INFO namenode.FSEditLog: Edit logging is async:true\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,020 INFO namenode.FSNamesystem: KeyProvider: null\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,021 INFO namenode.FSNamesystem: fsLock is fair: true\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,022 INFO namenode.FSNamesystem: Detailed lock hold time metrics enabled: false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,026 INFO namenode.FSNamesystem: fsOwner             = root (auth:SIMPLE)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,026 INFO namenode.FSNamesystem: supergroup          = supergroup\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,026 INFO namenode.FSNamesystem: isPermissionEnabled = true\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,026 INFO namenode.FSNamesystem: HA Enabled: false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,070 INFO common.Util: dfs.datanode.fileio.profiling.sampling.percentage set to 0. Disabling file IO profiling\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,081 INFO blockmanagement.DatanodeManager: dfs.block.invalidate.limit: configured=1000, counted=60, effected=1000\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,081 INFO blockmanagement.DatanodeManager: dfs.namenode.datanode.registration.ip-hostname-check=true\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,085 INFO blockmanagement.BlockManager: dfs.namenode.startup.delay.block.deletion.sec is set to 000:00:00:00.000\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,088 INFO blockmanagement.BlockManager: The block deletion will start around 2020 Sep 15 05:57:16\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,089 INFO util.GSet: Computing capacity for map BlocksMap\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,089 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,090 INFO util.GSet: 2.0% max memory 6.7 GB = 136.4 MB\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,090 INFO util.GSet: capacity      = 2^24 = 16777216 entries\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,131 INFO blockmanagement.BlockManager: Storage policy satisfier is disabled\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,131 INFO blockmanagement.BlockManager: dfs.block.access.token.enable = false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,139 INFO Configuration.deprecation: No unit for dfs.namenode.safemode.extension(30000) assuming MILLISECONDS\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,139 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.threshold-pct = 0.9990000128746033\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,139 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.min.datanodes = 0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,139 INFO blockmanagement.BlockManagerSafeMode: dfs.namenode.safemode.extension = 30000\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,140 INFO blockmanagement.BlockManager: defaultReplication         = 3\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,140 INFO blockmanagement.BlockManager: maxReplication             = 512\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,140 INFO blockmanagement.BlockManager: minReplication             = 1\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,140 INFO blockmanagement.BlockManager: maxReplicationStreams      = 2\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,140 INFO blockmanagement.BlockManager: redundancyRecheckInterval  = 3000ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,140 INFO blockmanagement.BlockManager: encryptDataTransfer        = false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,140 INFO blockmanagement.BlockManager: maxNumBlocksToLog          = 1000\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,166 INFO namenode.FSDirectory: GLOBAL serial map: bits=29 maxEntries=536870911\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,166 INFO namenode.FSDirectory: USER serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,166 INFO namenode.FSDirectory: GROUP serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,166 INFO namenode.FSDirectory: XATTR serial map: bits=24 maxEntries=16777215\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,180 INFO util.GSet: Computing capacity for map INodeMap\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,180 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,180 INFO util.GSet: 1.0% max memory 6.7 GB = 68.2 MB\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,180 INFO util.GSet: capacity      = 2^23 = 8388608 entries\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,197 INFO namenode.FSDirectory: ACLs enabled? false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,197 INFO namenode.FSDirectory: POSIX ACL inheritance enabled? true\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,197 INFO namenode.FSDirectory: XAttrs enabled? true\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,197 INFO namenode.NameNode: Caching file names occurring more than 10 times\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,202 INFO snapshot.SnapshotManager: Loaded config captureOpenFiles: false, skipCaptureAccessTimeOnlyChange: false, snapshotDiffAllowSnapRootDescendant: true, maxSnapshotLimit: 65536\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,204 INFO snapshot.SnapshotManager: SkipList is disabled\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,207 INFO util.GSet: Computing capacity for map cachedBlocks\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,207 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,208 INFO util.GSet: 0.25% max memory 6.7 GB = 17.0 MB\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,208 INFO util.GSet: capacity      = 2^21 = 2097152 entries\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,215 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.window.num.buckets = 10\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,215 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.num.users = 10\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,215 INFO metrics.TopMetrics: NNTop conf: dfs.namenode.top.windows.minutes = 1,5,25\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,218 INFO namenode.FSNamesystem: Retry cache on namenode is enabled\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,218 INFO namenode.FSNamesystem: Retry cache will use 0.03 of total heap and retry cache entry expiry time is 600000 millis\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,219 INFO util.GSet: Computing capacity for map NameNodeRetryCache\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,219 INFO util.GSet: VM type       = 64-bit\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,220 INFO util.GSet: 0.029999999329447746% max memory 6.7 GB = 2.0 MB\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,220 INFO util.GSet: capacity      = 2^18 = 262144 entries\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,242 INFO namenode.FSImage: Allocated new BlockPoolId: BP-1578121912-10.0.220.139-1600149436235\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,255 INFO common.Storage: Storage directory /opt/amazon/hadoop/hdfs/namenode has been successfully formatted.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,284 INFO namenode.FSImageFormatProtobuf: Saving image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 using no compression\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,375 INFO namenode.FSImageFormatProtobuf: Image file /opt/amazon/hadoop/hdfs/namenode/current/fsimage.ckpt_0000000000000000000 of size 399 bytes saved in 0 seconds .\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,387 INFO namenode.NNStorageRetentionManager: Going to retain 1 images with txid >= 0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,390 INFO namenode.FSImage: FSImageSaver clean checkpoint: txid=0 when meet shutdown.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:16,391 INFO namenode.NameNode: SHUTDOWN_MSG: \u001b[0m\n",
      "\u001b[34m/************************************************************\u001b[0m\n",
      "\u001b[34mSHUTDOWN_MSG: Shutting down NameNode at algo-1/10.0.220.139\u001b[0m\n",
      "\u001b[34m************************************************************/\u001b[0m\n",
      "\u001b[34mStarting namenodes on [algo-1]\u001b[0m\n",
      "\u001b[34malgo-1: /usr/hadoop-3.2.1/bin/../libexec/hadoop-functions.sh: line 982: ssh: command not found\u001b[0m\n",
      "\u001b[34mStarting datanodes\u001b[0m\n",
      "\u001b[34mlocalhost: /usr/hadoop-3.2.1/bin/../libexec/hadoop-functions.sh: line 982: ssh: command not found\u001b[0m\n",
      "\u001b[34mStarting secondary namenodes [ip-10-0-220-139.ec2.internal]\u001b[0m\n",
      "\u001b[34mip-10-0-220-139.ec2.internal: /usr/hadoop-3.2.1/bin/../libexec/hadoop-functions.sh: line 982: ssh: command not found\u001b[0m\n",
      "\u001b[34mWARNING: Use of this script to start HDFS daemons is deprecated.\u001b[0m\n",
      "\u001b[34mWARNING: Attempting to execute replacement \"hdfs --daemon start\" instead.\u001b[0m\n",
      "\u001b[34mWARNING: Use of this script to start HDFS daemons is deprecated.\u001b[0m\n",
      "\u001b[34mWARNING: Attempting to execute replacement \"hdfs --daemon start\" instead.\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mStarting resourcemanager\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mWARNING: /var/log/yarn/ does not exist. Creating.\u001b[0m\n",
      "\u001b[34mStarting nodemanagers\u001b[0m\n",
      "\u001b[34mWARNING: YARN_LOG_DIR has been replaced by HADOOP_LOG_DIR. Using value of YARN_LOG_DIR.\u001b[0m\n",
      "\u001b[34mlocalhost: /usr/hadoop-3.2.1/bin/../libexec/hadoop-functions.sh: line 982: ssh: command not found\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:28,837 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-09-15 05:57:29.782048: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer.so.6'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:29.782160: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libnvinfer_plugin.so.6'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:29.782174: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\u001b[0m\n",
      "\u001b[34m2.1.0\u001b[0m\n",
      "\u001b[34m#015Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]#015Downloading: 100%|██████████| 232k/232k [00:00<00:00, 50.0MB/s]\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,079 INFO spark.SparkContext: Running Spark version 2.4.6\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,099 INFO spark.SparkContext: Submitted application: AmazonReviewsSparkProcessor\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,140 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,140 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,140 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,140 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,141 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,353 INFO util.Utils: Successfully started service 'sparkDriver' on port 36847.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,376 INFO spark.SparkEnv: Registering MapOutputTracker\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,396 INFO spark.SparkEnv: Registering BlockManagerMaster\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,398 INFO storage.BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,398 INFO storage.BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,405 INFO storage.DiskBlockManager: Created local directory at /tmp/blockmgr-7f6d639b-7fe7-4eb6-a090-2cd728fcee68\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,422 INFO memory.MemoryStore: MemoryStore started with capacity 366.3 MB\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,465 INFO spark.SparkEnv: Registering OutputCommitCoordinator\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,534 INFO util.log: Logging initialized @3746ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,597 INFO server.Server: jetty-9.3.z-SNAPSHOT, build timestamp: 2018-06-05T17:11:56Z, git hash: 84205aa28f11a4f31f2a3b86d1bba2cc8ab69827\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,625 INFO server.Server: Started @3838ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,645 INFO server.AbstractConnector: Started ServerConnector@49190b40{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,645 INFO util.Utils: Successfully started service 'SparkUI' on port 4040.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,669 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7a75cac0{/jobs,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,669 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@219e1a87{/jobs/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,670 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6af856dd{/jobs/job,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,673 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@4c27bb9b{/jobs/job/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,673 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6441527c{/stages,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,674 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@590f35d7{/stages/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,674 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@224c0e67{/stages/stage,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,676 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1dfbc385{/stages/stage/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,676 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5f86c96b{/stages/pool,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,677 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@38b1306f{/stages/pool/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,678 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@52627661{/storage,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,678 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@11467043{/storage/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,679 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@78e23e91{/storage/rdd,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,680 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@49e15baa{/storage/rdd/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,680 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@871ed89{/environment,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,681 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2a1750ac{/environment/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,682 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@43e8f5c9{/executors,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,682 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@17da15{/executors/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,683 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@70d623b{/executors/threadDump,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,684 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@170fc046{/executors/threadDump/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,690 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@13cd29d3{/static,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,691 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@3711493c{/,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,693 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@540ca3fe{/api,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,693 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1dd49124{/jobs/job/kill,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,694 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@393fd643{/stages/stage/kill,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:31,696 INFO ui.SparkUI: Bound SparkUI to 0.0.0.0, and started at http://10.0.220.139:4040\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,451 INFO client.RMProxy: Connecting to ResourceManager at /10.0.220.139:8032\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,769 INFO yarn.Client: Requesting a new application from cluster with 1 NodeManagers\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,838 INFO conf.Configuration: resource-types.xml not found\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,839 INFO resource.ResourceUtils: Unable to find 'resource-types.xml'.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,854 INFO yarn.Client: Verifying our application has not requested more than the maximum memory capability of the cluster (31706 MB per container)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,855 INFO yarn.Client: Will allocate AM container, with 896 MB memory including 384 MB overhead\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,855 INFO yarn.Client: Setting up container launch context for our AM\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,858 INFO yarn.Client: Setting up the launch environment for our AM container\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,864 INFO yarn.Client: Preparing resources for our AM container\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:32,913 WARN yarn.Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:33,768 INFO yarn.Client: Uploading resource file:/tmp/spark-e71d38ef-62c0-45b8-80de-8d53ce8f01e9/__spark_libs__6938759022972703209.zip -> hdfs://10.0.220.139/user/root/.sparkStaging/application_1600149447309_0001/__spark_libs__6938759022972703209.zip\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:34,735 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,501 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,711 INFO yarn.Client: Uploading resource file:/usr/spark-2.4.6/python/lib/pyspark.zip -> hdfs://10.0.220.139/user/root/.sparkStaging/application_1600149447309_0001/pyspark.zip\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,720 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,742 INFO yarn.Client: Uploading resource file:/usr/spark-2.4.6/python/lib/py4j-0.10.7-src.zip -> hdfs://10.0.220.139/user/root/.sparkStaging/application_1600149447309_0001/py4j-0.10.7-src.zip\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,750 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,889 INFO yarn.Client: Uploading resource file:/tmp/spark-e71d38ef-62c0-45b8-80de-8d53ce8f01e9/__spark_conf__6731053516386118356.zip -> hdfs://10.0.220.139/user/root/.sparkStaging/application_1600149447309_0001/__spark_conf__.zip\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,904 INFO sasl.SaslDataTransferClient: SASL encryption trust check: localHostTrusted = false, remoteHostTrusted = false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,946 INFO spark.SecurityManager: Changing view acls to: root\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,946 INFO spark.SecurityManager: Changing modify acls to: root\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,946 INFO spark.SecurityManager: Changing view acls groups to: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,946 INFO spark.SecurityManager: Changing modify acls groups to: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:35,946 INFO spark.SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:36,727 INFO yarn.Client: Submitting application application_1600149447309_0001 to ResourceManager\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:36,923 INFO impl.YarnClientImpl: Submitted application application_1600149447309_0001\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:36,925 INFO cluster.SchedulerExtensionServices: Starting Yarn extension services with app application_1600149447309_0001 and attemptId None\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:37,933 INFO yarn.Client: Application report for application_1600149447309_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:37,937 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: [Tue Sep 15 05:57:37 +0000 2020] Scheduler has assigned a container for AM, waiting for AM container to be launched\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1600149456821\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1600149447309_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-09-15 05:57:38,939 INFO yarn.Client: Application report for application_1600149447309_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:39,942 INFO yarn.Client: Application report for application_1600149447309_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:40,944 INFO yarn.Client: Application report for application_1600149447309_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:41,947 INFO yarn.Client: Application report for application_1600149447309_0001 (state: ACCEPTED)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:42,597 INFO cluster.YarnClientSchedulerBackend: Add WebUI Filter. org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter, Map(PROXY_HOSTS -> algo-1, PROXY_URI_BASES -> http://algo-1:8088/proxy/application_1600149447309_0001), /proxy/application_1600149447309_0001\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:42,782 INFO cluster.YarnSchedulerBackend$YarnSchedulerEndpoint: ApplicationMaster registered as NettyRpcEndpointRef(spark-client://YarnAM)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:42,950 INFO yarn.Client: Application report for application_1600149447309_0001 (state: RUNNING)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:42,950 INFO yarn.Client: \u001b[0m\n",
      "\u001b[34m#011 client token: N/A\u001b[0m\n",
      "\u001b[34m#011 diagnostics: N/A\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster host: 10.0.205.199\u001b[0m\n",
      "\u001b[34m#011 ApplicationMaster RPC port: -1\u001b[0m\n",
      "\u001b[34m#011 queue: default\u001b[0m\n",
      "\u001b[34m#011 start time: 1600149456821\u001b[0m\n",
      "\u001b[34m#011 final status: UNDEFINED\u001b[0m\n",
      "\u001b[34m#011 tracking URL: http://algo-1:8088/proxy/application_1600149447309_0001/\u001b[0m\n",
      "\u001b[34m#011 user: root\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:42,951 INFO cluster.YarnClientSchedulerBackend: Application application_1600149447309_0001 has started running.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:42,980 INFO util.Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36049.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:42,981 INFO netty.NettyBlockTransferService: Server created on 10.0.220.139:36049\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:42,982 INFO storage.BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:43,001 INFO storage.BlockManagerMaster: Registering BlockManager BlockManagerId(driver, 10.0.220.139, 36049, None)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:43,004 INFO storage.BlockManagerMasterEndpoint: Registering block manager 10.0.220.139:36049 with 366.3 MB RAM, BlockManagerId(driver, 10.0.220.139, 36049, None)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:43,006 INFO storage.BlockManagerMaster: Registered BlockManager BlockManagerId(driver, 10.0.220.139, 36049, None)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:43,006 INFO storage.BlockManager: Initialized BlockManager: BlockManagerId(driver, 10.0.220.139, 36049, None)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:43,113 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /metrics/json.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:43,119 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@2b363ac3{/metrics/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:45,684 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Registered executor NettyRpcEndpointRef(spark-client://Executor) (10.0.205.199:35354) with ID 1\u001b[0m\n",
      "\u001b[34m2020-09-15 05:57:45,764 INFO storage.BlockManagerMasterEndpoint: Registering block manager algo-2:45803 with 11.9 GB RAM, BlockManagerId(1, algo-2, 45803, None)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:01,859 INFO cluster.YarnClientSchedulerBackend: SchedulerBackend is ready for scheduling beginning after waiting maxRegisteredResourcesWaitingTime: 30000(ms)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,080 INFO internal.SharedState: Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/usr/spark-2.4.6/spark-warehouse').\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,080 INFO internal.SharedState: Warehouse path is 'file:/usr/spark-2.4.6/spark-warehouse'.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,087 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,088 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@1b65cedd{/SQL,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,088 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/json.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,088 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6de37392{/SQL/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,089 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,089 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@6bc3435a{/SQL/execution,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,089 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /SQL/execution/json.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,090 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@5c4b1163{/SQL/execution/json,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,091 INFO ui.JettyUtils: Adding filter org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter to /static/sql.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,092 INFO handler.ContextHandler: Started o.s.j.s.ServletContextHandler@7b3e8151{/static/sql,null,AVAILABLE,@Spark}\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,393 INFO state.StateStoreCoordinatorRef: Registered StateStoreCoordinator endpoint\u001b[0m\n",
      "\u001b[34ms3a://sagemaker-us-east-1-322537213286/amazon-reviews-pds/tsv/\u001b[0m\n",
      "\u001b[34ms3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train\u001b[0m\n",
      "\u001b[34ms3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation\u001b[0m\n",
      "\u001b[34ms3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test\u001b[0m\n",
      "\u001b[34mProcessing s3a://sagemaker-us-east-1-322537213286/amazon-reviews-pds/tsv/ => s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,583 INFO impl.MetricsConfig: Loaded properties from hadoop-metrics2.properties\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,636 INFO impl.MetricsSystemImpl: Scheduled Metric snapshot period at 10 second(s).\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:02,636 INFO impl.MetricsSystemImpl: s3a-file-system metrics system started\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:04,028 INFO datasources.InMemoryFileIndex: It took 102 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:04,466 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:04,471 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:04,474 INFO datasources.FileSourceStrategy: Output Data Schema: struct<marketplace: string, customer_id: string, review_id: string, product_id: string, product_parent: string ... 13 more fields>\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:04,481 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:04,865 INFO codegen.CodeGenerator: Code generated in 222.799812 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,074 INFO codegen.CodeGenerator: Code generated in 34.101684 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,129 INFO memory.MemoryStore: Block broadcast_0 stored as values in memory (estimated size 401.9 KB, free 365.9 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,169 INFO memory.MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 42.9 KB, free 365.9 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,170 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 366.3 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,172 INFO spark.SparkContext: Created broadcast 0 from showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,195 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,271 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,286 INFO scheduler.DAGScheduler: Got job 0 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,286 INFO scheduler.DAGScheduler: Final stage: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,287 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,288 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,292 INFO scheduler.DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,358 INFO memory.MemoryStore: Block broadcast_1 stored as values in memory (estimated size 16.3 KB, free 365.8 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,360 INFO memory.MemoryStore: Block broadcast_1_piece0 stored as bytes in memory (estimated size 7.3 KB, free 365.8 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,361 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on 10.0.220.139:36049 (size: 7.3 KB, free: 366.3 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,361 INFO spark.SparkContext: Created broadcast 1 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,373 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,374 INFO cluster.YarnScheduler: Adding task set 0.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,396 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:05,592 INFO storage.BlockManagerInfo: Added broadcast_1_piece0 in memory on algo-2:45803 (size: 7.3 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:06,138 INFO storage.BlockManagerInfo: Added broadcast_0_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,759 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 2369 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,762 INFO cluster.YarnScheduler: Removed TaskSet 0.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,766 INFO scheduler.DAGScheduler: ResultStage 0 (showString at NativeMethodAccessorImpl.java:0) finished in 2.463 s\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,770 INFO scheduler.DAGScheduler: Job 0 finished: showString at NativeMethodAccessorImpl.java:0, took 2.498383 s\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\u001b[0m\n",
      "\u001b[34m|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|   product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\u001b[0m\n",
      "\u001b[34m|         US|   45610553| RMDCHWD0Y5OZ9|B00HH62VB6|     618218723|AGPtek® 10 Isolat...|Musical Instruments|          3|            0|          1|   N|                N|         Three Stars|Works very good, ...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   14640079| RZSL0BALIYUNU|B003LRN53I|     986692292|Sennheiser HD203 ...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|Nice headphones a...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    6111003| RIZR67JKUDBI0|B0006VMBHI|     603261968|AudioQuest LP rec...|Musical Instruments|          3|            0|          1|   N|                Y|         Three Stars|removes dust. doe...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    1546619|R27HL570VNL85F|B002B55TRG|     575084461|Hohner Inc. 560BX...|Musical Instruments|          5|            0|          0|   N|                Y|I purchase these ...|I purchase these ...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   12222213|R34EBU9QDWJ1GD|B00N1YPXW2|     165236328|Blue Yeti USB Mic...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|This is an awesom...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   46018513|R1WCUI4Z1SIQEO|B001N4GRGS|     134151483|Middle Atlantic P...|Musical Instruments|          5|            0|          0|   N|                N|          Five Stars|Used to cool equi...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   10225065| RL5LNO26GAVJ1|B009PJRMHQ|     694166585|Kmise 1pc Pickgua...|Musical Instruments|          2|            3|          4|   N|                Y|Will not Fit Epip...|Note- Does not Fi...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    6356995|R3GYQ5W8JHP8SB|B00NKBDAZS|     446431775|Kealoha Concert U...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|Well built Ukulel...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   35297198|R30SHYQXGG5EYC|B006MIU7U2|     125871705|Halco 80000 - MR1...|Musical Instruments|          5|            0|          0|   N|                Y|Works fine. Hope ...|Had to replace a ...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   32139520|R14YLXA56NP51I|B000FIBD0I|     771888534|Gator GPTBLACK Pl...|Musical Instruments|          5|            1|          1|   N|                N|I upgraded the po...|I've owned multip...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   36060782|R1ZH0HSH38IOTZ|B0002E52GG|      68535945|Hetman 1 - Light ...|Musical Instruments|          5|            0|          0|   N|                Y|My son's favourit...|Consistent qualit...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    5301309|R3H53KLLC210XI|B00RZIH52G|     725541773|Dragonpad pop fil...|Musical Instruments|          4|            0|          0|   N|                Y|Great pop filter ...|by far the best p...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   37472935|R3OOR877NGA8JK|B001792BAU|      46570323|DharmaObjects Rel...|Musical Instruments|          3|            0|          0|   N|                Y|                  Ok|Beautiful set. On...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   33578270|R1BY7WKOZ3KMH0|B009GSKW1Y|     547963417|Musiclily SSS Pla...|Musical Instruments|          2|            0|          0|   N|                Y|           Two Stars|Bridge pickup was...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   22070226| RXP1TFSWE8EG9|B0002F4TKA|     436074323|Vic Firth America...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|Feels good and la...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   52862655|R3J44DPP12OTLJ|B00K17YFBW|      81933093|Guitar Stand for ...|Musical Instruments|          5|            0|          0|   N|                Y|Great stand... on...|I love the stand....| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    4427243| RFOV69SK0T676|B00EQ24HJS|     669249276|Generic 3PLY Faux...|Musical Instruments|          5|            0|          0|   N|                Y|Looks great. You ...|On time. Looks gr...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   14108571|R2HUWDNW62FOL3|B00IBOYTUE|     749537231|Audio 2000 6525 3...|Musical Instruments|          1|            0|          0|   N|                Y|  Poor sound quality|I was hoping it w...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   27314089|R1KSU30XZGR452|B00FBRUSAE|     792472601|Sawtooth ST-AMP-1...|Musical Instruments|          5|            0|          0|   N|                Y|Perfect for the b...|Good sound for it...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   16735445|R2TZVLLTSHA07N|B0113D2QUO|     269114019|Upado Unlimited G...|Musical Instruments|          5|            1|          1|   N|                Y|It really is a mu...|Wow! I didn't exp...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\u001b[0m\n",
      "\u001b[34monly showing top 20 rows\n",
      "\u001b[0m\n",
      "\u001b[34mShowing null review_body rows...\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,856 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,857 INFO datasources.FileSourceStrategy: Post-Scan Filters: isnull(review_body#13)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,857 INFO datasources.FileSourceStrategy: Output Data Schema: struct<marketplace: string, customer_id: string, review_id: string, product_id: string, product_parent: string ... 13 more fields>\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,860 INFO execution.FileSourceScanExec: Pushed Filters: IsNull(review_body)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,928 INFO codegen.CodeGenerator: Code generated in 26.089167 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,936 INFO memory.MemoryStore: Block broadcast_2 stored as values in memory (estimated size 401.9 KB, free 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,954 INFO memory.MemoryStore: Block broadcast_2_piece0 stored as bytes in memory (estimated size 42.9 KB, free 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,954 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,955 INFO spark.SparkContext: Created broadcast 2 from showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,956 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,967 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,969 INFO scheduler.DAGScheduler: Got job 1 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,969 INFO scheduler.DAGScheduler: Final stage: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,969 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,969 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,969 INFO scheduler.DAGScheduler: Submitting ResultStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,974 INFO memory.MemoryStore: Block broadcast_3 stored as values in memory (estimated size 16.6 KB, free 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,975 INFO memory.MemoryStore: Block broadcast_3_piece0 stored as bytes in memory (estimated size 7.4 KB, free 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,976 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on 10.0.220.139:36049 (size: 7.4 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,977 INFO spark.SparkContext: Created broadcast 3 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,978 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 1 (MapPartitionsRDD[7] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,978 INFO cluster.YarnScheduler: Adding task set 1.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:07,979 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 1.0 (TID 1, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:08,016 INFO storage.BlockManagerInfo: Added broadcast_3_piece0 in memory on algo-2:45803 (size: 7.4 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:08,102 INFO storage.BlockManagerInfo: Added broadcast_2_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,286 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 1.0 (TID 1) in 1307 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,286 INFO cluster.YarnScheduler: Removed TaskSet 1.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,287 INFO scheduler.DAGScheduler: ResultStage 1 (showString at NativeMethodAccessorImpl.java:0) finished in 1.317 s\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,288 INFO scheduler.DAGScheduler: Job 1 finished: showString at NativeMethodAccessorImpl.java:0, took 1.320706 s\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+-----------+-----------+\u001b[0m\n",
      "\u001b[34m|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|   product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|review_body|review_date|\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+-----------+-----------+\u001b[0m\n",
      "\u001b[34m|         US|   24889557|R1ALT15XW84SOW|B000RW81AM|     561741789|Stanton N500 Repl...|Musical Instruments|          5|            3|          3|   N|                Y| I mean my record...|       null|       null|\u001b[0m\n",
      "\u001b[34m|         US|    4788420|R2MJ6IVQYBIGWB|B00Y7DB5ZA|     351956175|Scalze Mechanical...|Musical Instruments|          5|            0|          0|   N|                N|       Great Product|       null| 2015-08-24|\u001b[0m\n",
      "\u001b[34m|         US|   13756017|R1LY7OFXW7D83G|B00V39XDYW|     389322049|Strukture SSS57 S...|Musical Instruments|          1|            0|          1|   N|                Y|I think we have a...|       null| 2015-08-24|\u001b[0m\n",
      "\u001b[34m|         US|    1049988|R3IBRUXXKOD6HU|B008X040QE|     438050292|Surfing Blue Pear...|Musical Instruments|          5|            5|          5|   N|                Y|Should have done ...|       null| 2015-08-21|\u001b[0m\n",
      "\u001b[34m|         US|   41216360| RVVPQ9PKPSY9M|B00CFP5ESG|     954028768|Gator G-PG ACOUST...|Musical Instruments|          5|            1|          1|   N|                Y|          Five Stars|       null| 2015-08-18|\u001b[0m\n",
      "\u001b[34m|         US|    2291033| RH0M7W3FKAQE6|B008277N80|     412593952|Diamond Head Ukulele|Musical Instruments|          4|           21|         23|   N|                Y|          Four Stars|       null| 2015-08-15|\u001b[0m\n",
      "\u001b[34m|         US|   16594880|R39WV41UT37NOV|B000DLAO0C|     695688148|Jargar 4/4 Cello ...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|       null| 2015-08-15|\u001b[0m\n",
      "\u001b[34m|         US|    2000949|R16YVBT2IJDGSA|B000P9W5QI|     328210138|GP Percussion GP5...|Musical Instruments|          5|            3|          3|   N|                Y|          Five Stars|       null| 2015-08-14|\u001b[0m\n",
      "\u001b[34m|         US|    3991529|R1D7QB14L9UM0P|B00NKBDAZS|     446431775|Kealoha Concert U...|Musical Instruments|          5|            6|          6|   N|                Y|          Five Stars|       null| 2015-08-11|\u001b[0m\n",
      "\u001b[34m|         US|   20379821|R3HHDM1WQGE59V|B002DP594W|     153828378|Shure Professiona...|Musical Instruments|          4|            2|          3|   N|                Y|          Four Stars|       null| 2015-08-09|\u001b[0m\n",
      "\u001b[34m|         US|   47810643|R1HMENPQD85LN1|B00MO6KKSK|     308823533|Donner Dt-1 Chrom...|Musical Instruments|          5|            1|          1|   N|                Y|          Five Stars|       null| 2015-08-09|\u001b[0m\n",
      "\u001b[34m|         US|    2713246|R1NDQRG6NQW4LB|B00DS4OMUY|     613112255|Generic Amzdeal M...|Musical Instruments|          5|           22|         26|   N|                Y|          Five Stars|       null| 2015-08-08|\u001b[0m\n",
      "\u001b[34m|         US|    1025635|R2JC9Y0TV73V3T|B00KWOX51K|     412419029|Pro Tec SWPB2 Sto...|Musical Instruments|          4|           16|         17|   N|                N|          Four Stars|       null| 2015-08-06|\u001b[0m\n",
      "\u001b[34m|         US|     244839|R2YC4WBS1L2XCL|B00P63ZY2U|     378733816|WOWTOU LED Stage ...|Musical Instruments|          5|            2|          3|   N|                Y| Its very bright ...|       null|       null|\u001b[0m\n",
      "\u001b[34m|         US|   37622146|R369T16AY1NHCF|B00P08R23A|     642176027|Glory Black Resin...|Musical Instruments|          5|            9|          9|   N|                Y|Good piccolo. Not...|       null| 2015-07-30|\u001b[0m\n",
      "\u001b[34m|         US|   21145093| RJE12YGTJSEK3|B00I3XG5C8|     638790804|Epiphone CASINO C...|Musical Instruments|          5|            2|          3|   N|                Y|Not just a great ...|       null|       null|\u001b[0m\n",
      "\u001b[34m|         US|    2562323|R194MQJW0BZTAT|B0007LCKPU|     191392034|PYLE-PRO PADH1079...|Musical Instruments|          5|            4|          4|   N|                Y|          Five Stars|       null| 2015-07-20|\u001b[0m\n",
      "\u001b[34m|         US|   14703927|R1F2ZEGR2NB7G0|B005MR6IHK|     675226467|Fender FT-004 Chr...|Musical Instruments|          5|            6|          6|   N|                Y|works great but w...|       null| 2015-07-18|\u001b[0m\n",
      "\u001b[34m|         US|   50584198| RVSWCRTL9MUHM|B000VBH2IG|     714474785|Zoom H2 Handy Por...|Musical Instruments|          4|            0|          0|   N|                Y| The quality is p...|       null|       null|\u001b[0m\n",
      "\u001b[34m|         US|     362137|R18BYWE28FZF4U|B00KC4JMAS|     768480778|Audio-Technica AT...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|       null| 2015-07-10|\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+-----------+-----------+\u001b[0m\n",
      "\u001b[34monly showing top 20 rows\n",
      "\u001b[0m\n",
      "\u001b[34mShowing cleaned csv\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,349 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,349 INFO datasources.FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, review_body#13)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,350 INFO datasources.FileSourceStrategy: Output Data Schema: struct<marketplace: string, customer_id: string, review_id: string, product_id: string, product_parent: string ... 13 more fields>\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,350 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,406 INFO codegen.CodeGenerator: Code generated in 22.169339 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,411 INFO memory.MemoryStore: Block broadcast_4 stored as values in memory (estimated size 401.9 KB, free 365.0 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,430 INFO memory.MemoryStore: Block broadcast_4_piece0 stored as bytes in memory (estimated size 42.9 KB, free 365.0 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,431 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,432 INFO spark.SparkContext: Created broadcast 4 from showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,432 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,443 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,444 INFO scheduler.DAGScheduler: Got job 2 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,444 INFO scheduler.DAGScheduler: Final stage: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,444 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,445 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,445 INFO scheduler.DAGScheduler: Submitting ResultStage 2 (MapPartitionsRDD[11] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,448 INFO memory.MemoryStore: Block broadcast_5 stored as values in memory (estimated size 16.8 KB, free 364.9 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,450 INFO memory.MemoryStore: Block broadcast_5_piece0 stored as bytes in memory (estimated size 7.5 KB, free 364.9 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,450 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on 10.0.220.139:36049 (size: 7.5 KB, free: 366.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,451 INFO spark.SparkContext: Created broadcast 5 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,451 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 2 (MapPartitionsRDD[11] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,451 INFO cluster.YarnScheduler: Adding task set 2.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,452 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 2.0 (TID 2, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,466 INFO storage.BlockManagerInfo: Added broadcast_5_piece0 in memory on algo-2:45803 (size: 7.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,521 INFO storage.BlockManagerInfo: Added broadcast_4_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,670 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 2.0 (TID 2) in 218 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,670 INFO cluster.YarnScheduler: Removed TaskSet 2.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,670 INFO scheduler.DAGScheduler: ResultStage 2 (showString at NativeMethodAccessorImpl.java:0) finished in 0.224 s\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,671 INFO scheduler.DAGScheduler: Job 2 finished: showString at NativeMethodAccessorImpl.java:0, took 0.227703 s\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\u001b[0m\n",
      "\u001b[34m|marketplace|customer_id|     review_id|product_id|product_parent|       product_title|   product_category|star_rating|helpful_votes|total_votes|vine|verified_purchase|     review_headline|         review_body|review_date|\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\u001b[0m\n",
      "\u001b[34m|         US|   45610553| RMDCHWD0Y5OZ9|B00HH62VB6|     618218723|AGPtek® 10 Isolat...|Musical Instruments|          3|            0|          1|   N|                N|         Three Stars|Works very good, ...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   14640079| RZSL0BALIYUNU|B003LRN53I|     986692292|Sennheiser HD203 ...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|Nice headphones a...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    6111003| RIZR67JKUDBI0|B0006VMBHI|     603261968|AudioQuest LP rec...|Musical Instruments|          3|            0|          1|   N|                Y|         Three Stars|removes dust. doe...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    1546619|R27HL570VNL85F|B002B55TRG|     575084461|Hohner Inc. 560BX...|Musical Instruments|          5|            0|          0|   N|                Y|I purchase these ...|I purchase these ...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   12222213|R34EBU9QDWJ1GD|B00N1YPXW2|     165236328|Blue Yeti USB Mic...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|This is an awesom...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   46018513|R1WCUI4Z1SIQEO|B001N4GRGS|     134151483|Middle Atlantic P...|Musical Instruments|          5|            0|          0|   N|                N|          Five Stars|Used to cool equi...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   10225065| RL5LNO26GAVJ1|B009PJRMHQ|     694166585|Kmise 1pc Pickgua...|Musical Instruments|          2|            3|          4|   N|                Y|Will not Fit Epip...|Note- Does not Fi...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    6356995|R3GYQ5W8JHP8SB|B00NKBDAZS|     446431775|Kealoha Concert U...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|Well built Ukulel...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   35297198|R30SHYQXGG5EYC|B006MIU7U2|     125871705|Halco 80000 - MR1...|Musical Instruments|          5|            0|          0|   N|                Y|Works fine. Hope ...|Had to replace a ...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   32139520|R14YLXA56NP51I|B000FIBD0I|     771888534|Gator GPTBLACK Pl...|Musical Instruments|          5|            1|          1|   N|                N|I upgraded the po...|I've owned multip...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   36060782|R1ZH0HSH38IOTZ|B0002E52GG|      68535945|Hetman 1 - Light ...|Musical Instruments|          5|            0|          0|   N|                Y|My son's favourit...|Consistent qualit...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    5301309|R3H53KLLC210XI|B00RZIH52G|     725541773|Dragonpad pop fil...|Musical Instruments|          4|            0|          0|   N|                Y|Great pop filter ...|by far the best p...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   37472935|R3OOR877NGA8JK|B001792BAU|      46570323|DharmaObjects Rel...|Musical Instruments|          3|            0|          0|   N|                Y|                  Ok|Beautiful set. On...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   33578270|R1BY7WKOZ3KMH0|B009GSKW1Y|     547963417|Musiclily SSS Pla...|Musical Instruments|          2|            0|          0|   N|                Y|           Two Stars|Bridge pickup was...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   22070226| RXP1TFSWE8EG9|B0002F4TKA|     436074323|Vic Firth America...|Musical Instruments|          5|            0|          0|   N|                Y|          Five Stars|Feels good and la...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   52862655|R3J44DPP12OTLJ|B00K17YFBW|      81933093|Guitar Stand for ...|Musical Instruments|          5|            0|          0|   N|                Y|Great stand... on...|I love the stand....| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|    4427243| RFOV69SK0T676|B00EQ24HJS|     669249276|Generic 3PLY Faux...|Musical Instruments|          5|            0|          0|   N|                Y|Looks great. You ...|On time. Looks gr...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   14108571|R2HUWDNW62FOL3|B00IBOYTUE|     749537231|Audio 2000 6525 3...|Musical Instruments|          1|            0|          0|   N|                Y|  Poor sound quality|I was hoping it w...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   27314089|R1KSU30XZGR452|B00FBRUSAE|     792472601|Sawtooth ST-AMP-1...|Musical Instruments|          5|            0|          0|   N|                Y|Perfect for the b...|Good sound for it...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m|         US|   16735445|R2TZVLLTSHA07N|B0113D2QUO|     269114019|Upado Unlimited G...|Musical Instruments|          5|            1|          1|   N|                Y|It really is a mu...|Wow! I didn't exp...| 2015-08-31|\u001b[0m\n",
      "\u001b[34m+-----------+-----------+--------------+----------+--------------+--------------------+-------------------+-----------+-------------+-----------+----+-----------------+--------------------+--------------------+-----------+\u001b[0m\n",
      "\u001b[34monly showing top 20 rows\n",
      "\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,714 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,715 INFO datasources.FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, review_body#13)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,715 INFO datasources.FileSourceStrategy: Output Data Schema: struct<star_rating: int, review_body: string>\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,715 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,736 INFO codegen.CodeGenerator: Code generated in 10.25967 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,752 INFO codegen.CodeGenerator: Code generated in 11.215306 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,757 INFO memory.MemoryStore: Block broadcast_6 stored as values in memory (estimated size 401.9 KB, free 364.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,775 INFO memory.MemoryStore: Block broadcast_6_piece0 stored as bytes in memory (estimated size 42.9 KB, free 364.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,776 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 366.1 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,777 INFO spark.SparkContext: Created broadcast 6 from showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,777 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,785 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,786 INFO scheduler.DAGScheduler: Got job 3 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,786 INFO scheduler.DAGScheduler: Final stage: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,786 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,786 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,787 INFO scheduler.DAGScheduler: Submitting ResultStage 3 (MapPartitionsRDD[15] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,790 INFO memory.MemoryStore: Block broadcast_7 stored as values in memory (estimated size 12.2 KB, free 364.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,815 INFO memory.MemoryStore: Block broadcast_7_piece0 stored as bytes in memory (estimated size 6.4 KB, free 364.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,815 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on 10.0.220.139:36049 (size: 6.4 KB, free: 366.1 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,816 INFO spark.SparkContext: Created broadcast 7 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,817 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[15] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,817 INFO cluster.YarnScheduler: Adding task set 3.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,818 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 3.0 (TID 3, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,829 INFO storage.BlockManagerInfo: Added broadcast_7_piece0 in memory on algo-2:45803 (size: 6.4 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:09,871 INFO storage.BlockManagerInfo: Added broadcast_6_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,039 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 3.0 (TID 3) in 221 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,039 INFO cluster.YarnScheduler: Removed TaskSet 3.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,040 INFO scheduler.DAGScheduler: ResultStage 3 (showString at NativeMethodAccessorImpl.java:0) finished in 0.252 s\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,040 INFO scheduler.DAGScheduler: Job 3 finished: showString at NativeMethodAccessorImpl.java:0, took 0.255545 s\u001b[0m\n",
      "\u001b[34m+-----------+--------------------+\u001b[0m\n",
      "\u001b[34m|star_rating|         review_body|\u001b[0m\n",
      "\u001b[34m+-----------+--------------------+\u001b[0m\n",
      "\u001b[34m|          3|Works very good, ...|\u001b[0m\n",
      "\u001b[34m|          5|Nice headphones a...|\u001b[0m\n",
      "\u001b[34m|          3|removes dust. doe...|\u001b[0m\n",
      "\u001b[34m|          5|I purchase these ...|\u001b[0m\n",
      "\u001b[34m|          5|This is an awesom...|\u001b[0m\n",
      "\u001b[34m|          5|Used to cool equi...|\u001b[0m\n",
      "\u001b[34m|          2|Note- Does not Fi...|\u001b[0m\n",
      "\u001b[34m|          5|Well built Ukulel...|\u001b[0m\n",
      "\u001b[34m|          5|Had to replace a ...|\u001b[0m\n",
      "\u001b[34m|          5|I've owned multip...|\u001b[0m\n",
      "\u001b[34m|          5|Consistent qualit...|\u001b[0m\n",
      "\u001b[34m|          4|by far the best p...|\u001b[0m\n",
      "\u001b[34m|          3|Beautiful set. On...|\u001b[0m\n",
      "\u001b[34m|          2|Bridge pickup was...|\u001b[0m\n",
      "\u001b[34m|          5|Feels good and la...|\u001b[0m\n",
      "\u001b[34m|          5|I love the stand....|\u001b[0m\n",
      "\u001b[34m|          5|On time. Looks gr...|\u001b[0m\n",
      "\u001b[34m|          1|I was hoping it w...|\u001b[0m\n",
      "\u001b[34m|          5|Good sound for it...|\u001b[0m\n",
      "\u001b[34m|          5|Wow! I didn't exp...|\u001b[0m\n",
      "\u001b[34m+-----------+--------------------+\u001b[0m\n",
      "\u001b[34monly showing top 20 rows\n",
      "\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,630 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,631 INFO datasources.FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, review_body#13)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,631 INFO datasources.FileSourceStrategy: Output Data Schema: struct<star_rating: int, review_body: string>\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,631 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,654 INFO codegen.CodeGenerator: Code generated in 8.724808 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,684 INFO codegen.CodeGenerator: Code generated in 20.071247 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,698 INFO codegen.CodeGenerator: Code generated in 9.98059 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,703 INFO memory.MemoryStore: Block broadcast_8 stored as values in memory (estimated size 401.9 KB, free 364.1 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,720 INFO memory.MemoryStore: Block broadcast_8_piece0 stored as bytes in memory (estimated size 42.9 KB, free 364.0 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,721 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 366.1 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,721 INFO spark.SparkContext: Created broadcast 8 from showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,722 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,784 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,785 INFO scheduler.DAGScheduler: Got job 4 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,785 INFO scheduler.DAGScheduler: Final stage: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,785 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,785 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,786 INFO scheduler.DAGScheduler: Submitting ResultStage 4 (MapPartitionsRDD[22] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,793 INFO memory.MemoryStore: Block broadcast_9 stored as values in memory (estimated size 849.5 KB, free 363.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,799 INFO memory.MemoryStore: Block broadcast_9_piece0 stored as bytes in memory (estimated size 644.8 KB, free 362.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,800 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on 10.0.220.139:36049 (size: 644.8 KB, free: 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,800 INFO spark.SparkContext: Created broadcast 9 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,801 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 4 (MapPartitionsRDD[22] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,801 INFO cluster.YarnScheduler: Adding task set 4.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,803 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 4.0 (TID 4, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:10,816 INFO storage.BlockManagerInfo: Added broadcast_9_piece0 in memory on algo-2:45803 (size: 644.8 KB, free: 11.9 GB)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-09-15 05:58:11,309 INFO storage.BlockManagerInfo: Added broadcast_8_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,045 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 4.0 (TID 4) in 2243 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,045 INFO cluster.YarnScheduler: Removed TaskSet 4.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,047 INFO python.PythonAccumulatorV2: Connected to AccumulatorServer at host: 127.0.0.1 port: 37075\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,048 INFO scheduler.DAGScheduler: ResultStage 4 (showString at NativeMethodAccessorImpl.java:0) finished in 2.260 s\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,048 INFO scheduler.DAGScheduler: Job 4 finished: showString at NativeMethodAccessorImpl.java:0, took 2.264110 s\u001b[0m\n",
      "\u001b[34m+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m|tfrecords                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    |\u001b[0m\n",
      "\u001b[34m+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34m|[[101, 2573, 2200, 2204, 1010, 2021, 19653, 2015, 2632, 4140, 1997, 5005, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2]]                                                                                                                                                                                                                                                                                                                                                         |\u001b[0m\n",
      "\u001b[34m|[[101, 3835, 2132, 19093, 2012, 1037, 9608, 3976, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                                                                                     |\u001b[0m\n",
      "\u001b[34m|[[101, 20362, 6497, 1012, 2515, 2025, 4550, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2]]                                                                                                                                                                                                                                                                                                                                                                           |\u001b[0m\n",
      "\u001b[34m|[[101, 1045, 5309, 2122, 2005, 1037, 2767, 1999, 2709, 2005, 2652, 2068, 2005, 2026, 2269, 1998, 2060, 12455, 2012, 1037, 2334, 5075, 2188, 1012, 4067, 2017, 1054, 1012, 24869, 16523, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                    |\u001b[0m\n",
      "\u001b[34m|[[101, 2023, 2003, 2019, 12476, 23025, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                                                                                           |\u001b[0m\n",
      "\u001b[34m|[[101, 2109, 2000, 4658, 3941, 2503, 13675, 14728, 16786, 2015, 1012, 2499, 2307, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                                                                    |\u001b[0m\n",
      "\u001b[34m|[[101, 3602, 1011, 2515, 2025, 4906, 4958, 11514, 27406, 22214, 2569, 999, 3067, 2003, 12800, 2526, 2944, 1998, 2009, 2097, 2025, 6039, 1996, 2686, 2090, 1996, 14910, 24204, 2545, 3294, 1012, 2673, 2842, 2003, 2307, 1998, 2204, 7477, 21530, 4728, 1012, 1045, 2018, 2000, 5587, 2026, 2219, 7661, 2081, 6039, 2121, 5127, 2000, 3143, 1996, 3857, 1012, 1045, 2031, 2025, 2042, 2583, 2000, 2424, 2023, 2806, 4060, 3457, 2008, 2097, 4906, 2026, 2858, 2007, 5372, 12403, 6129, 2090, 14910, 24204, 2545, 2302, 1037, 1004, 1001, 4090, 1025, 7661, 1004, 1001, 4090, 1025, 3976, 1998, 2383, 2000, 4604, 2115, 2858, 2041, 1012, 1026, 7987, 1013, 1028, 2204, 3976, 1010, 2021, 2022, 4810, 2000, 2079, 2070, 7661, 2147, 4426, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1]]                       |\u001b[0m\n",
      "\u001b[34m|[[101, 2092, 2328, 2866, 9307, 2571, 999, 2026, 2684, 7459, 2009, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                                                                               |\u001b[0m\n",
      "\u001b[34m|[[101, 2018, 2000, 5672, 1037, 2047, 2422, 2044, 1037, 7407, 4040, 1012, 2573, 2986, 1012, 3246, 2009, 16180, 2083, 1996, 10943, 2100, 2558, 2023, 2051, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                                  |\u001b[0m\n",
      "\u001b[34m|[[101, 1045, 1005, 2310, 3079, 3674, 4964, 7923, 2058, 1996, 2086, 1010, 2021, 1045, 2172, 2738, 6293, 2007, 3265, 3466, 3197, 1008, 1008, 1008, 1045, 1005, 2310, 4156, 1037, 2261, 4064, 7923, 1998, 2027, 6357, 2039, 4634, 4237, 1010, 2059, 2009, 1005, 1055, 2784, 2416, 2051, 1008, 1008, 1008, 2026, 2567, 1011, 1999, 1011, 2375, 4156, 1996, 14246, 2102, 16558, 28400, 2099, 2004, 1037, 1060, 1011, 3742, 5592, 1019, 2086, 3283, 1010, 1998, 2172, 2000, 2026, 4474, 1010, 2009, 1005, 1055, 2145, 10209, 4632, 1008, 1008, 1008, 1045, 1005, 2310, 3333, 2009, 1037, 2261, 2335, 1010, 2009, 1005, 1055, 2042, 9554, 3706, 2006, 1037, 2261, 2335, 1010, 6476, 2105, 3365, 2335, 1010, 2021, 2044, 2035, 2023, 6905, 1010, 2016, 1005, 1055, 2145, 2600, 2378, 1005, 2004, 2524, 102], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]|\u001b[0m\n",
      "\u001b[34m|[[101, 8335, 3737, 1010, 2053, 2844, 1051, 26797, 2869, 1010, 2573, 2092, 1012, 2026, 2365, 1005, 1055, 8837, 9368, 10764, 3514, 1012, 2002, 2003, 1037, 3809, 2447, 1998, 2023, 2003, 2036, 2054, 2010, 3836, 1006, 1037, 2658, 2102, 19379, 22327, 2121, 1007, 3594, 1012, 2009, 1005, 1055, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                |\u001b[0m\n",
      "\u001b[34m|[[101, 2011, 2521, 1996, 2190, 3769, 11307, 1045, 2031, 2109, 1010, 5186, 4621, 1010, 1045, 2106, 2025, 6065, 2151, 2250, 2012, 2035, 1010, 2026, 2069, 3291, 2003, 2008, 1996, 13020, 1011, 3300, 1998, 15986, 18856, 16613, 2024, 10036, 1998, 2524, 2000, 14171, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [3]]                                                                                                                                                                                                                                                            |\u001b[0m\n",
      "\u001b[34m|[[101, 3376, 2275, 1012, 2069, 1996, 2614, 2025, 2012, 2146, 1998, 26709, 2361, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [2]]                                                                                                                                                                                                                                                                                                                                                      |\u001b[0m\n",
      "\u001b[34m|[[101, 2958, 15373, 2001, 3714, 1012, 1045, 5672, 1040, 1996, 15373, 1998, 7929, 2085, 1012, 2000, 10036, 2000, 4604, 2067, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1]]                                                                                                                                                                                                                                                                                                                               |\u001b[0m\n",
      "\u001b[34m|[[101, 5683, 2204, 1998, 2197, 2146, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                                                                                               |\u001b[0m\n",
      "\u001b[34m|[[101, 1045, 2293, 1996, 3233, 1012, 1045, 4149, 2048, 1012, 1996, 2069, 1043, 15909, 2818, 2003, 2008, 2043, 1045, 4987, 1037, 5830, 2000, 2026, 2858, 1010, 1996, 5830, 1005, 1055, 13354, 2718, 1996, 2723, 2043, 1996, 2858, 2001, 1999, 1996, 3233, 1012, 1037, 2157, 6466, 13354, 13332, 1996, 3291, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                       |\u001b[0m\n",
      "\u001b[34m|[[101, 2006, 2051, 1012, 3504, 2307, 1012, 2017, 2031, 2000, 3424, 6895, 17585, 15135, 2047, 11224, 19990, 2043, 2017, 5672, 1037, 4060, 18405, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                                     |\u001b[0m\n",
      "\u001b[34m|[[101, 1045, 2001, 5327, 2009, 2052, 2147, 2092, 1010, 2021, 2699, 1037, 2117, 11601, 1998, 2052, 2069, 4374, 1037, 2843, 1997, 10763, 1999, 2119, 5363, 1012, 2001, 2196, 2583, 2000, 2131, 3154, 2614, 2012, 2035, 1998, 2699, 3048, 2185, 2013, 2151, 2825, 11099, 4385, 1012, 6410, 10858, 2151, 2785, 1997, 4390, 5008, 1998, 3784, 2001, 11158, 2004, 2092, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0]]                                                                                                                                                                                                           |\u001b[0m\n",
      "\u001b[34m|[[101, 2204, 2614, 2005, 2049, 2946, 1998, 3976, 1012, 2307, 1997, 1037, 2402, 2858, 3076, 1996, 4553, 2006, 1059, 1013, 1051, 4911, 1996, 2924, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                                                                                      |\u001b[0m\n",
      "\u001b[34m|[[101, 10166, 999, 1045, 2134, 1005, 1056, 5987, 1996, 3737, 1998, 2046, 9323, 1997, 2023, 4031, 2000, 2022, 2061, 2152, 1012, 2009, 2428, 2003, 1037, 3315, 6602, 1998, 1996, 2338, 2003, 1037, 10392, 2126, 2000, 4088, 1012, 4283, 2005, 1996, 16465, 2791, 2008, 2253, 2046, 2023, 4031, 999, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [4]]                                                                                                                                                                                                                                                |\u001b[0m\n",
      "\u001b[34m+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\u001b[0m\n",
      "\u001b[34monly showing top 20 rows\n",
      "\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,136 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,136 INFO datasources.FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, review_body#13)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,136 INFO datasources.FileSourceStrategy: Output Data Schema: struct<star_rating: int, review_body: string>\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,136 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,161 INFO codegen.CodeGenerator: Code generated in 10.098346 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,186 INFO codegen.CodeGenerator: Code generated in 17.365068 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,194 INFO memory.MemoryStore: Block broadcast_10 stored as values in memory (estimated size 401.9 KB, free 362.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,211 INFO memory.MemoryStore: Block broadcast_10_piece0 stored as bytes in memory (estimated size 42.9 KB, free 362.1 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,212 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,213 INFO spark.SparkContext: Created broadcast 10 from showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,213 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,246 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,247 INFO scheduler.DAGScheduler: Got job 5 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,247 INFO scheduler.DAGScheduler: Final stage: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,247 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,248 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,248 INFO scheduler.DAGScheduler: Submitting ResultStage 5 (MapPartitionsRDD[29] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,255 INFO memory.MemoryStore: Block broadcast_11 stored as values in memory (estimated size 849.1 KB, free 361.3 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,260 INFO memory.MemoryStore: Block broadcast_11_piece0 stored as bytes in memory (estimated size 644.8 KB, free 360.7 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,260 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on 10.0.220.139:36049 (size: 644.8 KB, free: 364.8 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,261 INFO spark.SparkContext: Created broadcast 11 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,261 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[29] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,261 INFO cluster.YarnScheduler: Adding task set 5.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,262 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 5.0 (TID 5, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,273 INFO storage.BlockManagerInfo: Added broadcast_11_piece0 in memory on algo-2:45803 (size: 644.8 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:13,297 INFO storage.BlockManagerInfo: Added broadcast_10_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,515 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 5.0 (TID 5) in 2253 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,515 INFO cluster.YarnScheduler: Removed TaskSet 5.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,516 INFO scheduler.DAGScheduler: ResultStage 5 (showString at NativeMethodAccessorImpl.java:0) finished in 2.266 s\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,517 INFO scheduler.DAGScheduler: Job 5 finished: showString at NativeMethodAccessorImpl.java:0, took 2.270796 s\u001b[0m\n",
      "\u001b[34m+--------------------+--------------------+--------------------+---------+\u001b[0m\n",
      "\u001b[34m|           input_ids|          input_mask|         segment_ids|label_ids|\u001b[0m\n",
      "\u001b[34m+--------------------+--------------------+--------------------+---------+\u001b[0m\n",
      "\u001b[34m|[101, 2573, 2200,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [2]|\u001b[0m\n",
      "\u001b[34m|[101, 3835, 2132,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 20362, 6497...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [2]|\u001b[0m\n",
      "\u001b[34m|[101, 1045, 5309,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 2023, 2003,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 2109, 2000,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 3602, 1011,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [1]|\u001b[0m\n",
      "\u001b[34m|[101, 2092, 2328,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 2018, 2000,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 1045, 1005,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 8335, 3737,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 2011, 2521,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [3]|\u001b[0m\n",
      "\u001b[34m|[101, 3376, 2275,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [2]|\u001b[0m\n",
      "\u001b[34m|[101, 2958, 15373...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [1]|\u001b[0m\n",
      "\u001b[34m|[101, 5683, 2204,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 1045, 2293,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 2006, 2051,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 1045, 2001,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [0]|\u001b[0m\n",
      "\u001b[34m|[101, 2204, 2614,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m|[101, 10166, 999,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|      [4]|\u001b[0m\n",
      "\u001b[34m+--------------------+--------------------+--------------------+---------+\u001b[0m\n",
      "\u001b[34monly showing top 20 rows\n",
      "\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,731 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on algo-2:45803 in memory (size: 644.8 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,731 INFO storage.BlockManagerInfo: Removed broadcast_11_piece0 on 10.0.220.139:36049 in memory (size: 644.8 KB, free: 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,737 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,737 INFO datasources.FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, review_body#13)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,737 INFO datasources.FileSourceStrategy: Output Data Schema: struct<star_rating: int, review_body: string>\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,737 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,752 INFO spark.ContextCleaner: Cleaned accumulator 169\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 60\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 59\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 87\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 184\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 161\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 129\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 48\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 83\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,753 INFO spark.ContextCleaner: Cleaned accumulator 165\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 85\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 100\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 166\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 139\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 136\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 91\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 145\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 97\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 77\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 33\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 183\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 120\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 32\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 126\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 134\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 20\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 122\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 159\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,754 INFO spark.ContextCleaner: Cleaned accumulator 179\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,755 INFO spark.ContextCleaner: Cleaned accumulator 88\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,755 INFO spark.ContextCleaner: Cleaned accumulator 163\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,755 INFO spark.ContextCleaner: Cleaned accumulator 12\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,755 INFO spark.ContextCleaner: Cleaned accumulator 90\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,755 INFO spark.ContextCleaner: Cleaned accumulator 174\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,755 INFO spark.ContextCleaner: Cleaned accumulator 125\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,755 INFO spark.ContextCleaner: Cleaned accumulator 152\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 51\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 123\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 29\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 42\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 127\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 130\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 56\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 44\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 73\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 16\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 82\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 64\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 175\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 23\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 75\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 19\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 43\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 135\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 79\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 156\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 132\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 186\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,756 INFO spark.ContextCleaner: Cleaned accumulator 45\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 70\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 116\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 28\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 24\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 74\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 93\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 11\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 147\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,757 INFO spark.ContextCleaner: Cleaned accumulator 17\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,771 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on algo-2:45803 in memory (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,772 INFO storage.BlockManagerInfo: Removed broadcast_0_piece0 on 10.0.220.139:36049 in memory (size: 42.9 KB, free: 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 40\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 128\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 76\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 178\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 118\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 143\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 84\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 170\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 67\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 144\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 36\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,780 INFO spark.ContextCleaner: Cleaned accumulator 124\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,785 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on algo-2:45803 in memory (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,785 INFO storage.BlockManagerInfo: Removed broadcast_6_piece0 on 10.0.220.139:36049 in memory (size: 42.9 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,789 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on 10.0.220.139:36049 in memory (size: 6.4 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,790 INFO storage.BlockManagerInfo: Removed broadcast_7_piece0 on algo-2:45803 in memory (size: 6.4 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 54\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 52\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 65\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 14\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 39\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 95\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 49\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 153\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 110\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 119\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 92\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 68\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 162\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 41\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 113\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 155\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 66\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 168\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 99\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 78\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 181\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 8\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 117\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 53\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 38\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 6\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 26\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 164\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 149\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 137\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,792 INFO spark.ContextCleaner: Cleaned accumulator 18\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,794 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on 10.0.220.139:36049 in memory (size: 42.9 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,795 INFO storage.BlockManagerInfo: Removed broadcast_4_piece0 on algo-2:45803 in memory (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 107\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 58\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 154\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 176\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 89\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 112\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 57\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 106\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 69\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 30\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 98\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 5\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 37\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 72\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 2\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 4\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 157\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 158\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 187\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 182\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 131\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 3\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 115\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 46\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 63\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 31\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 142\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 102\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 171\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 62\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 111\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 81\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 177\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 104\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 121\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 173\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 151\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 146\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 80\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 61\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 15\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 150\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 7\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 13\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 34\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 108\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,797 INFO spark.ContextCleaner: Cleaned accumulator 140\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,799 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on 10.0.220.139:36049 in memory (size: 7.5 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,800 INFO storage.BlockManagerInfo: Removed broadcast_5_piece0 on algo-2:45803 in memory (size: 7.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,802 INFO spark.ContextCleaner: Cleaned accumulator 180\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,802 INFO spark.ContextCleaner: Cleaned accumulator 71\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,802 INFO spark.ContextCleaner: Cleaned accumulator 148\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,804 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on 10.0.220.139:36049 in memory (size: 7.3 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,805 INFO storage.BlockManagerInfo: Removed broadcast_1_piece0 on algo-2:45803 in memory (size: 7.3 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 133\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 160\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 172\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 96\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 101\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 35\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 55\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 9\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,807 INFO spark.ContextCleaner: Cleaned accumulator 22\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,808 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on 10.0.220.139:36049 in memory (size: 42.9 KB, free: 365.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,809 INFO storage.BlockManagerInfo: Removed broadcast_2_piece0 on algo-2:45803 in memory (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 94\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 86\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 21\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 109\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 141\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 185\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 50\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 138\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,811 INFO spark.ContextCleaner: Cleaned accumulator 167\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,813 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on 10.0.220.139:36049 in memory (size: 7.4 KB, free: 365.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,814 INFO storage.BlockManagerInfo: Removed broadcast_3_piece0 on algo-2:45803 in memory (size: 7.4 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,816 INFO spark.ContextCleaner: Cleaned accumulator 27\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,816 INFO spark.ContextCleaner: Cleaned accumulator 114\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,816 INFO spark.ContextCleaner: Cleaned accumulator 25\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,816 INFO spark.ContextCleaner: Cleaned accumulator 1\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,816 INFO spark.ContextCleaner: Cleaned accumulator 10\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,816 INFO spark.ContextCleaner: Cleaned accumulator 105\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,816 INFO spark.ContextCleaner: Cleaned accumulator 47\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,816 INFO spark.ContextCleaner: Cleaned accumulator 103\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,818 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on algo-2:45803 in memory (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,818 INFO storage.BlockManagerInfo: Removed broadcast_10_piece0 on 10.0.220.139:36049 in memory (size: 42.9 KB, free: 365.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,832 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on 10.0.220.139:36049 in memory (size: 42.9 KB, free: 365.7 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,832 INFO storage.BlockManagerInfo: Removed broadcast_8_piece0 on algo-2:45803 in memory (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,841 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on 10.0.220.139:36049 in memory (size: 644.8 KB, free: 366.3 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,842 INFO storage.BlockManagerInfo: Removed broadcast_9_piece0 on algo-2:45803 in memory (size: 644.8 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,948 WARN commit.AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,949 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,949 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,949 INFO commit.AbstractS3ACommitterFactory: Using Commmitter FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20200915055815_0000}; taskId=attempt_20200915055815_0000_m_000000_0, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@7516d61b}; outputPath=s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train, workPath=s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train/_temporary/0/_temporary/attempt_20200915055815_0000_m_000000_0, algorithmVersion=2, skipCleanup=false, ignoreCleanupFailures=false} for s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:15,950 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,476 INFO codegen.CodeGenerator: Code generated in 33.611705 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,483 INFO memory.MemoryStore: Block broadcast_12 stored as values in memory (estimated size 401.9 KB, free 365.9 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,495 INFO memory.MemoryStore: Block broadcast_12_piece0 stored as bytes in memory (estimated size 42.9 KB, free 365.9 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,495 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 366.3 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,496 INFO spark.SparkContext: Created broadcast 12 from save at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,497 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,557 INFO spark.SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,558 INFO scheduler.DAGScheduler: Got job 6 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,558 INFO scheduler.DAGScheduler: Final stage: ResultStage 6 (save at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,558 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,558 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,558 INFO scheduler.DAGScheduler: Submitting ResultStage 6 (MapPartitionsRDD[34] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,583 INFO memory.MemoryStore: Block broadcast_13 stored as values in memory (estimated size 1096.1 KB, free 364.8 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,589 INFO memory.MemoryStore: Block broadcast_13_piece0 stored as bytes in memory (estimated size 734.5 KB, free 364.1 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,589 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on 10.0.220.139:36049 (size: 734.5 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,590 INFO spark.SparkContext: Created broadcast 13 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,591 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 6 (MapPartitionsRDD[34] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,591 INFO cluster.YarnScheduler: Adding task set 6.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,592 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 6.0 (TID 6, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,592 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 6.0 (TID 7, algo-2, executor 1, partition 1, PROCESS_LOCAL, 8478 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,605 INFO storage.BlockManagerInfo: Added broadcast_13_piece0 in memory on algo-2:45803 (size: 734.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 05:58:16,716 INFO storage.BlockManagerInfo: Added broadcast_12_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-09-15 06:21:18,554 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 6.0 (TID 7) in 1381962 ms on algo-2 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,137 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 6.0 (TID 6) in 4526545 ms on algo-2 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,137 INFO cluster.YarnScheduler: Removed TaskSet 6.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,139 INFO scheduler.DAGScheduler: ResultStage 6 (save at NativeMethodAccessorImpl.java:0) finished in 4526.579 s\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,139 INFO scheduler.DAGScheduler: Job 6 finished: save at NativeMethodAccessorImpl.java:0, took 4526.582249 s\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,669 INFO datasources.FileFormatWriter: Write Job ed404a2b-526e-43c0-8ae6-83a966490d31 committed.\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,673 INFO datasources.FileFormatWriter: Finished processing stats for write job ed404a2b-526e-43c0-8ae6-83a966490d31.\u001b[0m\n",
      "\u001b[34mWrote to output file:  s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,717 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,718 INFO datasources.FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, review_body#13)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,718 INFO datasources.FileSourceStrategy: Output Data Schema: struct<star_rating: int, review_body: string>\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,718 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,799 WARN commit.AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,799 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,800 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,800 INFO commit.AbstractS3ACommitterFactory: Using Commmitter FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20200915071343_0000}; taskId=attempt_20200915071343_0000_m_000000_0, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@6d85e9ad}; outputPath=s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation, workPath=s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation/_temporary/0/_temporary/attempt_20200915071343_0000_m_000000_0, algorithmVersion=2, skipCleanup=false, ignoreCleanupFailures=false} for s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:43,800 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,205 INFO codegen.CodeGenerator: Code generated in 30.074609 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,212 INFO memory.MemoryStore: Block broadcast_14 stored as values in memory (estimated size 401.9 KB, free 363.7 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,230 INFO memory.MemoryStore: Block broadcast_14_piece0 stored as bytes in memory (estimated size 42.9 KB, free 363.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,230 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,231 INFO spark.SparkContext: Created broadcast 14 from save at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,232 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,334 INFO spark.SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,335 INFO scheduler.DAGScheduler: Got job 7 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,335 INFO scheduler.DAGScheduler: Final stage: ResultStage 7 (save at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,336 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,336 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,337 INFO scheduler.DAGScheduler: Submitting ResultStage 7 (MapPartitionsRDD[41] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,373 INFO memory.MemoryStore: Block broadcast_15 stored as values in memory (estimated size 1096.2 KB, free 362.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,380 INFO memory.MemoryStore: Block broadcast_15_piece0 stored as bytes in memory (estimated size 734.5 KB, free 361.9 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,380 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on 10.0.220.139:36049 (size: 734.5 KB, free: 364.8 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,381 INFO spark.SparkContext: Created broadcast 15 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,383 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 7 (MapPartitionsRDD[41] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,383 INFO cluster.YarnScheduler: Adding task set 7.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,387 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 7.0 (TID 8, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,387 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 7.0 (TID 9, algo-2, executor 1, partition 1, PROCESS_LOCAL, 8478 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,400 INFO storage.BlockManagerInfo: Added broadcast_15_piece0 in memory on algo-2:45803 (size: 734.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:13:44,470 INFO storage.BlockManagerInfo: Added broadcast_14_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,331 INFO spark.ContextCleaner: Cleaned accumulator 206\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,331 INFO spark.ContextCleaner: Cleaned accumulator 188\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,331 INFO spark.ContextCleaner: Cleaned accumulator 221\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,331 INFO spark.ContextCleaner: Cleaned accumulator 199\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 203\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 190\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 201\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 202\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 212\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 224\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 200\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 223\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 189\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 217\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 227\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 191\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 208\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,332 INFO spark.ContextCleaner: Cleaned accumulator 210\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,336 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on 10.0.220.139:36049 in memory (size: 42.9 KB, free: 364.8 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,337 INFO storage.BlockManagerInfo: Removed broadcast_12_piece0 on algo-2:45803 in memory (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,340 INFO spark.ContextCleaner: Cleaned accumulator 194\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,341 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on 10.0.220.139:36049 in memory (size: 734.5 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,342 INFO storage.BlockManagerInfo: Removed broadcast_13_piece0 on algo-2:45803 in memory (size: 734.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 197\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 198\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 192\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 220\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 196\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 205\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 226\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 215\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 222\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 225\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 193\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 214\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 213\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 218\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 219\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 209\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 204\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 216\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 195\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 207\u001b[0m\n",
      "\u001b[34m2020-09-15 07:27:43,344 INFO spark.ContextCleaner: Cleaned accumulator 211\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-09-15 07:36:35,269 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 7.0 (TID 9) in 1370882 ms on algo-2 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:55,792 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 7.0 (TID 8) in 4511408 ms on algo-2 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:55,794 INFO cluster.YarnScheduler: Removed TaskSet 7.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:55,794 INFO scheduler.DAGScheduler: ResultStage 7 (save at NativeMethodAccessorImpl.java:0) finished in 4511.455 s\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:55,794 INFO scheduler.DAGScheduler: Job 7 finished: save at NativeMethodAccessorImpl.java:0, took 4511.459635 s\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,278 INFO datasources.FileFormatWriter: Write Job 0a5edcb6-fd9e-437f-8429-ad8451dc1b50 committed.\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,279 INFO datasources.FileFormatWriter: Finished processing stats for write job 0a5edcb6-fd9e-437f-8429-ad8451dc1b50.\u001b[0m\n",
      "\u001b[34mWrote to output file:  s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,315 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,315 INFO datasources.FileSourceStrategy: Post-Scan Filters: AtLeastNNulls(n, review_body#13)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,315 INFO datasources.FileSourceStrategy: Output Data Schema: struct<star_rating: int, review_body: string>\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,315 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,360 WARN commit.AbstractS3ACommitterFactory: Using standard FileOutputCommitter to commit work. This is slow and potentially unsafe.\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,360 INFO output.FileOutputCommitter: File Output Committer Algorithm version is 2\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,360 INFO output.FileOutputCommitter: FileOutputCommitter skip cleanup _temporary folders under output directory:false, ignore cleanup failures: false\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,360 INFO commit.AbstractS3ACommitterFactory: Using Commmitter FileOutputCommitter{PathOutputCommitter{context=TaskAttemptContextImpl{JobContextImpl{jobId=job_20200915082856_0000}; taskId=attempt_20200915082856_0000_m_000000_0, status=''}; org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter@716dbc48}; outputPath=s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test, workPath=s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test/_temporary/0/_temporary/attempt_20200915082856_0000_m_000000_0, algorithmVersion=2, skipCleanup=false, ignoreCleanupFailures=false} for s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,360 INFO datasources.SQLHadoopMapReduceCommitProtocol: Using output committer class org.apache.hadoop.mapreduce.lib.output.FileOutputCommitter\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,672 INFO codegen.CodeGenerator: Code generated in 26.163643 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,678 INFO memory.MemoryStore: Block broadcast_16 stored as values in memory (estimated size 401.9 KB, free 363.7 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,695 INFO memory.MemoryStore: Block broadcast_16_piece0 stored as bytes in memory (estimated size 42.9 KB, free 363.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,695 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,697 INFO spark.SparkContext: Created broadcast 16 from save at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,697 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 84137401 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,776 INFO spark.SparkContext: Starting job: save at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,776 INFO scheduler.DAGScheduler: Got job 8 (save at NativeMethodAccessorImpl.java:0) with 2 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,776 INFO scheduler.DAGScheduler: Final stage: ResultStage 8 (save at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,776 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,777 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,777 INFO scheduler.DAGScheduler: Submitting ResultStage 8 (MapPartitionsRDD[48] at save at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,801 INFO memory.MemoryStore: Block broadcast_17 stored as values in memory (estimated size 1096.1 KB, free 362.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,806 INFO memory.MemoryStore: Block broadcast_17_piece0 stored as bytes in memory (estimated size 734.5 KB, free 361.9 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,806 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on 10.0.220.139:36049 (size: 734.5 KB, free: 364.8 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,807 INFO spark.SparkContext: Created broadcast 17 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,809 INFO scheduler.DAGScheduler: Submitting 2 missing tasks from ResultStage 8 (MapPartitionsRDD[48] at save at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0, 1))\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,809 INFO cluster.YarnScheduler: Adding task set 8.0 with 2 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,812 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 8.0 (TID 10, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8339 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,812 INFO scheduler.TaskSetManager: Starting task 1.0 in stage 8.0 (TID 11, algo-2, executor 1, partition 1, PROCESS_LOCAL, 8478 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,822 INFO storage.BlockManagerInfo: Added broadcast_17_piece0 in memory on algo-2:45803 (size: 734.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:28:56,880 INFO storage.BlockManagerInfo: Added broadcast_16_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:51:42,430 INFO scheduler.TaskSetManager: Finished task 1.0 in stage 8.0 (TID 11) in 1365618 ms on algo-2 (executor 1) (1/2)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,274 INFO spark.ContextCleaner: Cleaned accumulator 244\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,274 INFO spark.ContextCleaner: Cleaned accumulator 253\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,274 INFO spark.ContextCleaner: Cleaned accumulator 242\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,274 INFO spark.ContextCleaner: Cleaned accumulator 232\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,274 INFO spark.ContextCleaner: Cleaned accumulator 248\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 263\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 245\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 243\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 261\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 260\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 235\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 256\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 234\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,275 INFO spark.ContextCleaner: Cleaned accumulator 241\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,276 INFO spark.ContextCleaner: Cleaned accumulator 228\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,276 INFO spark.ContextCleaner: Cleaned accumulator 229\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,276 INFO spark.ContextCleaner: Cleaned accumulator 262\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,280 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on 10.0.220.139:36049 in memory (size: 42.9 KB, free: 364.8 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,282 INFO storage.BlockManagerInfo: Removed broadcast_14_piece0 on algo-2:45803 in memory (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 267\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 258\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 247\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 252\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 231\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 264\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 238\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 249\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 255\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 240\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 246\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 250\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 236\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 259\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 230\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 265\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 254\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 266\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 257\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 237\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,284 INFO spark.ContextCleaner: Cleaned accumulator 239\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,287 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on algo-2:45803 in memory (size: 734.5 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,287 INFO storage.BlockManagerInfo: Removed broadcast_15_piece0 on 10.0.220.139:36049 in memory (size: 734.5 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,291 INFO spark.ContextCleaner: Cleaned accumulator 233\u001b[0m\n",
      "\u001b[34m2020-09-15 08:57:43,291 INFO spark.ContextCleaner: Cleaned accumulator 251\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m2020-09-15 09:44:02,283 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 8.0 (TID 10) in 4505473 ms on algo-2 (executor 1) (2/2)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:02,283 INFO cluster.YarnScheduler: Removed TaskSet 8.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:02,284 INFO scheduler.DAGScheduler: ResultStage 8 (save at NativeMethodAccessorImpl.java:0) finished in 4505.505 s\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:02,284 INFO scheduler.DAGScheduler: Job 8 finished: save at NativeMethodAccessorImpl.java:0, took 4505.508438 s\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:02,803 INFO datasources.FileFormatWriter: Write Job d9cb7bf5-dddd-4739-93c6-c91b3fc75f3e committed.\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:02,803 INFO datasources.FileFormatWriter: Finished processing stats for write job d9cb7bf5-dddd-4739-93c6-c91b3fc75f3e.\u001b[0m\n",
      "\u001b[34mWrote to output file:  s3a://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,005 INFO datasources.InMemoryFileIndex: It took 56 ms to list leaf files for 1 paths.\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,015 INFO memory.MemoryStore: Block broadcast_18 stored as values in memory (estimated size 389.9 KB, free 363.7 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,026 INFO memory.MemoryStore: Block broadcast_18_piece0 stored as bytes in memory (estimated size 42.4 KB, free 363.7 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,027 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on 10.0.220.139:36049 (size: 42.4 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,027 INFO spark.SparkContext: Created broadcast 18 from newAPIHadoopFile at DefaultSource.scala:37\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,103 INFO input.FileInputFormat: Total input files to process : 1\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,121 INFO spark.SparkContext: Starting job: aggregate at TensorFlowInferSchema.scala:39\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,121 INFO scheduler.DAGScheduler: Got job 9 (aggregate at TensorFlowInferSchema.scala:39) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,122 INFO scheduler.DAGScheduler: Final stage: ResultStage 9 (aggregate at TensorFlowInferSchema.scala:39)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,122 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,122 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,122 INFO scheduler.DAGScheduler: Submitting ResultStage 9 (MapPartitionsRDD[52] at map at DefaultSource.scala:41), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,126 INFO memory.MemoryStore: Block broadcast_19 stored as values in memory (estimated size 3.8 KB, free 363.7 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,127 INFO memory.MemoryStore: Block broadcast_19_piece0 stored as bytes in memory (estimated size 2.2 KB, free 363.6 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,127 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on 10.0.220.139:36049 (size: 2.2 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,128 INFO spark.SparkContext: Created broadcast 19 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,131 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 9 (MapPartitionsRDD[52] at map at DefaultSource.scala:41) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,131 INFO cluster.YarnScheduler: Adding task set 9.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,139 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 9.0 (TID 12, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8085 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,158 INFO storage.BlockManagerInfo: Added broadcast_19_piece0 in memory on algo-2:45803 (size: 2.2 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:03,174 INFO storage.BlockManagerInfo: Added broadcast_18_piece0 in memory on algo-2:45803 (size: 42.4 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,549 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 9.0 (TID 12) in 1418 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,549 INFO cluster.YarnScheduler: Removed TaskSet 9.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,549 INFO scheduler.DAGScheduler: ResultStage 9 (aggregate at TensorFlowInferSchema.scala:39) finished in 1.424 s\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,552 INFO scheduler.DAGScheduler: Job 9 finished: aggregate at TensorFlowInferSchema.scala:39, took 1.430559 s\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,564 INFO datasources.FileSourceStrategy: Pruning directories with: \u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,565 INFO datasources.FileSourceStrategy: Post-Scan Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,565 INFO datasources.FileSourceStrategy: Output Data Schema: struct<label_ids: bigint, input_ids: array<bigint>, input_mask: array<bigint>, segment_ids: array<bigint> ... 2 more fields>\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,565 INFO execution.FileSourceScanExec: Pushed Filters: \u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,587 INFO codegen.CodeGenerator: Code generated in 13.112526 ms\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,592 INFO memory.MemoryStore: Block broadcast_20 stored as values in memory (estimated size 398.1 KB, free 363.3 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,608 INFO memory.MemoryStore: Block broadcast_20_piece0 stored as bytes in memory (estimated size 42.9 KB, free 363.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,608 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on 10.0.220.139:36049 (size: 42.9 KB, free: 365.5 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,611 INFO spark.SparkContext: Created broadcast 20 from broadcast at DefaultSource.scala:94\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,612 INFO execution.FileSourceScanExec: Planning scan with bin packing, max size: 13378699 bytes, open cost is considered as scanning 4194304 bytes.\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,620 INFO spark.SparkContext: Starting job: showString at NativeMethodAccessorImpl.java:0\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,621 INFO scheduler.DAGScheduler: Got job 10 (showString at NativeMethodAccessorImpl.java:0) with 1 output partitions\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,621 INFO scheduler.DAGScheduler: Final stage: ResultStage 10 (showString at NativeMethodAccessorImpl.java:0)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,621 INFO scheduler.DAGScheduler: Parents of final stage: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,622 INFO scheduler.DAGScheduler: Missing parents: List()\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,622 INFO scheduler.DAGScheduler: Submitting ResultStage 10 (MapPartitionsRDD[56] at showString at NativeMethodAccessorImpl.java:0), which has no missing parents\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,634 INFO memory.MemoryStore: Block broadcast_21 stored as values in memory (estimated size 12.6 KB, free 363.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,635 INFO memory.MemoryStore: Block broadcast_21_piece0 stored as bytes in memory (estimated size 5.6 KB, free 363.2 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,635 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on 10.0.220.139:36049 (size: 5.6 KB, free: 365.4 MB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,635 INFO spark.SparkContext: Created broadcast 21 from broadcast at DAGScheduler.scala:1163\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,636 INFO scheduler.DAGScheduler: Submitting 1 missing tasks from ResultStage 10 (MapPartitionsRDD[56] at showString at NativeMethodAccessorImpl.java:0) (first 15 tasks are for partitions Vector(0))\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,636 INFO cluster.YarnScheduler: Adding task set 10.0 with 1 tasks\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,638 INFO scheduler.TaskSetManager: Starting task 0.0 in stage 10.0 (TID 13, algo-2, executor 1, partition 0, PROCESS_LOCAL, 8395 bytes)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,644 INFO storage.BlockManagerInfo: Added broadcast_21_piece0 in memory on algo-2:45803 (size: 5.6 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,678 INFO storage.BlockManagerInfo: Added broadcast_20_piece0 in memory on algo-2:45803 (size: 42.9 KB, free: 11.9 GB)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,736 INFO scheduler.TaskSetManager: Finished task 0.0 in stage 10.0 (TID 13) in 100 ms on algo-2 (executor 1) (1/1)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,736 INFO cluster.YarnScheduler: Removed TaskSet 10.0, whose tasks have all completed, from pool \u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,737 INFO scheduler.DAGScheduler: ResultStage 10 (showString at NativeMethodAccessorImpl.java:0) finished in 0.115 s\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,737 INFO scheduler.DAGScheduler: Job 10 finished: showString at NativeMethodAccessorImpl.java:0, took 0.116637 s\u001b[0m\n",
      "\u001b[34m+---------+--------------------+--------------------+--------------------+\u001b[0m\n",
      "\u001b[34m|label_ids|           input_ids|          input_mask|         segment_ids|\u001b[0m\n",
      "\u001b[34m+---------+--------------------+--------------------+--------------------+\u001b[0m\n",
      "\u001b[34m|        1|[101, 100, 102, 0...|[1, 1, 1, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        1|[101, 100, 102, 0...|[1, 1, 1, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 100, 102, 0...|[1, 1, 1, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 100, 102, 0...|[1, 1, 1, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 100, 102, 0...|[1, 1, 1, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 100, 102, 0...|[1, 1, 1, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 100, 102, 0...|[1, 1, 1, 0, 0, 0...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 100, 3435, ...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        0|[101, 1001, 1015,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 1002, 1020,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        0|[101, 1002, 2184,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        3|[101, 1002, 2184,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        0|[101, 1002, 2654,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        2|[101, 1002, 3429,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        0|[101, 1002, 3998,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        3|[101, 1002, 4749,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 1002, 5594,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 1002, 8746,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        3|[101, 1002, 19527...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m|        4|[101, 1004, 1001,...|[1, 1, 1, 1, 1, 1...|[0, 0, 0, 0, 0, 0...|\u001b[0m\n",
      "\u001b[34m+---------+--------------------+--------------------+--------------------+\u001b[0m\n",
      "\u001b[34monly showing top 20 rows\n",
      "\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,987 INFO spark.SparkContext: Invoking stop() from shutdown hook\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,991 INFO server.AbstractConnector: Stopped Spark@49190b40{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,993 INFO ui.SparkUI: Stopped Spark web UI at http://10.0.220.139:4040\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:04,997 INFO cluster.YarnClientSchedulerBackend: Interrupting monitor thread\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,010 INFO cluster.YarnClientSchedulerBackend: Shutting down all executors\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,011 INFO cluster.YarnSchedulerBackend$YarnDriverEndpoint: Asking each executor to shut down\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,013 INFO cluster.SchedulerExtensionServices: Stopping SchedulerExtensionServices\u001b[0m\n",
      "\u001b[34m(serviceOption=None,\n",
      " services=List(),\n",
      " started=false)\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,014 INFO cluster.YarnClientSchedulerBackend: Stopped\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,018 INFO spark.MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,026 INFO memory.MemoryStore: MemoryStore cleared\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,026 INFO storage.BlockManager: BlockManager stopped\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,027 INFO storage.BlockManagerMaster: BlockManagerMaster stopped\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,029 INFO scheduler.OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,034 INFO spark.SparkContext: Successfully stopped SparkContext\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,034 INFO util.ShutdownHookManager: Shutdown hook called\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,035 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-f3bd7b0f-8fdf-4806-aaa9-3b78ebd45825\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,037 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-e71d38ef-62c0-45b8-80de-8d53ce8f01e9\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,039 INFO util.ShutdownHookManager: Deleting directory /tmp/spark-e71d38ef-62c0-45b8-80de-8d53ce8f01e9/pyspark-370af289-a966-428d-a9ef-82f6bbc76c0d\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,043 INFO impl.MetricsSystemImpl: Stopping s3a-file-system metrics system...\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,043 INFO impl.MetricsSystemImpl: s3a-file-system metrics system stopped.\u001b[0m\n",
      "\u001b[34m2020-09-15 09:44:05,044 INFO impl.MetricsSystemImpl: s3a-file-system metrics system shutdown complete.\u001b[0m\n",
      "\u001b[35m2020-09-15 09:44:06\u001b[0m\n",
      "\u001b[35mFinished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\u001b[35mReceived end of job signal, exiting...\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mFinished Yarn configuration files setup.\n",
      "\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "running_processor.wait()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">위 Processing Job이 완료되기 전까지 기다려 주시기 바랍니다.</span></h2>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# the Processed Output Dataset 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-15 07:13:44          0 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train/_SUCCESS\r\n",
      "2020-09-15 07:13:38  450267574 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train/part-00000-f89d9eb8-fdf8-4a54-b5e8-6567d2a5958c-c000.tfrecord\r\n",
      "2020-09-15 06:21:17  122739791 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train/part-00001-f89d9eb8-fdf8-4a54-b5e8-6567d2a5958c-c000.tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $train_data_bert_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-15 08:28:57          0 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation/_SUCCESS\r\n",
      "2020-09-15 08:28:56   25065057 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation/part-00000-bf37a7ed-3d6e-401e-ad4d-6eecc10de278-c000.tfrecord\r\n",
      "2020-09-15 07:36:35    6798940 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation/part-00001-bf37a7ed-3d6e-401e-ad4d-6eecc10de278-c000.tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $validation_data_bert_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-15 09:44:03          0 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test/_SUCCESS\r\n",
      "2020-09-15 09:44:02   24958447 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test/part-00000-00115674-2af8-411b-81d1-96c0b778e4ae-c000.tfrecord\r\n",
      "2020-09-15 08:51:42    6789042 amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test/part-00001-00115674-2af8-411b-81d1-96c0b778e4ae-c000.tfrecord\r\n"
     ]
    }
   ],
   "source": [
    "!aws s3 ls --recursive $test_data_bert_output/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train/_SUCCESS to data-tfrecord/bert-train/_SUCCESS\n",
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train/part-00001-f89d9eb8-fdf8-4a54-b5e8-6567d2a5958c-c000.tfrecord to data-tfrecord/bert-train/part-00001-f89d9eb8-fdf8-4a54-b5e8-6567d2a5958c-c000.tfrecord\n",
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-train/part-00000-f89d9eb8-fdf8-4a54-b5e8-6567d2a5958c-c000.tfrecord to data-tfrecord/bert-train/part-00000-f89d9eb8-fdf8-4a54-b5e8-6567d2a5958c-c000.tfrecord\n",
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation/_SUCCESS to data-tfrecord/bert-validation/_SUCCESS\n",
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation/part-00000-bf37a7ed-3d6e-401e-ad4d-6eecc10de278-c000.tfrecord to data-tfrecord/bert-validation/part-00000-bf37a7ed-3d6e-401e-ad4d-6eecc10de278-c000.tfrecord\n",
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-validation/part-00001-bf37a7ed-3d6e-401e-ad4d-6eecc10de278-c000.tfrecord to data-tfrecord/bert-validation/part-00001-bf37a7ed-3d6e-401e-ad4d-6eecc10de278-c000.tfrecord\n",
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test/_SUCCESS to data-tfrecord/bert-test/_SUCCESS\n",
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test/part-00000-00115674-2af8-411b-81d1-96c0b778e4ae-c000.tfrecord to data-tfrecord/bert-test/part-00000-00115674-2af8-411b-81d1-96c0b778e4ae-c000.tfrecord\n",
      "download: s3://sagemaker-us-east-1-322537213286/amazon-reviews-spark-processor-2020-09-15-05-53-32/output/bert-test/part-00001-00115674-2af8-411b-81d1-96c0b778e4ae-c000.tfrecord to data-tfrecord/bert-test/part-00001-00115674-2af8-411b-81d1-96c0b778e4ae-c000.tfrecord\n"
     ]
    }
   ],
   "source": [
    "train_data = './data-tfrecord/bert-train'\n",
    "validation_data = './data-tfrecord/bert-validation'\n",
    "test_data = './data-tfrecord/bert-test'\n",
    "\n",
    "!aws s3 cp $train_data_bert_output $train_data --recursive\n",
    "!aws s3 cp $validation_data_bert_output $validation_data --recursive\n",
    "!aws s3 cp $test_data_bert_output $test_data --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'train_data_bert_output' (str)\n",
      "Stored 'train_data' (str)\n"
     ]
    }
   ],
   "source": [
    "%store train_data_bert_output train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'validation_data_bert_output' (str)\n",
      "Stored 'validation_data' (str)\n"
     ]
    }
   ],
   "source": [
    "%store validation_data_bert_output validation_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'test_data_bert_output' (str)\n",
      "Stored 'test_data' (str)\n"
     ]
    }
   ],
   "source": [
    "%store test_data_bert_output test_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
