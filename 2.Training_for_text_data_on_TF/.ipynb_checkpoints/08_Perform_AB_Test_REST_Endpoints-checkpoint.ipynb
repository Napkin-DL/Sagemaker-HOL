{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST Endpoints 기반 A/B Test 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“production variants”이라는 개념으로 하나의 SageMaker Endpoint 내에서 여러 신규 모델을 테스트하고 배포 할 수 있습니다. 이러한 variants은 하드웨어 (CPU/GPU), 데이터(코미디/영화), 지역(US West 또는 AP South)에 따라 다를 수 있습니다. Canary 배포와 블루/그린 배포를 위해 endpoint의 모델 간에 트래픽을 전환 할 수 있습니다. A/B 테스트를 위해 트래픽을 분할 할 수 있습니다. 또한 초당 requests와 같이 특정 메트릭을 기반으로 endpoints를 scale-out 또는 in이 가능합니다. 더 많은 request이 들어 오면 SageMaker는 자동으로 model prediction API를 확장합니다.\n",
    "#### scale-out/in 기능은 Endpoint가 T 시리즈 인스턴스를 사용하는 경우 disable 됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/model_ab.png\" width=\"80%\" align=\"left\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "실제 production 환경에서 서로 다른 모델을 비교하고 테스트하기 위해 트래픽 분할을 사용하여 사용자의 subset에 다른 모델 variants로 지정할 수 있습니다. 목표는 어떤 variants가 더 좋은 성능을 가지고 있는지 확인하는 것입니다. 이러한 테스트는 통계적으로 유의미하게 수행하기 위해 오랜 기간(주) 동안 실행해야하는 경우가 종종 있습니다. 위 그림에서 2개의 variants 사이에 임의의 50-50 트래픽 분할을 사용하여 배포 된 2개의 추천 모델을 보여줍니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import time\n",
    "import sagemaker\n",
    "import pandas as pd\n",
    "\n",
    "sess   = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "role = sagemaker.get_execution_role()\n",
    "region = boto3.Session().region_name\n",
    "\n",
    "sm = boto3.Session().client(service_name='sagemaker', region_name=region)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이전 Notebook에서 Endpoints를 생성하신 경우에는 Endpoints를 삭제하신 후 이 노트북을 생성하시기 바랍니다. 그렇지 않은 경우 HOL를 수행하시는 동안에 ResourceLimitExceeded error를 보실 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-07-15-14-26-15-565-1594908133\n",
      "tensorflow-training-2020-07-15-14-26-15-565-var-b-1594908129\n",
      "tensorflow-training-2020-07-15-14-26-15-565-var-a-1594908129\n"
     ]
    }
   ],
   "source": [
    "list_endpoints = sm.list_endpoints()\n",
    "\n",
    "for ep in list_endpoints['Endpoints']:\n",
    "    sm.delete_endpoint(EndpointName=ep['EndpointName'])\n",
    "    \n",
    "\n",
    "NextToken = 'None'\n",
    "while NextToken !='':\n",
    "    lec = sm.list_endpoint_configs(NextToken=NextToken) if NextToken != 'None' else sm.list_endpoint_configs()\n",
    "    for epc in lec['EndpointConfigs']:\n",
    "        print(epc['EndpointConfigName'])\n",
    "        sm.delete_endpoint_config(EndpointConfigName=epc['EndpointConfigName'])\n",
    "        time.sleep(3)\n",
    "    NextToken = lec['NextToken'] if lec.get('NextToken') else ''\n",
    "\n",
    "NextToken = 'None'\n",
    "while NextToken !='':\n",
    "    lec = sm.list_models(NextToken=NextToken) if NextToken != 'None' else sm.list_models()\n",
    "    for epc in lec['Models']:\n",
    "        print(epc['ModelName'])\n",
    "        sm.delete_model(ModelName=epc['ModelName'])\n",
    "        time.sleep(3)\n",
    "    NextToken = lec['NextToken'] if lec.get('NextToken') else ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%store -r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow-training-2020-07-15-14-26-15-565\n"
     ]
    }
   ],
   "source": [
    "print(training_job_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook 내 Model 복사"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://sagemaker-us-east-2-322537213286/tensorflow-training-2020-07-15-14-26-15-565/output/model.tar.gz to ./model.tar.gz\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp s3://$bucket/$training_job_name/output/model.tar.gz ./model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorboard/\n",
      "tensorflow/\n",
      "tensorflow/saved_model/\n",
      "tensorflow/saved_model/0/\n",
      "tensorflow/saved_model/0/assets/\n",
      "tensorflow/saved_model/0/variables/\n",
      "tensorflow/saved_model/0/variables/variables.index\n",
      "tensorflow/saved_model/0/variables/variables.data-00000-of-00001\n",
      "tensorflow/saved_model/0/saved_model.pb\n",
      "transformers/\n",
      "transformers/fine-tuned/\n",
      "transformers/fine-tuned/tf_model.h5\n",
      "transformers/fine-tuned/config.json\n",
      "metrics/\n",
      "metrics/confusion_matrix.png\n"
     ]
    }
   ],
   "source": [
    "!tar -xvzf ./model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction Signature 살펴보기\n",
    "CLI 를 통해 모델의 Input/output을 조회할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 128)\n",
      "        name: serving_default_input_ids:0\n",
      "    inputs['input_mask'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 128)\n",
      "        name: serving_default_input_mask:0\n",
      "    inputs['segment_ids'] tensor_info:\n",
      "        dtype: DT_INT64\n",
      "        shape: (-1, 128)\n",
      "        name: serving_default_segment_ids:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['output_1'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 5)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "WARNING:tensorflow:From /home/ec2-user/anaconda3/envs/tensorflow2_p36/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "\n",
      "Defined Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #3\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/segment_ids'), 'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n",
      "    Option #4\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          DType: dict\n",
      "          Value: {'input_mask': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_mask'), 'input_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/input_ids'), 'segment_ids': TensorSpec(shape=(None, 128), dtype=tf.int64, name='inputs/segment_ids')}\n",
      "        Named Argument #1\n",
      "          DType: str\n",
      "          Value: ['t', 'r', 'a', 'i', 'n', 'i', 'n', 'g']\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --all --dir ./tensorflow/saved_model/0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training job에서 Model A의 variant 생성\n",
    "\n",
    "Notes:\n",
    "\n",
    "* Training과 Inference 이미지가 다르기 때문에 `primary_container_image`가 필요합니다.\n",
    "* 기본적으로 Training 이미지가 사용되므로, 추가적으로 재정의가 필요합니다.\n",
    "* https://github.com/aws/sagemaker-python-sdk/issues/1379 참조\n",
    "* 이 variant는 Elastic Inference를 사용하므로 Elastic Inference 이미지가 필요합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow-training-2020-07-15-14-26-15-565-var-a-1594910325'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "timestamp = '{}'.format(int(time.time()))\n",
    "\n",
    "model_a_name = '{}-{}-{}'.format(training_job_name, 'var-a', timestamp)\n",
    "\n",
    "sess.create_model_from_job(name=model_a_name,\n",
    "                           training_job_name=training_job_name,\n",
    "                           role=role,\n",
    "#                            primary_container_image='763104351884.dkr.ecr.{}.amazonaws.com/tensorflow-inference:2.1.0-cpu-py36-ubuntu18.04'.format(region))\n",
    "                           primary_container_image='763104351884.dkr.ecr.{}.amazonaws.com/tensorflow-inference-eia:2.0.0-cpu-py36-ubuntu18.04'.format(region))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training job에서 Model B의 variant 생성\n",
    "Notes:\n",
    "* 이 모델은 Variant A와 동일하지만, EIA를 사용하지 않습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tensorflow-training-2020-07-15-14-26-15-565-var-b-1594910325'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_b_name = '{}-{}-{}'.format(training_job_name, 'var-b', timestamp)\n",
    "\n",
    "sess.create_model_from_job(name=model_b_name,\n",
    "                           training_job_name=training_job_name,\n",
    "                           role=role,\n",
    "                           primary_container_image='763104351884.dkr.ecr.{}.amazonaws.com/tensorflow-inference:2.0.0-cpu-py36-ubuntu18.04'.format(region))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Canary Rollouts and A/B Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Canary rollouts은 5% 정도의 사용자에게만 신규 모델을 안전하게 제공하는데 활용됩니다. 전체 사용자 기반에 영향을 주지 않고 실제 production에서 테스트를 하려는 경우에 유용합니다. 대부분의 트래픽은 기존 모델로 이동하므로 Canary 모델의 클러스터 크기는 트래픽이 5%에 불과하기 때문에 상대적으로 작을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`deploy()`함수를 사용하는 대신에 Canary 배포와 A/B 테스팅에 대한 다중 variants로 `Endpoint Configuration`를 생성합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = '{}'.format(int(time.time()))\n",
    "\n",
    "endpoint_config_name = '{}-{}'.format(training_job_name, timestamp)\n",
    "\n",
    "endpoint_config = client.create_endpoint_config(\n",
    "    EndpointConfigName=endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "         'VariantName': 'VariantA',\n",
    "         'ModelName': model_a_name,\n",
    "         'InstanceType':'ml.m5.large',\n",
    "         'InitialInstanceCount': 1,\n",
    "         'InitialVariantWeight': 50,\n",
    "        'AcceleratorType':'ml.eia2.medium' # This variant will use an Elastic Inference Adapter (GPU)            \n",
    "        },\n",
    "        {\n",
    "         'VariantName': 'VariantB',\n",
    "         'ModelName': model_b_name,\n",
    "         'InstanceType':'ml.m5.large',\n",
    "         'InitialInstanceCount': 1,\n",
    "         'InitialVariantWeight': 50,\n",
    "        }\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-2#/endpointConfig/tensorflow-training-2020-07-15-14-26-15-565-1594910328\">REST Endpoint Configuration</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpointConfig/{}\">REST Endpoint Configuration</a></b>'.format(region, endpoint_config_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = '{}-{}'.format(training_job_name, timestamp)\n",
    "\n",
    "endpoint_response = client.create_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=endpoint_config_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-2#/endpoints/tensorflow-training-2020-07-15-14-26-15-565-1594910328\">REST Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">REST Endpoint</a></b>'.format(region, endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">위 Endpoint가 Deploy되기 전까지 기다려 주시기 바랍니다.</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "waiter = client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Raw Text를 BERT Tokens로 변환하기 위한 Request Handler 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RequestHandler(object):\n",
    "    import json\n",
    "    \n",
    "    def __init__(self, tokenizer, max_seq_length):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_seq_length = max_seq_length\n",
    "\n",
    "    def __call__(self, instances):\n",
    "        transformed_instances = []\n",
    "\n",
    "        for instance in instances:\n",
    "            encode_plus_tokens = tokenizer.encode_plus(instance,\n",
    "                                                       pad_to_max_length=True,\n",
    "                                                       max_length=self.max_seq_length)\n",
    "            \n",
    "            input_ids = encode_plus_tokens['input_ids']\n",
    "            input_mask = encode_plus_tokens['attention_mask']\n",
    "            segment_ids = [0] * self.max_seq_length\n",
    "\n",
    "            transformed_instance = {\"input_ids\": input_ids, \n",
    "                                    \"input_mask\": input_mask, \n",
    "                                    \"segment_ids\": segment_ids}\n",
    "            transformed_instances.append(transformed_instance)\n",
    "\n",
    "        transformed_data = {\"instances\": transformed_instances}\n",
    "\n",
    "        return json.dumps(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  BERT Response를 Predicted Classes로 변환하기 위한 Response Handler 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResponseHandler(object):\n",
    "    import json\n",
    "    \n",
    "    def __init__(self, classes):\n",
    "        self.classes = classes\n",
    "    \n",
    "    def softmax(self, x):\n",
    "        import numpy as np\n",
    "        e_x = np.exp(x - np.max(x))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "\n",
    "    def __call__(self, response, accept_header):\n",
    "        import numpy as np\n",
    "        \n",
    "        response_body = response.read().decode('utf-8')\n",
    "        response_json = json.loads(response_body)\n",
    "\n",
    "        log_probabilities = response_json[\"predictions\"]\n",
    "\n",
    "        predicted_classes = []\n",
    "\n",
    "        # Convert log_probabilities => softmax (all probabilities add up to 1) => argmax (final prediction)\n",
    "        for log_probability in log_probabilities:\n",
    "            softmax = self.softmax(log_probability)    \n",
    "            predicted_class_idx = np.argmax(softmax, axis=-1)\n",
    "            print(predicted_class_idx)\n",
    "            predicted_class = self.classes[predicted_class_idx]\n",
    "            predicted_classes.append(predicted_class)\n",
    "\n",
    "        return predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from transformers import DistilBertTokenizer\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-uncased')\n",
    "\n",
    "request_handler = RequestHandler(tokenizer=tokenizer,\n",
    "                                 max_seq_length=128)\n",
    "\n",
    "response_handler = ResponseHandler(classes=[1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor 객체 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.serving import Predictor\n",
    "\n",
    "predictor = Predictor(endpoint_name=endpoint_name,\n",
    "                      sagemaker_session=sess,\n",
    "                      serializer=request_handler,\n",
    "                      deserializer=response_handler,\n",
    "                      content_type='application/json',\n",
    "                      model_name='saved_model',\n",
    "                      model_version=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "4\n",
      "[Predicted Star Rating: 5] This is great!\n",
      "[Predicted Star Rating: 5] This is not good.\n"
     ]
    }
   ],
   "source": [
    "# import tensorflow as tf\n",
    "# import json\n",
    "    \n",
    "reviews = [\"This is great!\", \n",
    "           \"This is not good.\"]\n",
    "\n",
    "predicted_classes = predictor.predict(reviews)\n",
    "\n",
    "for predicted_class, review in zip(predicted_classes, reviews):\n",
    "    print('[Predicted Star Rating: {}]'.format(predicted_class), review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REST Endpoint 성능 지표 검토"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-2#/endpoints/tensorflow-training-2020-07-15-14-26-15-565-1594910328\">REST Endpoint Performance Metrics</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">REST Endpoint Performance Metrics</a></b>'.format(region, endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variant B로 모든 트래픽 이동\n",
    "\n",
    "\n",
    "_**No downtime** 트래픽 이동을 위한 작업이 수행되는 동안에 downtime이 없습니다._\n",
    "\n",
    "이 작업에도 몇 분의 시간이 걸립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_endpoint_config = [\n",
    "    {\n",
    "        'VariantName': 'VariantA',\n",
    "        'DesiredWeight': 0,\n",
    "    },\n",
    "    {\n",
    "        'VariantName': 'VariantB',\n",
    "        'DesiredWeight': 100,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointArn': 'arn:aws:sagemaker:us-east-2:322537213286:endpoint/tensorflow-training-2020-07-15-14-26-15-565-1594910328',\n",
       " 'ResponseMetadata': {'RequestId': '646e32ae-ba39-4965-8226-d65444d8bd1e',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '646e32ae-ba39-4965-8226-d65444d8bd1e',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '122',\n",
       "   'date': 'Thu, 16 Jul 2020 14:53:55 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.update_endpoint_weights_and_capacities(\n",
    "    EndpointName=endpoint_name,\n",
    "    DesiredWeightsAndCapacities=updated_endpoint_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-2#/endpoints/tensorflow-training-2020-07-15-14-26-15-565-1594910328\">REST Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">REST Endpoint</a></b>'.format(region, endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><span style=\"color:red\">위 Endpoint가 update되는 동안은 기다려 주시기 바랍니다.</span></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = boto3.client('sagemaker')\n",
    "waiter = client.get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=endpoint_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 비용절감을 위한 Variant A 삭제\n",
    "\n",
    "Endpoint configuration은 variant B만 사용하도록 수정합니다.\n",
    "\n",
    "_**No downtime** 트래픽 이동을 위한 작업이 수행되는 동안에 downtime이 없습니다._\n",
    "\n",
    "이 작업에도 몇 분의 시간이 걸립니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "timestamp = '{}'.format(int(time.time()))\n",
    "\n",
    "updated_endpoint_config_name = '{}-{}'.format(training_job_name, timestamp)\n",
    "\n",
    "updated_endpoint_config = client.create_endpoint_config(\n",
    "    EndpointConfigName=updated_endpoint_config_name,\n",
    "    ProductionVariants=[\n",
    "        {\n",
    "         'VariantName': 'VariantB',\n",
    "         'ModelName': model_b_name,  # Only specify variant B to remove variant A\n",
    "         'InstanceType':'ml.m5.large',\n",
    "         'InitialInstanceCount': 1,\n",
    "         'InitialVariantWeight': 100\n",
    "        }\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'EndpointArn': 'arn:aws:sagemaker:us-east-2:322537213286:endpoint/tensorflow-training-2020-07-15-14-26-15-565-1594910328',\n",
       " 'ResponseMetadata': {'RequestId': '09403880-a56c-426f-9a5c-09e6f80b7728',\n",
       "  'HTTPStatusCode': 200,\n",
       "  'HTTPHeaders': {'x-amzn-requestid': '09403880-a56c-426f-9a5c-09e6f80b7728',\n",
       "   'content-type': 'application/x-amz-json-1.1',\n",
       "   'content-length': '122',\n",
       "   'date': 'Thu, 16 Jul 2020 14:55:27 GMT'},\n",
       "  'RetryAttempts': 0}}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.update_endpoint(\n",
    "    EndpointName=endpoint_name,\n",
    "    EndpointConfigName=updated_endpoint_config_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region=us-east-2#/endpoints/tensorflow-training-2020-07-15-14-26-15-565-1594910328\">REST Endpoint</a></b>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "\n",
    "display(HTML('<b>Review <a href=\"https://console.aws.amazon.com/sagemaker/home?region={}#/endpoints/{}\">REST Endpoint</a></b>'.format(region, endpoint_name)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ab_endpoint = endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'model_ab_endpoint' (str)\n"
     ]
    }
   ],
   "source": [
    "%store model_ab_endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow2_p36",
   "language": "python",
   "name": "conda_tensorflow2_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
